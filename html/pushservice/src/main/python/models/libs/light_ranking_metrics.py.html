<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../../../" id="documentation_options" src="../../../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>from functools import partial</p>
<dl class="simple">
<dt>from twitter.cortex.ml.embeddings.deepbird.grouped_metrics.configuration import (</dt><dd><p>GroupedMetricsConfiguration,</p>
</dd>
</dl>
<p>)
from twitter.cortex.ml.embeddings.deepbird.grouped_metrics.helpers import (</p>
<blockquote>
<div><p>extract_prediction_from_prediction_record,</p>
</div></blockquote>
<p>)</p>
<p># checkstyle: noqa</p>
<dl>
<dt>def score_loss_at_n(labels, predictions, lightN):</dt><dd><p>“””
Compute the absolute ScoreLoss ranking metric
Args:</p>
<blockquote>
<div><p>labels (list)     : A list of label values       (HeavyRanking Reference)
predictions (list): A list of prediction values  (LightRanking Predictions)
lightN (int): size of the list at which of Initial candidates to compute ScoreLoss. (LightRanking)</p>
</div></blockquote>
<p>“””
assert len(labels) == len(predictions)</p>
<dl class="simple">
<dt>if lightN &lt;= 0:</dt><dd><p>return None</p>
</dd>
</dl>
<p>labels_with_predictions = zip(labels, predictions)
labels_with_sorted_predictions = sorted(</p>
<blockquote>
<div><p>labels_with_predictions, key=lambda x: x[1], reverse=True</p>
</div></blockquote>
<p>)[:lightN]
labels_top1_light = max([label for label, _ in labels_with_sorted_predictions])
labels_top1_heavy = max(labels)</p>
<p>return labels_top1_heavy - labels_top1_light</p>
</dd>
<dt>def cgr_at_nk(labels, predictions, lightN, heavyK):</dt><dd><p>“””
Compute Cumulative Gain Ratio (CGR) ranking metric
Args:</p>
<blockquote>
<div><p>labels (list)     : A list of label values       (HeavyRanking Reference)
predictions (list): A list of prediction values  (LightRanking Predictions)
lightN (int): size of the list at which of Initial candidates to compute CGR. (LightRanking)
heavyK (int): size of the list at which of Refined candidates to compute CGR. (HeavyRanking)</p>
</div></blockquote>
<p>“””
assert len(labels) == len(predictions)</p>
<dl class="simple">
<dt>if (not lightN) or (not heavyK):</dt><dd><p>out = None</p>
</dd>
<dt>elif lightN &lt;= 0 or heavyK &lt;= 0:</dt><dd><p>out = None</p>
</dd>
</dl>
<p>else:</p>
<blockquote>
<div><p>labels_with_predictions = zip(labels, predictions)
labels_with_sorted_predictions = sorted(</p>
<blockquote>
<div><p>labels_with_predictions, key=lambda x: x[1], reverse=True</p>
</div></blockquote>
<p>)[:lightN]
labels_topN_light = [label for label, _ in labels_with_sorted_predictions]</p>
<dl class="simple">
<dt>if lightN &lt;= heavyK:</dt><dd><p>cg_light = sum(labels_topN_light)</p>
</dd>
<dt>else:</dt><dd><p>labels_topK_heavy_from_light = sorted(labels_topN_light, reverse=True)[:heavyK]
cg_light = sum(labels_topK_heavy_from_light)</p>
</dd>
</dl>
<p>ideal_ordering = sorted(labels, reverse=True)
cg_heavy = sum(ideal_ordering[: min(lightN, heavyK)])</p>
<p>out = 0.0
if cg_heavy != 0:</p>
<blockquote>
<div><p>out = max(cg_light / cg_heavy, 0)</p>
</div></blockquote>
</div></blockquote>
<p>return out</p>
</dd>
<dt>def _get_weight(w, atK):</dt><dd><dl class="simple">
<dt>if not w:</dt><dd><p>return 1.0</p>
</dd>
<dt>elif len(w) &lt;= atK:</dt><dd><p>return 0.0</p>
</dd>
<dt>else:</dt><dd><p>return w[atK]</p>
</dd>
</dl>
</dd>
<dt>def recall_at_nk(labels, predictions, n=None, k=None, w=None):</dt><dd><p>“””
Recall at N-K ranking metric
Args:</p>
<blockquote>
<div><p>labels (list): A list of label values
predictions (list): A list of prediction values
n (int): size of the list at which of predictions to compute recall. (Light Ranking Predictions)</p>
<blockquote>
<div><p>The default is None in which case the length of the provided predictions is used as L</p>
</div></blockquote>
<dl class="simple">
<dt>k (int): size of the list at which of labels to compute recall. (Heavy Ranking Predictions)</dt><dd><p>The default is None in which case the length of the provided labels is used as L</p>
</dd>
</dl>
<p>w (list): weight vector sorted by labels</p>
</div></blockquote>
<p>“””
assert len(labels) == len(predictions)</p>
<dl class="simple">
<dt>if not any(labels):</dt><dd><p>out = None</p>
</dd>
</dl>
<p>else:</p>
<blockquote>
<div><p>safe_n = len(predictions) if not n else min(len(predictions), n)
safe_k = len(labels) if not k else min(len(labels), k)</p>
<p>labels_with_predictions = zip(labels, predictions)
sorted_labels_with_predictions = sorted(</p>
<blockquote>
<div><p>labels_with_predictions, key=lambda x: x[0], reverse=True</p>
</div></blockquote>
<p>)</p>
<p>order_sorted_labels_predictions = zip(range(len(labels)), <a href="#id1"><span class="problematic" id="id2">*</span></a>zip(<a href="#id3"><span class="problematic" id="id4">*</span></a>sorted_labels_with_predictions))</p>
<dl class="simple">
<dt>order_with_predictions = [</dt><dd><p>(order, pred) for order, label, pred in order_sorted_labels_predictions</p>
</dd>
</dl>
<p>]
order_with_sorted_predictions = sorted(order_with_predictions, key=lambda x: x[1], reverse=True)</p>
<p>pred_sorted_order_at_n = [order for order, _ in order_with_sorted_predictions][:safe_n]</p>
<dl class="simple">
<dt>intersection_weight = [</dt><dd><p>_get_weight(w, order) if order &lt; safe_k else 0 for order in pred_sorted_order_at_n</p>
</dd>
</dl>
<p>]</p>
<p>intersection_score = sum(intersection_weight)
full_score = sum(w) if w else float(safe_k)</p>
<p>out = 0.0
if full_score != 0:</p>
<blockquote>
<div><p>out = intersection_score / full_score</p>
</div></blockquote>
</div></blockquote>
<p>return out</p>
</dd>
<dt>class ExpectedLossGroupedMetricsConfiguration(GroupedMetricsConfiguration):</dt><dd><p>“””
This is the Expected Loss Grouped metric computation configuration.
“””</p>
<dl>
<dt>def __init__(self, lightNs=[]):</dt><dd><p>“””
Args:</p>
<blockquote>
<div><p>lightNs (list): size of the list at which of Initial candidates to compute Expected Loss. (LightRanking)</p>
</div></blockquote>
<p>“””
self.lightNs = lightNs</p>
</dd>
</dl>
<p>&#64;property
def name(self):</p>
<blockquote>
<div><p>return “ExpectedLoss”</p>
</div></blockquote>
<p>&#64;property
def metrics_dict(self):</p>
<blockquote>
<div><p>metrics_to_compute = {}
for lightN in self.lightNs:</p>
<blockquote>
<div><p>metric_name = “<a href="#id5"><span class="problematic" id="id6">ExpectedLoss_atLight_</span></a>” + str(lightN)
metrics_to_compute[metric_name] = partial(score_loss_at_n, lightN=lightN)</p>
</div></blockquote>
<p>return metrics_to_compute</p>
</div></blockquote>
<dl class="simple">
<dt>def extract_label(self, prec, drec, drec_label):</dt><dd><p>return drec_label</p>
</dd>
<dt>def extract_prediction(self, prec, drec, drec_label):</dt><dd><p>return extract_prediction_from_prediction_record(prec)</p>
</dd>
</dl>
</dd>
<dt>class CGRGroupedMetricsConfiguration(GroupedMetricsConfiguration):</dt><dd><p>“””
This is the Cumulative Gain Ratio (CGR) Grouped metric computation configuration.
CGR at the max length of each session is the default.
CGR at additional positions can be computed by specifying a list of ‘n’s and ‘k’s
“””</p>
<dl>
<dt>def __init__(self, lightNs=[], heavyKs=[]):</dt><dd><p>“””
Args:</p>
<blockquote>
<div><p>lightNs (list): size of the list at which of Initial candidates to compute CGR. (LightRanking)
heavyK (int):   size of the list at which of Refined candidates to compute CGR. (HeavyRanking)</p>
</div></blockquote>
<p>“””
self.lightNs = lightNs
self.heavyKs = heavyKs</p>
</dd>
</dl>
<p>&#64;property
def name(self):</p>
<blockquote>
<div><p>return “cgr”</p>
</div></blockquote>
<p>&#64;property
def metrics_dict(self):</p>
<blockquote>
<div><p>metrics_to_compute = {}
for lightN in self.lightNs:</p>
<blockquote>
<div><dl class="simple">
<dt>for heavyK in self.heavyKs:</dt><dd><p>metric_name = “<a href="#id7"><span class="problematic" id="id8">cgr_atLight_</span></a>” + str(lightN) + “_atHeavy_” + str(heavyK)
metrics_to_compute[metric_name] = partial(cgr_at_nk, lightN=lightN, heavyK=heavyK)</p>
</dd>
</dl>
</div></blockquote>
<p>return metrics_to_compute</p>
</div></blockquote>
<dl class="simple">
<dt>def extract_label(self, prec, drec, drec_label):</dt><dd><p>return drec_label</p>
</dd>
<dt>def extract_prediction(self, prec, drec, drec_label):</dt><dd><p>return extract_prediction_from_prediction_record(prec)</p>
</dd>
</dl>
</dd>
<dt>class RecallGroupedMetricsConfiguration(GroupedMetricsConfiguration):</dt><dd><p>“””
This is the Recall Grouped metric computation configuration.
Recall at the max length of each session is the default.
Recall at additional positions can be computed by specifying a list of ‘n’s and ‘k’s
“””</p>
<dl>
<dt>def __init__(self, n=[], k=[], w=[]):</dt><dd><p>“””
Args:</p>
<blockquote>
<div><p>n (list): A list of ints. List of prediction rank thresholds (for light)
k (list): A list of ints. List of label rank thresholds (for heavy)</p>
</div></blockquote>
<p>“””
self.predN = n
self.labelK = k
self.weight = w</p>
</dd>
</dl>
<p>&#64;property
def name(self):</p>
<blockquote>
<div><p>return “group_recall”</p>
</div></blockquote>
<p>&#64;property
def metrics_dict(self):</p>
<blockquote>
<div><p>metrics_to_compute = {“group_recall_unweighted”: recall_at_nk}
if not self.weight:</p>
<blockquote>
<div><p>metrics_to_compute[“group_recall_weighted”] = partial(recall_at_nk, w=self.weight)</p>
</div></blockquote>
<dl>
<dt>if self.predN and self.labelK:</dt><dd><dl>
<dt>for n in self.predN:</dt><dd><dl>
<dt>for k in self.labelK:</dt><dd><dl>
<dt>if n &gt;= k:</dt><dd><dl class="simple">
<dt>metrics_to_compute[</dt><dd><p>“group_recall_unweighted_at_L” + str(n) + “_at_H” + str(k)</p>
</dd>
</dl>
<p>] = partial(recall_at_nk, n=n, k=k)
if self.weight:</p>
<blockquote>
<div><dl class="simple">
<dt>metrics_to_compute[</dt><dd><p>“group_recall_weighted_at_L” + str(n) + “_at_H” + str(k)</p>
</dd>
</dl>
<p>] = partial(recall_at_nk, n=n, k=k, w=self.weight)</p>
</div></blockquote>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt>if self.labelK and not self.predN:</dt><dd><dl>
<dt>for k in self.labelK:</dt><dd><dl class="simple">
<dt>metrics_to_compute[“group_recall_unweighted_at_full_at_H” + str(k)] = partial(</dt><dd><p>recall_at_nk, k=k</p>
</dd>
</dl>
<p>)
if self.weight:</p>
<blockquote>
<div><dl class="simple">
<dt>metrics_to_compute[“group_recall_weighted_at_full_at_H” + str(k)] = partial(</dt><dd><p>recall_at_nk, k=k, w=self.weight</p>
</dd>
</dl>
<p>)</p>
</div></blockquote>
</dd>
</dl>
</dd>
</dl>
<p>return metrics_to_compute</p>
</div></blockquote>
<dl class="simple">
<dt>def extract_label(self, prec, drec, drec_label):</dt><dd><p>return drec_label</p>
</dd>
<dt>def extract_prediction(self, prec, drec, drec_label):</dt><dd><p>return extract_prediction_from_prediction_record(prec)</p>
</dd>
</dl>
</dd>
</dl>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../../index.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../../../_sources/pushservice/src/main/python/models/libs/light_ranking_metrics.py.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>