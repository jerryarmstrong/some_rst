<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../../../" id="documentation_options" src="../../../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>“””
Utilties for constructing a metric_fn for magic recs.
“””</p>
<dl class="simple">
<dt>from twml.contrib.metrics.metrics import (</dt><dd><p>get_dual_binary_tasks_metric_fn,
get_numeric_metric_fn,
get_partial_multi_binary_class_metric_fn,
get_single_binary_task_metric_fn,</p>
</dd>
</dl>
<p>)</p>
<p>from .model_utils import generate_disliked_mask</p>
<p>import tensorflow.compat.v1 as tf</p>
<dl class="simple">
<dt>METRIC_BOOK = {</dt><dd><p>“OONC”: [“OONC”],
“OONC_Engagement”: [“OONC”, “Engagement”],
“Sent”: [“Sent”],
“HeavyRankPosition”: [“HeavyRankPosition”],
“HeavyRankProbability”: [“HeavyRankProbability”],</p>
</dd>
</dl>
<p>}</p>
<p>USER_AGE_FEATURE_NAME = “accountAge”
NEW_USER_AGE_CUTOFF = 0</p>
<dl>
<dt>def remove_padding_and_flatten(tensor, valid_batch_size):</dt><dd><dl>
<dt>“””Remove the padding of the input padded tensor given the valid batch size tensor,</dt><dd><p>then flatten the output with respect to the first dimension.</p>
</dd>
<dt>Args:</dt><dd><p>tensor: A tensor of size [META_BATCH_SIZE, BATCH_SIZE, FEATURE_DIM].
valid_batch_size: A tensor of size [META_BATCH_SIZE], with each element indicating</p>
<blockquote>
<div><p>the effective batch size of the BATCH_SIZE dimension.</p>
</div></blockquote>
</dd>
<dt>Returns:</dt><dd><p>A tesnor of size [tf.reduce_sum(valid_batch_size), FEATURE_DIM].</p>
</dd>
</dl>
<p>“””
unpadded_ragged_tensor = tf.RaggedTensor.from_tensor(tensor=tensor, lengths=valid_batch_size)</p>
<p>return unpadded_ragged_tensor.flat_values</p>
</dd>
<dt>def safe_mask(values, mask):</dt><dd><p>“””Mask values if possible.</p>
<p>Boolean mask inputed values if and only if values is a tensor of the same dimension as mask (or can be broadcasted to that dimension).</p>
<dl class="simple">
<dt>Args:</dt><dd><p>values (Any or Tensor): Input tensor to mask. Dim 0 should be size N.
mask (boolean tensor): A boolean tensor of size N.</p>
</dd>
</dl>
<p>Returns Values or Values masked.
“””
if values is None:</p>
<blockquote>
<div><p>return values</p>
</div></blockquote>
<dl class="simple">
<dt>if not tf.is_tensor(values):</dt><dd><p>return values</p>
</dd>
</dl>
<p>values_shape = values.get_shape()
if not values_shape or len(values_shape) == 0:</p>
<blockquote>
<div><p>return values</p>
</div></blockquote>
<dl class="simple">
<dt>if not mask.get_shape().is_compatible_with(values_shape[0]):</dt><dd><p>return values</p>
</dd>
</dl>
<p>return tf.boolean_mask(values, mask)</p>
</dd>
<dt>def add_new_user_metrics(metric_fn):</dt><dd><p>“””Will stratify the metric_fn by adding new user metrics.</p>
<p>Given an input metric_fn, double every metric: One will be the orignal and the other will only include those for new users.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>metric_fn (python function): Base twml metric_fn.</p>
</dd>
</dl>
<p>Returns a metric_fn with new user metrics included.
“””</p>
<dl>
<dt>def metric_fn_with_new_users(graph_output, labels, weights):</dt><dd><dl>
<dt>if USER_AGE_FEATURE_NAME not in graph_output:</dt><dd><dl>
<dt>raise ValueError(</dt><dd><dl class="simple">
<dt>“In order to get metrics stratified by user age, {name} feature should be added to model graph output. However, only the following output keys were found: {keys}.”.format(</dt><dd><p>name=USER_AGE_FEATURE_NAME, keys=graph_output.keys()</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
<p>metric_ops = metric_fn(graph_output, labels, weights)</p>
<dl>
<dt>is_new = tf.reshape(</dt><dd><dl class="simple">
<dt>tf.math.less_equal(</dt><dd><p>tf.cast(graph_output[USER_AGE_FEATURE_NAME], tf.int64),
tf.cast(NEW_USER_AGE_CUTOFF, tf.int64),</p>
</dd>
</dl>
<p>),
[-1],</p>
</dd>
</dl>
<p>)</p>
<p>labels = safe_mask(labels, is_new)
weights = safe_mask(weights, is_new)
graph_output = {key: safe_mask(values, is_new) for key, values in graph_output.items()}</p>
<p>new_user_metric_ops = metric_fn(graph_output, labels, weights)
new_user_metric_ops = {name + “_new_users”: ops for name, ops in new_user_metric_ops.items()}
metric_ops.update(new_user_metric_ops)
return metric_ops</p>
</dd>
</dl>
<p>return metric_fn_with_new_users</p>
</dd>
<dt>def get_meta_learn_single_binary_task_metric_fn(</dt><dd><p>metrics, classnames, top_k=(5, 5, 5), use_top_k=False</p>
</dd>
<dt>):</dt><dd><p>“””Wrapper function to use the metric_fn with meta learning evaluation scheme.</p>
<dl>
<dt>Args:</dt><dd><p>metrics: A list of string representing metric names.
classnames: A list of string repsenting class names, In case of multiple binary class models,</p>
<blockquote>
<div><p>the names for each class or label.</p>
</div></blockquote>
<p>top_k: A tuple of int to specify top K metrics.
use_top_k: A boolean value indicating of top K of metrics is used.</p>
</dd>
<dt>Returns:</dt><dd><p>A customized metric_fn function.</p>
</dd>
</dl>
<p>“””</p>
<dl>
<dt>def get_eval_metric_ops(graph_output, labels, weights):</dt><dd><dl class="simple">
<dt>“””The op func of the eval_metrics. Comparing with normal version,</dt><dd><p>the difference is we flatten the output, label, and weights.</p>
</dd>
<dt>Args:</dt><dd><p>graph_output: A dict of tensors.
labels: A tensor of int32 be the value of either 0 or 1.
weights: A tensor of float32 to indicate the per record weight.</p>
</dd>
<dt>Returns:</dt><dd><p>A dict of metric names and values.</p>
</dd>
</dl>
<p>“””
metric_op_weighted = get_partial_multi_binary_class_metric_fn(</p>
<blockquote>
<div><p>metrics, predcols=0, classes=classnames</p>
</div></blockquote>
<p>)
classnames_unweighted = [”<a href="#id1"><span class="problematic" id="id2">unweighted_</span></a>” + classname for classname in classnames]
metric_op_unweighted = get_partial_multi_binary_class_metric_fn(</p>
<blockquote>
<div><p>metrics, predcols=0, classes=classnames_unweighted</p>
</div></blockquote>
<p>)</p>
<p>valid_batch_size = graph_output[“valid_batch_size”]
graph_output[“output”] = remove_padding_and_flatten(graph_output[“output”], valid_batch_size)
labels = remove_padding_and_flatten(labels, valid_batch_size)
weights = remove_padding_and_flatten(weights, valid_batch_size)</p>
<p>tf.ensure_shape(graph_output[“output”], [None, 1])
tf.ensure_shape(labels, [None, 1])
tf.ensure_shape(weights, [None, 1])</p>
<p>metrics_weighted = metric_op_weighted(graph_output, labels, weights)
metrics_unweighted = metric_op_unweighted(graph_output, labels, None)
metrics_weighted.update(metrics_unweighted)</p>
<dl class="simple">
<dt>if use_top_k:</dt><dd><p>metric_op_numeric = get_numeric_metric_fn(metrics=None, topK=top_k, predcol=0, labelcol=1)
metrics_numeric = metric_op_numeric(graph_output, labels, weights)
metrics_weighted.update(metrics_numeric)</p>
</dd>
</dl>
<p>return metrics_weighted</p>
</dd>
</dl>
<p>return get_eval_metric_ops</p>
</dd>
<dt>def get_meta_learn_dual_binary_tasks_metric_fn(</dt><dd><p>metrics, classnames, top_k=(5, 5, 5), use_top_k=False</p>
</dd>
<dt>):</dt><dd><p>“””Wrapper function to use the metric_fn with meta learning evaluation scheme.</p>
<dl>
<dt>Args:</dt><dd><p>metrics: A list of string representing metric names.
classnames: A list of string repsenting class names, In case of multiple binary class models,</p>
<blockquote>
<div><p>the names for each class or label.</p>
</div></blockquote>
<p>top_k: A tuple of int to specify top K metrics.
use_top_k: A boolean value indicating of top K of metrics is used.</p>
</dd>
<dt>Returns:</dt><dd><p>A customized metric_fn function.</p>
</dd>
</dl>
<p>“””</p>
<dl>
<dt>def get_eval_metric_ops(graph_output, labels, weights):</dt><dd><dl class="simple">
<dt>“””The op func of the eval_metrics. Comparing with normal version,</dt><dd><p>the difference is we flatten the output, label, and weights.</p>
</dd>
<dt>Args:</dt><dd><p>graph_output: A dict of tensors.
labels: A tensor of int32 be the value of either 0 or 1.
weights: A tensor of float32 to indicate the per record weight.</p>
</dd>
<dt>Returns:</dt><dd><p>A dict of metric names and values.</p>
</dd>
</dl>
<p>“””
metric_op_weighted = get_partial_multi_binary_class_metric_fn(</p>
<blockquote>
<div><p>metrics, predcols=[0, 1], classes=classnames</p>
</div></blockquote>
<p>)
classnames_unweighted = [”<a href="#id3"><span class="problematic" id="id4">unweighted_</span></a>” + classname for classname in classnames]
metric_op_unweighted = get_partial_multi_binary_class_metric_fn(</p>
<blockquote>
<div><p>metrics, predcols=[0, 1], classes=classnames_unweighted</p>
</div></blockquote>
<p>)</p>
<p>valid_batch_size = graph_output[“valid_batch_size”]
graph_output[“output”] = remove_padding_and_flatten(graph_output[“output”], valid_batch_size)
labels = remove_padding_and_flatten(labels, valid_batch_size)
weights = remove_padding_and_flatten(weights, valid_batch_size)</p>
<p>tf.ensure_shape(graph_output[“output”], [None, 2])
tf.ensure_shape(labels, [None, 2])
tf.ensure_shape(weights, [None, 1])</p>
<p>metrics_weighted = metric_op_weighted(graph_output, labels, weights)
metrics_unweighted = metric_op_unweighted(graph_output, labels, None)
metrics_weighted.update(metrics_unweighted)</p>
<dl class="simple">
<dt>if use_top_k:</dt><dd><p>metric_op_numeric = get_numeric_metric_fn(metrics=None, topK=top_k, predcol=2, labelcol=2)
metrics_numeric = metric_op_numeric(graph_output, labels, weights)
metrics_weighted.update(metrics_numeric)</p>
</dd>
</dl>
<p>return metrics_weighted</p>
</dd>
</dl>
<p>return get_eval_metric_ops</p>
</dd>
<dt>def get_metric_fn(task_name, use_stratify_metrics, use_meta_batch=False):</dt><dd><p>“””Will retrieve the metric_fn for magic recs.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>task_name (string): Which task is being used for this model.
use_stratify_metrics (boolean): Should we add stratified metrics (new user metrics).
use_meta_batch (boolean): If the output/label/weights are passed in 3D shape instead of
2D shape.</p>
</dd>
<dt>Returns:</dt><dd><p>A metric_fn function to pass in twml Trainer.</p>
</dd>
</dl>
<p>“””
if task_name not in METRIC_BOOK:</p>
<blockquote>
<div><dl>
<dt>raise ValueError(</dt><dd><dl class="simple">
<dt>“Task name of {task_name} not recognized. Unable to retrieve metrics.”.format(</dt><dd><p>task_name=task_name</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
<p>)</p>
</div></blockquote>
<p>class_names = METRIC_BOOK[task_name]
if use_meta_batch:</p>
<blockquote>
<div><dl class="simple">
<dt>get_n_binary_task_metric_fn = (</dt><dd><p>get_meta_learn_single_binary_task_metric_fn
if len(class_names) == 1
else get_meta_learn_dual_binary_tasks_metric_fn</p>
</dd>
</dl>
<p>)</p>
</div></blockquote>
<dl>
<dt>else:</dt><dd><dl class="simple">
<dt>get_n_binary_task_metric_fn = (</dt><dd><p>get_single_binary_task_metric_fn if len(class_names) == 1 else get_dual_binary_tasks_metric_fn</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
<p>metric_fn = get_n_binary_task_metric_fn(metrics=None, classnames=METRIC_BOOK[task_name])</p>
<dl class="simple">
<dt>if use_stratify_metrics:</dt><dd><p>metric_fn = add_new_user_metrics(metric_fn)</p>
</dd>
</dl>
<p>return metric_fn</p>
</dd>
<dt>def flip_disliked_labels(metric_fn):</dt><dd><p>“””This function returns an adapted metric_fn which flips the labels of the OONCed evaluation data to 0 if it is disliked.
Args:</p>
<blockquote>
<div><p>metric_fn: A metric_fn function to pass in twml Trainer.</p>
</div></blockquote>
<dl class="simple">
<dt>Returns:</dt><dd><p>_adapted_metric_fn: A customized metric_fn function with disliked OONC labels flipped.</p>
</dd>
</dl>
<p>“””</p>
<dl>
<dt>def _adapted_metric_fn(graph_output, labels, weights):</dt><dd><p>“””A customized metric_fn function with disliked OONC labels flipped.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>graph_output: A dict of tensors.
labels: labels of training samples, which is a 2D tensor of shape batch_size x 3: [OONCs, engagements, dislikes]
weights: A tensor of float32 to indicate the per record weight.</p>
</dd>
<dt>Returns:</dt><dd><p>A dict of metric names and values.</p>
</dd>
</dl>
<p>“””
# We want to multiply the label of the observation by 0 only when it is disliked
disliked_mask = generate_disliked_mask(labels)</p>
<p># Extract OONC and engagement labels only.
labels = tf.reshape(labels[:, 0:2], shape=[-1, 2])</p>
<p># Labels will be set to 0 if it is disliked.
adapted_labels = labels * tf.cast(tf.logical_not(disliked_mask), dtype=labels.dtype)</p>
<p>return metric_fn(graph_output, adapted_labels, weights)</p>
</dd>
</dl>
<p>return _adapted_metric_fn</p>
</dd>
</dl>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../../index.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../../../_sources/pushservice/src/main/python/models/libs/metric_fn_utils.py.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>