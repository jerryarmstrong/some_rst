<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>from dataclasses import dataclass
from typing import Tuple</p>
<p>from tml.common.batch import DataclassBatch
from tml.common.testing_utils import mock_pg
from tml.core import train_pipeline</p>
<p>import torch
from torchrec.distributed import DistributedModelParallel</p>
<p>&#64;dataclass
class MockDataclassBatch(DataclassBatch):</p>
<blockquote>
<div><p>continuous_features: torch.Tensor
labels: torch.Tensor</p>
</div></blockquote>
<dl>
<dt>class MockModule(torch.nn.Module):</dt><dd><dl class="simple">
<dt>def __init__(self) -&gt; None:</dt><dd><p>super().__init__()
self.model = torch.nn.Linear(10, 1)
self.loss_fn = torch.nn.BCEWithLogitsLoss()</p>
</dd>
<dt>def forward(self, batch: MockDataclassBatch) -&gt; Tuple[torch.Tensor, torch.Tensor]:</dt><dd><p>pred = self.model(batch.continuous_features)
loss = self.loss_fn(pred, batch.labels)
return (loss, pred)</p>
</dd>
</dl>
</dd>
<dt>def create_batch(bsz: int):</dt><dd><dl class="simple">
<dt>return MockDataclassBatch(</dt><dd><p>continuous_features=torch.rand(bsz, 10).float(),
labels=torch.bernoulli(torch.empty(bsz, 1).uniform_(0, 1)).float(),</p>
</dd>
</dl>
<p>)</p>
</dd>
<dt>def test_sparse_pipeline():</dt><dd><p>device = torch.device(“cpu”)
model = MockModule().to(device)</p>
<p>steps = 8
example = create_batch(1)
dataloader = iter(example for _ in range(steps + 2))</p>
<p>results = []
with mock_pg():</p>
<blockquote>
<div><p>d_model = DistributedModelParallel(model)
pipeline = train_pipeline.TrainPipelineSparseDist(</p>
<blockquote>
<div><p>model=d_model,
optimizer=torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9),
device=device,
grad_accum=2,</p>
</div></blockquote>
<p>)
for _ in range(steps):</p>
<blockquote>
<div><p>results.append(pipeline.progress(dataloader))</p>
</div></blockquote>
</div></blockquote>
<p>results = [elem.detach().numpy() for elem in results]
# Check gradients are accumulated, i.e. results do not change for every 0th and 1th.
for first, second in zip(results[::2], results[1::2]):</p>
<blockquote>
<div><p>assert first == second, results</p>
</div></blockquote>
<p># Check we do update gradients, i.e. results do change for every 1th and 2nd.
for first, second in zip(results[1::2], results[2::2]):</p>
<blockquote>
<div><p>assert first != second, results</p>
</div></blockquote>
</dd>
<dt>def test_amp():</dt><dd><p>device = torch.device(“cpu”)
model = MockModule().to(device)</p>
<p>steps = 8
example = create_batch(1)
dataloader = iter(example for _ in range(steps + 2))</p>
<p>results = []
with mock_pg():</p>
<blockquote>
<div><p>d_model = DistributedModelParallel(model)
pipeline = train_pipeline.TrainPipelineSparseDist(</p>
<blockquote>
<div><p>model=d_model,
optimizer=torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9),
device=device,
enable_amp=True,
# Not supported on CPU.
enable_grad_scaling=False,</p>
</div></blockquote>
<p>)
for _ in range(steps):</p>
<blockquote>
<div><p>results.append(pipeline.progress(dataloader))</p>
</div></blockquote>
</div></blockquote>
<p>results = [elem.detach() for elem in results]
for value in results:</p>
<blockquote>
<div><p>assert value.dtype == torch.bfloat16</p>
</div></blockquote>
</dd>
</dl>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index2.rst.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index2.rst.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../_sources/core/test_train_pipeline.py.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>