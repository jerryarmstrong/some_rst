<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>import kerastuner as kt
import math
import numpy as np
import pandas as pd
import random
import sklearn.metrics
import tensorflow as tf
import os
import glob</p>
<p>from tqdm import tqdm
from matplotlib import pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from google.cloud import storage</p>
<p>physical_devices = tf.config.list_physical_devices(‘GPU’)
physical_devices</p>
<p>tf.config.set_visible_devices([tf.config.PhysicalDevice(name=’/physical_device:GPU:1’, device_type=’GPU’)], ‘GPU’)
tf.config.get_visible_devices(‘GPU’)</p>
<p>def decode_fn_embedding(example_proto):</p>
<blockquote>
<div><dl class="simple">
<dt>feature_description = {</dt><dd><p>“embedding”: tf.io.FixedLenFeature([256], dtype=tf.float32),
“labels”: tf.io.FixedLenFeature([], dtype=tf.int64),</p>
</dd>
</dl>
<p>}</p>
<dl class="simple">
<dt>example = tf.io.parse_single_example(</dt><dd><p>example_proto,
feature_description</p>
</dd>
</dl>
<p>)</p>
<p>return example</p>
</div></blockquote>
<dl>
<dt>def preprocess_embedding_example(example_dict, positive_label=1, features_as_dict=False):</dt><dd><p>labels = example_dict[“labels”]
label = tf.math.reduce_any(labels == positive_label)
label = tf.cast(label, tf.int32)
embedding = example_dict[“embedding”]</p>
<dl class="simple">
<dt>if features_as_dict:</dt><dd><p>features = {“embedding”: embedding}</p>
</dd>
<dt>else:</dt><dd><p>features = embedding</p>
</dd>
</dl>
<p>return features, label</p>
</dd>
</dl>
<p>input_root = …
sens_prev_input_root = …</p>
<p>use_sens_prev_data = True
has_validation_data = True
positive_label = 1</p>
<p>train_batch_size = 256
test_batch_size = 256
validation_batch_size = 256</p>
<p>do_resample = False
def class_func(features, label):</p>
<blockquote>
<div><p>return label</p>
</div></blockquote>
<dl class="simple">
<dt>resample_fn = tf.data.experimental.rejection_resample(</dt><dd><p>class_func, target_dist = [0.5, 0.5], seed=0</p>
</dd>
</dl>
<p>)
train_glob = f”{input_root}/train/tfrecord/<a href="#id1"><span class="problematic" id="id2">*</span></a>.tfrecord”
train_files = tf.io.gfile.glob(train_glob)</p>
<dl class="simple">
<dt>if use_sens_prev_data:</dt><dd><p>train_sens_prev_glob = f”{sens_prev_input_root}/train/tfrecord/<a href="#id3"><span class="problematic" id="id4">*</span></a>.tfrecord”
train_sens_prev_files = tf.io.gfile.glob(train_sens_prev_glob)
train_files = train_files + train_sens_prev_files</p>
</dd>
</dl>
<p>random.shuffle(train_files)</p>
<dl class="simple">
<dt>if not len(train_files):</dt><dd><p>raise ValueError(f”Did not find any train files matching {train_glob}”)</p>
</dd>
</dl>
<p>test_glob = f”{input_root}/test/tfrecord/<a href="#id5"><span class="problematic" id="id6">*</span></a>.tfrecord”
test_files =  tf.io.gfile.glob(test_glob)</p>
<dl class="simple">
<dt>if not len(test_files):</dt><dd><p>raise ValueError(f”Did not find any eval files matching {test_glob}”)</p>
</dd>
</dl>
<p>test_ds = tf.data.TFRecordDataset(test_files).map(decode_fn_embedding)
test_ds = test_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label)).batch(batch_size=test_batch_size)</p>
<dl>
<dt>if use_sens_prev_data:</dt><dd><p>test_sens_prev_glob = f”{sens_prev_input_root}/test/tfrecord/<a href="#id7"><span class="problematic" id="id8">*</span></a>.tfrecord”
test_sens_prev_files =  tf.io.gfile.glob(test_sens_prev_glob)</p>
<dl class="simple">
<dt>if not len(test_sens_prev_files):</dt><dd><p>raise ValueError(f”Did not find any eval files matching {test_sens_prev_glob}”)</p>
</dd>
</dl>
<p>test_sens_prev_ds = tf.data.TFRecordDataset(test_sens_prev_files).map(decode_fn_embedding)
test_sens_prev_ds = test_sens_prev_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label)).batch(batch_size=test_batch_size)</p>
</dd>
</dl>
<p>train_ds = tf.data.TFRecordDataset(train_files).map(decode_fn_embedding)
train_ds = train_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label))</p>
<dl class="simple">
<dt>if do_resample:</dt><dd><p>train_ds = train_ds.apply(resample_fn).map(lambda _,b:(b))</p>
</dd>
</dl>
<p>train_ds = train_ds.batch(batch_size=256).shuffle(buffer_size=10)
train_ds = train_ds.repeat()</p>
<dl>
<dt>if has_validation_data:</dt><dd><p>eval_glob = f”{input_root}/validation/tfrecord/<a href="#id9"><span class="problematic" id="id10">*</span></a>.tfrecord”
eval_files =  tf.io.gfile.glob(eval_glob)</p>
<dl class="simple">
<dt>if use_sens_prev_data:</dt><dd><p>eval_sens_prev_glob = f”{sens_prev_input_root}/validation/tfrecord/<a href="#id11"><span class="problematic" id="id12">*</span></a>.tfrecord”
eval_sens_prev_files = tf.io.gfile.glob(eval_sens_prev_glob)
eval_files =  eval_files + eval_sens_prev_files</p>
</dd>
<dt>if not len(eval_files):</dt><dd><p>raise ValueError(f”Did not find any eval files matching {eval_glob}”)</p>
</dd>
</dl>
<p>eval_ds = tf.data.TFRecordDataset(eval_files).map(decode_fn_embedding)
eval_ds = eval_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label)).batch(batch_size=validation_batch_size)</p>
</dd>
</dl>
<p>else:</p>
<blockquote>
<div><p>eval_ds = tf.data.TFRecordDataset(test_files).map(decode_fn_embedding)
eval_ds = eval_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label)).batch(batch_size=validation_batch_size)</p>
</div></blockquote>
<p>check_ds = tf.data.TFRecordDataset(train_files).map(decode_fn_embedding)
cnt = 0
pos_cnt = 0
for example in tqdm(check_ds):</p>
<blockquote>
<div><p>label = example[‘labels’]
if label == 1:</p>
<blockquote>
<div><p>pos_cnt += 1</p>
</div></blockquote>
<p>cnt += 1</p>
</div></blockquote>
<p>print(f’{cnt} train entries with {pos_cnt} positive’)</p>
<p>metrics = []</p>
<dl>
<dt>metrics.append(</dt><dd><dl class="simple">
<dt>tf.keras.metrics.PrecisionAtRecall(</dt><dd><p>recall=0.9, num_thresholds=200, class_id=None, name=None, dtype=None</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
<p>)</p>
<dl>
<dt>metrics.append(</dt><dd><dl class="simple">
<dt>tf.keras.metrics.AUC(</dt><dd><p>num_thresholds=200,
curve=”PR”,</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
<p>)
def build_model(hp):</p>
<blockquote>
<div><p>model = Sequential()</p>
<dl class="simple">
<dt>optimizer = tf.keras.optimizers.Adam(</dt><dd><p>learning_rate=0.001,
beta_1=0.9,
beta_2=0.999,
epsilon=1e-08,
amsgrad=False,
name=”Adam”,</p>
</dd>
</dl>
<p>)</p>
<p>activation=hp.Choice(“activation”, [“tanh”, “gelu”])
kernel_initializer=hp.Choice(“kernel_initializer”, [“he_uniform”, “glorot_uniform”])
for i in range(hp.Int(“num_layers”, 1, 2)):</p>
<blockquote>
<div><p>model.add(tf.keras.layers.BatchNormalization())</p>
<p>units=hp.Int(“units”, min_value=128, max_value=256, step=128)</p>
<dl>
<dt>if i == 0:</dt><dd><dl>
<dt>model.add(</dt><dd><dl class="simple">
<dt>Dense(</dt><dd><p>units=units,
activation=activation,
kernel_initializer=kernel_initializer,
input_shape=(None, 256)</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
<p>)</p>
</dd>
<dt>else:</dt><dd><dl>
<dt>model.add(</dt><dd><dl class="simple">
<dt>Dense(</dt><dd><p>units=units,
activation=activation,
kernel_initializer=kernel_initializer,</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
</div></blockquote>
<p>model.add(Dense(1, activation=’sigmoid’, kernel_initializer=kernel_initializer))
model.compile(optimizer=optimizer, loss=’binary_crossentropy’, metrics=metrics)</p>
<p>return model</p>
</div></blockquote>
<dl class="simple">
<dt>tuner = kt.tuners.BayesianOptimization(</dt><dd><p>build_model,
objective=kt.Objective(‘val_loss’, direction=”min”),
max_trials=30,
directory=’tuner_dir’,
project_name=’with_twitter_clip’)</p>
</dd>
<dt>callbacks = [tf.keras.callbacks.EarlyStopping(</dt><dd><p>monitor=’val_loss’, min_delta=0, patience=5, verbose=0,
mode=’auto’, baseline=None, restore_best_weights=True</p>
</dd>
</dl>
<p>)]</p>
<p>steps_per_epoch = 400
tuner.search(train_ds,</p>
<blockquote>
<div><p>epochs=100,
batch_size=256,
steps_per_epoch=steps_per_epoch,
verbose=2,
validation_data=eval_ds,
callbacks=callbacks)</p>
</div></blockquote>
<p>tuner.results_summary()
models = tuner.get_best_models(num_models=2)
best_model = models[0]</p>
<p>best_model.build(input_shape=(None, 256))
best_model.summary()</p>
<p>tuner.get_best_hyperparameters()[0].values</p>
<dl>
<dt>optimizer = tf.keras.optimizers.Adam(</dt><dd><blockquote>
<div><p>learning_rate=0.001,
beta_1=0.9,
beta_2=0.999,
epsilon=1e-08,
amsgrad=False,
name=”Adam”,</p>
</div></blockquote>
<p>)</p>
</dd>
</dl>
<p>best_model.compile(optimizer=optimizer, loss=’binary_crossentropy’, metrics=metrics)
best_model.summary()</p>
<dl class="simple">
<dt>callbacks = [tf.keras.callbacks.EarlyStopping(</dt><dd><p>monitor=’val_loss’, min_delta=0, patience=10, verbose=0,
mode=’auto’, baseline=None, restore_best_weights=True</p>
</dd>
</dl>
<p>)]
history = best_model.fit(train_ds, epochs=100, validation_data=eval_ds, steps_per_epoch=steps_per_epoch, callbacks=callbacks)</p>
<p>model_name = ‘twitter_hypertuned’
model_path = f’models/nsfw_Keras_with_CLIP_{model_name}’
tf.keras.models.save_model(best_model, model_path)</p>
<dl>
<dt>def copy_local_directory_to_gcs(local_path, bucket, gcs_path):</dt><dd><p>“””Recursively copy a directory of files to GCS.</p>
<p>local_path should be a directory and not have a trailing slash.
“””
assert os.path.isdir(local_path)
for local_file in glob.glob(local_path + ‘/<a href="#id13"><span class="problematic" id="id14">**</span></a>’):</p>
<blockquote>
<div><dl class="simple">
<dt>if not os.path.isfile(local_file):</dt><dd><p>dir_name = os.path.basename(os.path.normpath(local_file))
copy_local_directory_to_gcs(local_file, bucket, f”{gcs_path}/{dir_name}”)</p>
</dd>
<dt>else:</dt><dd><p>remote_path = os.path.join(gcs_path, local_file[1 + len(local_path) :])
blob = bucket.blob(remote_path)
blob.upload_from_filename(local_file)</p>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
<p>client = storage.Client(project=…)
bucket = client.get_bucket(…)
copy_local_directory_to_gcs(model_path, bucket, model_path)
copy_local_directory_to_gcs(‘tuner_dir’, bucket, ‘tuner_dir’)
loaded_model = tf.keras.models.load_model(model_path)
print(history.history.keys())</p>
<p>plt.figure(figsize = (20, 5))</p>
<p>plt.subplot(1, 3, 1)
plt.plot(history.history[‘auc’])
plt.plot(history.history[‘val_auc’])
plt.title(‘model auc’)
plt.ylabel(‘auc’)
plt.xlabel(‘epoch’)
plt.legend([‘train’, ‘test’], loc=’upper left’)</p>
<p>plt.subplot(1, 3, 2)
plt.plot(history.history[‘loss’])
plt.plot(history.history[‘val_loss’])
plt.title(‘model loss’)
plt.ylabel(‘loss’)
plt.xlabel(‘epoch’)
plt.legend([‘train’, ‘test’], loc=’upper left’)</p>
<p>plt.subplot(1, 3, 3)
plt.plot(history.history[‘precision_at_recall’])
plt.plot(history.history[‘val_precision_at_recall’])
plt.title(‘model precision at 0.9 recall’)
plt.ylabel(‘precision_at_recall’)
plt.xlabel(‘epoch’)
plt.legend([‘train’, ‘test’], loc=’upper left’)</p>
<p>plt.savefig(‘history_with_twitter_clip.pdf’)</p>
<p>test_labels = []
test_preds = []</p>
<dl class="simple">
<dt>for batch_features, batch_labels in tqdm(test_ds):</dt><dd><p>test_preds.extend(loaded_model.predict_proba(batch_features))
test_labels.extend(batch_labels.numpy())</p>
</dd>
</dl>
<p>test_sens_prev_labels = []
test_sens_prev_preds = []</p>
<dl class="simple">
<dt>for batch_features, batch_labels in tqdm(test_sens_prev_ds):</dt><dd><p>test_sens_prev_preds.extend(loaded_model.predict_proba(batch_features))
test_sens_prev_labels.extend(batch_labels.numpy())</p>
</dd>
</dl>
<p>n_test_pos = 0
n_test_neg = 0
n_test = 0</p>
<dl>
<dt>for label in test_labels:</dt><dd><p>n_test +=1
if label == 1:</p>
<blockquote>
<div><p>n_test_pos +=1</p>
</div></blockquote>
<dl class="simple">
<dt>else:</dt><dd><p>n_test_neg +=1</p>
</dd>
</dl>
</dd>
</dl>
<p>print(f’n_test = {n_test}, n_pos = {n_test_pos}, n_neg = {n_test_neg}’)</p>
<p>n_test_sens_prev_pos = 0
n_test_sens_prev_neg = 0
n_test_sens_prev = 0</p>
<dl>
<dt>for label in test_sens_prev_labels:</dt><dd><p>n_test_sens_prev +=1
if label == 1:</p>
<blockquote>
<div><p>n_test_sens_prev_pos +=1</p>
</div></blockquote>
<dl class="simple">
<dt>else:</dt><dd><p>n_test_sens_prev_neg +=1</p>
</dd>
</dl>
</dd>
</dl>
<p>print(f’n_test_sens_prev = {n_test_sens_prev}, n_pos_sens_prev = {n_test_sens_prev_pos}, n_neg = {n_test_sens_prev_neg}’)</p>
<p>test_weights = np.ones(np.asarray(test_preds).shape)</p>
<p>test_labels = np.asarray(test_labels)
test_preds = np.asarray(test_preds)
test_weights = np.asarray(test_weights)</p>
<dl class="simple">
<dt>pr = sklearn.metrics.precision_recall_curve(</dt><dd><p>test_labels,
test_preds)</p>
</dd>
</dl>
<p>auc = sklearn.metrics.auc(pr[1], pr[0])
plt.plot(pr[1], pr[0])
plt.title(“nsfw (MU test set)”)</p>
<p>test_sens_prev_weights = np.ones(np.asarray(test_sens_prev_preds).shape)</p>
<p>test_sens_prev_labels = np.asarray(test_sens_prev_labels)
test_sens_prev_preds = np.asarray(test_sens_prev_preds)
test_sens_prev_weights = np.asarray(test_sens_prev_weights)</p>
<dl class="simple">
<dt>pr_sens_prev = sklearn.metrics.precision_recall_curve(</dt><dd><p>test_sens_prev_labels,
test_sens_prev_preds)</p>
</dd>
</dl>
<p>auc_sens_prev = sklearn.metrics.auc(pr_sens_prev[1], pr_sens_prev[0])
plt.plot(pr_sens_prev[1], pr_sens_prev[0])
plt.title(“nsfw (sens prev test set)”)</p>
<dl>
<dt>df = pd.DataFrame(</dt><dd><dl class="simple">
<dt>{</dt><dd><p>“label”: test_labels.squeeze(),
“preds_keras”: np.asarray(test_preds).flatten(),</p>
</dd>
</dl>
<p>})</p>
</dd>
</dl>
<p>plt.figure(figsize=(15, 10))
df[“preds_keras”].hist()
plt.title(“Keras predictions”, size=20)
plt.xlabel(‘score’)
plt.ylabel(“freq”)</p>
<p>plt.figure(figsize = (20, 5))
plt.subplot(1, 3, 1)</p>
<p>plt.plot(pr[2], pr[0][0:-1])
plt.xlabel(“threshold”)
plt.ylabel(“precision”)</p>
<p>plt.subplot(1, 3, 2)</p>
<p>plt.plot(pr[2], pr[1][0:-1])
plt.xlabel(“threshold”)
plt.ylabel(“recall”)
plt.title(“Keras”, size=20)</p>
<p>plt.subplot(1, 3, 3)</p>
<p>plt.plot(pr[1], pr[0])
plt.xlabel(“recall”)
plt.ylabel(“precision”)</p>
<p>plt.savefig(‘with_twitter_clip.pdf’)</p>
<dl class="simple">
<dt>def get_point_for_recall(recall_value, recall, precision):</dt><dd><p>idx = np.argmin(np.abs(recall - recall_value))
return (recall[idx], precision[idx])</p>
</dd>
<dt>def get_point_for_precision(precision_value, recall, precision):</dt><dd><p>idx = np.argmin(np.abs(precision - precision_value))
return (recall[idx], precision[idx])</p>
</dd>
</dl>
<p>precision, recall, thresholds = pr</p>
<p>auc_precision_recall = sklearn.metrics.auc(recall, precision)</p>
<p>print(auc_precision_recall)</p>
<p>plt.figure(figsize=(15, 10))
plt.plot(recall, precision)</p>
<p>plt.xlabel(“recall”)
plt.ylabel(“precision”)</p>
<p>ptAt50 = get_point_for_recall(0.5, recall, precision)
print(ptAt50)
plt.plot( [ptAt50[0],ptAt50[0]], [0,ptAt50[1]], ‘r’)
plt.plot([0, ptAt50[0]], [ptAt50[1], ptAt50[1]], ‘r’)</p>
<p>ptAt90 = get_point_for_recall(0.9, recall, precision)
print(ptAt90)
plt.plot( [ptAt90[0],ptAt90[0]], [0,ptAt90[1]], ‘b’)
plt.plot([0, ptAt90[0]], [ptAt90[1], ptAt90[1]], ‘b’)</p>
<p>ptAt50fmt = “%.4f” % ptAt50[1]
ptAt90fmt = “%.4f” % ptAt90[1]
aucFmt = “%.4f” % auc_precision_recall
plt.title(</p>
<blockquote>
<div><p>f”Keras (nsfw MU test)nAUC={aucFmt}np={ptAt50fmt} &#64; r=0.5np={ptAt90fmt} &#64; r=0.9nN_train={…}} ({…} pos), N_test={n_test} ({n_test_pos} pos)”,
size=20</p>
</div></blockquote>
<p>)
plt.subplots_adjust(top=0.72)
plt.savefig(‘recall_precision_nsfw_Keras_with_twitter_CLIP_MU_test.pdf’)</p>
<p>precision, recall, thresholds = pr_sens_prev</p>
<p>auc_precision_recall = sklearn.metrics.auc(recall, precision)
print(auc_precision_recall)
plt.figure(figsize=(15, 10))</p>
<p>plt.plot(recall, precision)</p>
<p>plt.xlabel(“recall”)
plt.ylabel(“precision”)</p>
<p>ptAt50 = get_point_for_recall(0.5, recall, precision)
print(ptAt50)
plt.plot( [ptAt50[0],ptAt50[0]], [0,ptAt50[1]], ‘r’)
plt.plot([0, ptAt50[0]], [ptAt50[1], ptAt50[1]], ‘r’)</p>
<p>ptAt90 = get_point_for_recall(0.9, recall, precision)
print(ptAt90)
plt.plot( [ptAt90[0],ptAt90[0]], [0,ptAt90[1]], ‘b’)
plt.plot([0, ptAt90[0]], [ptAt90[1], ptAt90[1]], ‘b’)</p>
<p>ptAt50fmt = “%.4f” % ptAt50[1]
ptAt90fmt = “%.4f” % ptAt90[1]
aucFmt = “%.4f” % auc_precision_recall
plt.title(</p>
<blockquote>
<div><p>f”Keras (nsfw sens prev test)nAUC={aucFmt}np={ptAt50fmt} &#64; r=0.5np={ptAt90fmt} &#64; r=0.9nN_train={…} ({…} pos), N_test={n_test_sens_prev} ({n_test_sens_prev_pos} pos)”,
size=20</p>
</div></blockquote>
<p>)
plt.subplots_adjust(top=0.72)
plt.savefig(‘recall_precision_nsfw_Keras_with_twitter_CLIP_sens_prev_test.pdf’)</p>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index2.rst.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index2.rst.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../_sources/trust_and_safety_models/nsfw/nsfw_media.py.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>