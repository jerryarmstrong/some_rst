<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p># Navi: High-Performance Machine Learning Serving Server in Rust</p>
<p>Navi is a high-performance, versatile machine learning serving server implemented in Rust and tailored for production usage. It’s designed to efficiently serve within the Twitter tech stack, offering top-notch performance while focusing on core features.</p>
<p>## Key Features</p>
<ul class="simple">
<li><p><strong>Minimalist Design Optimized for Production Use Cases</strong>: Navi delivers ultra-high performance, stability, and availability, engineered to handle real-world application demands with a streamlined codebase.</p></li>
<li><p><strong>gRPC API Compatibility with TensorFlow Serving</strong>: Seamless integration with existing TensorFlow Serving clients via its gRPC API, enabling easy integration, smooth deployment, and scaling in production environments.</p></li>
<li><p><strong>Plugin Architecture for Different Runtimes</strong>: Navi’s pluggable architecture supports various machine learning runtimes, providing adaptability and extensibility for diverse use cases. Out-of-the-box support is available for TensorFlow and Onnx Runtime, with PyTorch in an experimental state.</p></li>
</ul>
<p>## Current State</p>
<p>While Navi’s features may not be as comprehensive as its open-source counterparts, its performance-first mindset makes it highly efficient.
- Navi for TensorFlow is currently the most feature-complete, supporting multiple input tensors of different types (float, int, string, etc.).
- Navi for Onnx primarily supports one input tensor of type string, used in Twitter’s home recommendation with a proprietary BatchPredictRequest format.
- Navi for Pytorch is compilable and runnable but not yet production-ready in terms of performance and stability.</p>
<p>## Directory Structure</p>
<ul class="simple">
<li><p><cite>navi</cite>: The main code repository for Navi</p></li>
<li><p><cite>dr_transform</cite>: Twitter-specific converter that converts BatchPredictionRequest Thrift to ndarray</p></li>
<li><p><cite>segdense</cite>: Twitter-specific config to specify how to retrieve feature values from BatchPredictionRequest</p></li>
<li><p><cite>thrift_bpr_adapter</cite>: generated thrift code for BatchPredictionRequest</p></li>
</ul>
<p>## Content
We have included all <a href="#id1"><span class="problematic" id="id2">*</span></a>.rs source code files that make up the main Navi binaries for you to examine. However, we have not included the test and benchmark code, or various configuration files, due to data security concerns.</p>
<p>## Run
In navi/navi, you can run the following commands:
- <cite>scripts/run_tf2.sh</cite> for [TensorFlow](<a class="reference external" href="https://www.tensorflow.org/">https://www.tensorflow.org/</a>)
- <cite>scripts/run_onnx.sh</cite> for [Onnx](<a class="reference external" href="https://onnx.ai/">https://onnx.ai/</a>)</p>
<p>Do note that you need to create a models directory and create some versions, preferably using epoch time, e.g., <cite>1679693908377</cite>.
so the models structure looks like:</p>
<blockquote>
<div><dl>
<dt>models/</dt><dd><dl class="option-list">
<dt><kbd><span class="option">-w<var>eb_click</var></span></kbd></dt>
<dd><ul class="simple">
<li><p>1809000</p></li>
<li><p>1809010</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<p>## Build
You can adapt the above scripts to build using Cargo.</p>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../_sources/navi/README.md.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>