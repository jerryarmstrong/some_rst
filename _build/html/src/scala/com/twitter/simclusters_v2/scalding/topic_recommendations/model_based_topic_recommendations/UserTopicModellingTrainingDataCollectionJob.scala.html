<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../../../../../" id="documentation_options" src="../../../../../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>package com.twitter.simclusters_v2.scalding.topic_recommendations.model_based_topic_recommendations</p>
<p>import com.twitter.algebird.Monoid
import com.twitter.bijection.Injection
import com.twitter.dal.client.dataset.SnapshotDALDatasetBase
import com.twitter.ml.api.DataRecord
import com.twitter.ml.api._
import com.twitter.scalding.TypedPipe
import com.twitter.scalding._
import com.twitter.scalding_internal.dalv2.DALWrite.D
import com.twitter.scalding_internal.dalv2.dataset.DALWrite._
import com.twitter.simclusters_v2.common.Country
import com.twitter.simclusters_v2.common.Language
import com.twitter.simclusters_v2.common.TopicId
import com.twitter.simclusters_v2.common.UserId
import com.twitter.wtf.scalding.jobs.common.AdhocExecutionApp
import com.twitter.wtf.scalding.jobs.common.ScheduledExecutionApp
import java.util.TimeZone
import scala.util.Random
import com.twitter.ml.api.util.FDsl._
import com.twitter.scalding.source.DailySuffixCsv
import com.twitter.scalding.source.DailySuffixTypedTsv
import com.twitter.simclusters_v2.hdfs_sources.FavTfgTopicEmbeddingsScalaDataset
import com.twitter.simclusters_v2.scalding.embedding.common.ExternalDataSources
import com.twitter.simclusters_v2.thriftscala.EmbeddingType</p>
<dl class="simple">
<dt>/**</dt><dd><p>This job is to obtain the training and test data for the model-based approach to topic recommendations:
Approach:
1. Read FavTfgTopicEmbeddingsScalaDataset - to get topic simclusters embeddings for the followed and not interested in topics
2. Read SimclustersV2InterestedIn20M145KUpdatedScalaDataset - to get user’s interestedIn Simclusters embeddings
3. Read UsersourceScalaDataset - to get user’s countryCode and language
Use the datasets above to get the features for the model and generate DataRecords.
<a href="#id1"><span class="problematic" id="id2">*</span></a>/</p>
</dd>
</dl>
<p>/*
To run:
scalding remote run –target src/scala/com/twitter/simclusters_v2/scalding/topic_recommendations/model_based_topic_recommendations:training_data_for_topic_recommendations-adhoc –user cassowary –submitter atla-aor-08-sr1 –main-class com.twitter.simclusters_v2.scalding.topic_recommendations.model_based_topic_recommendations.UserTopicFeatureHydrationAdhocApp –submitter-memory 128192.megabyte –hadoop-properties “mapreduce.map.memory.mb=8192 mapreduce.map.java.opts=’-Xmx7618M’ mapreduce.reduce.memory.mb=8192 mapreduce.reduce.java.opts=’-Xmx7618M’” – –date 2020-10-14 –outputDir “/user/cassowary/adhoc/your_ldap/user_topic_features_popular_clusters_filtered_oct_16”</p>
<blockquote>
<div><p><a href="#id3"><span class="problematic" id="id4">*</span></a>/</p>
</div></blockquote>
<p>object UserTopicFeatureHydrationAdhocApp extends AdhocExecutionApp {</p>
<blockquote>
<div><p>import UserTopicModellingJobUtils._</p>
<dl class="simple">
<dt>override def runOnDateRange(</dt><dd><p>args: Args</p>
</dd>
<dt>)(</dt><dd><p>implicit dateRange: DateRange,
timeZone: TimeZone,
uniqueID: UniqueID</p>
</dd>
</dl>
<p>): Execution[Unit] = {</p>
<blockquote>
<div><p>val outputDir = args(“outputDir”)
val numDataRecordsTraining = Stat(“num_data_records_training”)
val numDataRecordsTesting = Stat(“num_data_records_testing”)
val testingRatio = args.double(“testingRatio”, 0.2)</p>
<dl class="simple">
<dt>val (trainingDataSamples, testDataSamples, sortedVocab) = UserTopicModellingJobUtils.run(</dt><dd><p>ExternalDataSources.topicFollowGraphSource,
ExternalDataSources.notInterestedTopicsSource,
ExternalDataSources.userSource,
DataSources.getUserInterestedInData,
DataSources.getPerLanguageTopicEmbeddings,
testingRatio</p>
</dd>
</dl>
<p>)</p>
<p>val userTopicAdapter = new UserTopicDataRecordAdapter()
Execution</p>
<blockquote>
<div><dl>
<dt>.zip(</dt><dd><dl>
<dt>convertTypedPipeToDataSetPipe(</dt><dd><dl class="simple">
<dt>trainingDataSamples.map { train =&gt;</dt><dd><p>numDataRecordsTraining.inc()
train</p>
</dd>
</dl>
<p>},
userTopicAdapter)
.writeExecution(</p>
<blockquote>
<div><p>DailySuffixFeatureSink(outputDir + “/training”)</p>
</div></blockquote>
<p>),</p>
</dd>
<dt>convertTypedPipeToDataSetPipe(</dt><dd><dl class="simple">
<dt>testDataSamples.map { test =&gt;</dt><dd><p>numDataRecordsTesting.inc()
test</p>
</dd>
</dl>
<p>},
userTopicAdapter)
.writeExecution(</p>
<blockquote>
<div><p>DailySuffixFeatureSink(outputDir + “/testing”)</p>
</div></blockquote>
<p>),</p>
</dd>
<dt>sortedVocab</dt><dd><dl class="simple">
<dt>.map { topicsWithSortedIndexes =&gt;</dt><dd><p>topicsWithSortedIndexes.map(_._1)</p>
</dd>
</dl>
<p>}.flatten.writeExecution(DailySuffixTypedTsv(outputDir + “/vocab”))</p>
</dd>
</dl>
</dd>
</dl>
<p>).unit</p>
</div></blockquote>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>}</p>
<p>/**
capesospy-v2 update –build_locally </p>
<blockquote>
<div><p>–start_cron training_data_for_topic_recommendations src/scala/com/twitter/simclusters_v2/capesos_config/atla_proc3.yaml
<a href="#id5"><span class="problematic" id="id6">*</span></a>/</p>
</div></blockquote>
<p>object UserTopicFeatureHydrationScheduledApp extends ScheduledExecutionApp {</p>
<blockquote>
<div><p>import UserTopicModellingJobUtils._</p>
<dl class="simple">
<dt>private val outputPath: String =</dt><dd><p>“/user/cassowary/processed/user_topic_modelling”</p>
</dd>
</dl>
<p>override def batchIncrement: Duration = Days(1)</p>
<p>override def firstTime: RichDate = RichDate(“2020-10-13”)</p>
<dl>
<dt>override def runOnDateRange(</dt><dd><p>args: Args</p>
</dd>
<dt>)(</dt><dd><p>implicit dateRange: DateRange,
timeZone: TimeZone,
uniqueID: UniqueID</p>
</dd>
<dt>): Execution[Unit] = {</dt><dd><p>val testingRatio = args.double(“testingRatio”, 0.2)</p>
<dl class="simple">
<dt>val (trainingDataSamples, testDataSamples, sortedVocab) = UserTopicModellingJobUtils.run(</dt><dd><p>ExternalDataSources.topicFollowGraphSource,
ExternalDataSources.notInterestedTopicsSource,
ExternalDataSources.userSource,
DataSources.getUserInterestedInData,
DataSources.getPerLanguageTopicEmbeddings,
testingRatio</p>
</dd>
</dl>
<p>)</p>
<p>val userTopicAdapter = new UserTopicDataRecordAdapter()
Execution</p>
<blockquote>
<div><dl>
<dt>.zip(</dt><dd><dl class="simple">
<dt>getTrainTestExec(</dt><dd><p>trainingDataSamples,
testDataSamples,
TopicRecommendationsTrainDatarecordsJavaDataset,
TopicRecommendationsTestDatarecordsJavaDataset,
outputPath,
userTopicAdapter</p>
</dd>
</dl>
<p>),
sortedVocab</p>
<blockquote>
<div><dl class="simple">
<dt>.map { topicsWithSortedIndexes =&gt;</dt><dd><p>topicsWithSortedIndexes.map(_._1)</p>
</dd>
</dl>
<p>}.flatten.writeExecution(DailySuffixTypedTsv(outputPath + “/vocab”))</p>
</div></blockquote>
</dd>
</dl>
<p>).unit</p>
</div></blockquote>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
<p>object UserTopicModellingJobUtils {</p>
<blockquote>
<div><dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>The main function that produces training and the test data</p></li>
<li></li>
<li><p>&#64;param topicFollowGraphSource user with followed topics from TFG</p></li>
<li><p>&#64;param notInterestedTopicsSource  user with not interested in topics</p></li>
<li><p>&#64;param userSource user with country and language</p></li>
<li><p>&#64;param userInterestedInData user with interestedin simcluster embeddings</p></li>
<li><p>&#64;param topicPerLanguageEmbeddings topics with simcluster embeddings</p></li>
<li></li>
<li><p>&#64;return Tuple (trainingDataSamples, testingDataSamples, sortedTopicsVocab)</p></li>
</ul>
<p><a href="#id7"><span class="problematic" id="id8">*</span></a>/</p>
</dd>
<dt>def run(</dt><dd><p>topicFollowGraphSource: TypedPipe[(TopicId, UserId)],
notInterestedTopicsSource: TypedPipe[(TopicId, UserId)],
userSource: TypedPipe[(UserId, (Country, Language))],
userInterestedInData: TypedPipe[(UserId, Map[Int, Double])],
topicPerLanguageEmbeddings: TypedPipe[((TopicId, Language), Map[Int, Double])],
testingRatio: Double</p>
</dd>
<dt>)(</dt><dd><p>implicit uniqueID: UniqueID,
dateRange: DateRange,
timeZone: TimeZone</p>
</dd>
<dt>): (</dt><dd><p>TypedPipe[UserTopicTrainingSample],
TypedPipe[UserTopicTrainingSample],
TypedPipe[Seq[(TopicId, Int)]]</p>
</dd>
<dt>) = {</dt><dd><dl>
<dt>val allFollowableTopics: TypedPipe[TopicId] =</dt><dd><p>topicFollowGraphSource.map(_._1).distinct</p>
</dd>
<dt>val allFollowableTopicsWithMappedIds: TypedPipe[(TopicId, Int)] =</dt><dd><dl>
<dt>allFollowableTopics.groupAll.mapGroup {</dt><dd><dl>
<dt>case (_, topicIter) =&gt;</dt><dd><dl class="simple">
<dt>topicIter.zipWithIndex.map {</dt><dd><dl class="simple">
<dt>case (topicId, mappedId) =&gt;</dt><dd><p>(topicId, mappedId)</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
<p>}.values</p>
</dd>
<dt>val sortedVocab: TypedPipe[Seq[(TopicId, Int)]] =</dt><dd><p>allFollowableTopicsWithMappedIds.map(Seq(_)).map(_.sortBy(_._2))</p>
</dd>
<dt>val dataTrainingSamples: TypedPipe[UserTopicTrainingSample] = getDataSamplesFromTrainingData(</dt><dd><p>topicFollowGraphSource,
notInterestedTopicsSource,
userSource,
userInterestedInData,
topicPerLanguageEmbeddings,
allFollowableTopicsWithMappedIds</p>
</dd>
</dl>
<p>)
val (trainSplit, testSplit) = splitByUser(dataTrainingSamples, testingRatio)</p>
<p>(trainSplit, testSplit, sortedVocab)</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Split the data samples based on user_id into train and test data. This ensures that the same</p></li>
<li><p>user’s data records are not part of both train and test data.</p></li>
</ul>
<p><a href="#id9"><span class="problematic" id="id10">*</span></a>/</p>
</dd>
<dt>def splitByUser(</dt><dd><p>dataTrainingSamples: TypedPipe[UserTopicTrainingSample],
testingRatio: Double</p>
</dd>
<dt>): (TypedPipe[UserTopicTrainingSample], TypedPipe[UserTopicTrainingSample]) = {</dt><dd><dl class="simple">
<dt>val (trainSplit, testSplit) = dataTrainingSamples</dt><dd><dl class="simple">
<dt>.map { currSmple =&gt; (currSmple.userId, currSmple) }.groupBy(_._1).partition(_ =&gt;</dt><dd><p>Random.nextDouble() &gt; testingRatio)</p>
</dd>
</dl>
</dd>
</dl>
<p>val trainingData = trainSplit.values.map(_._2)
val testingData = testSplit.values.map(_._2)
(trainingData, testingData)</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>To get the target topic for each training data sample for a user from the TopicFollowGraph</p></li>
<li></li>
<li><p>&#64;param topicFollowSource</p></li>
<li><p>&#64;return (UserId, Set(allFollowedTopicsExceptTargetTopic), targetTopic)</p></li>
</ul>
<p><a href="#id11"><span class="problematic" id="id12">*</span></a>/</p>
</dd>
<dt>def getTargetTopicsFromTFG(</dt><dd><p>topicFollowSource: TypedPipe[(TopicId, UserId)]</p>
</dd>
<dt>)(</dt><dd><p>implicit uniqueID: UniqueID</p>
</dd>
<dt>): TypedPipe[(UserId, Set[TopicId], TopicId)] = {</dt><dd><p>val numTrainingSamples = Stat(“num_positive_training_samples”)</p>
<dl>
<dt>val userFollowedTopics = topicFollowSource.swap</dt><dd><dl class="simple">
<dt>.map {</dt><dd><p>case (userId, topicId) =&gt; (userId, Set(topicId))</p>
</dd>
</dl>
<p>}.sumByKey.toTypedPipe</p>
</dd>
<dt>userFollowedTopics.flatMap {</dt><dd><dl>
<dt>case (userID, followedTopicsSet) =&gt;</dt><dd><dl class="simple">
<dt>followedTopicsSet.map { currFollowedTopic =&gt;</dt><dd><p>numTrainingSamples.inc()
val remainingTopics = followedTopicsSet - currFollowedTopic
(userID, remainingTopics, currFollowedTopic)</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Helper function that does the intermediate join operation between a user’s followed,</p></li>
<li><p>not-interested, interestedIn, country and language typedpipe sources, read from different sources.</p></li>
</ul>
<p><a href="#id13"><span class="problematic" id="id14">*</span></a>/</p>
</dd>
<dt>def getFeaturesIntermediateJoin(</dt><dd><p>topicFollowGraphSource: TypedPipe[(TopicId, UserId)],
notInterestedTopicsSource: TypedPipe[(TopicId, UserId)],
allFollowableTopicsWithMappedIds: TypedPipe[(TopicId, Int)],
userCountryAndLanguage: TypedPipe[(UserId, (Country, Language))],
userInterestedInData: TypedPipe[(UserId, Map[Int, Double])]</p>
</dd>
<dt>)(</dt><dd><p>implicit uniqueID: UniqueID</p>
</dd>
<dt>): TypedPipe[</dt><dd><dl class="simple">
<dt>(</dt><dd><p>UserId,
Set[TopicId],
Set[TopicId],
TopicId,
Int,
Country,
Language,
Map[Int, Double]</p>
</dd>
</dl>
<p>)</p>
</dd>
<dt>] = {</dt><dd><p>implicit val l2b: Long =&gt; Array[Byte] = Injection.long2BigEndian</p>
<dl class="simple">
<dt>val userWithFollowedTargetTopics: TypedPipe[</dt><dd><p>(UserId, Set[TopicId], TopicId)</p>
</dd>
</dl>
<p>] = getTargetTopicsFromTFG(topicFollowGraphSource)</p>
<dl>
<dt>val userWithNotInterestedTopics: TypedPipe[(UserId, Set[TopicId])] =</dt><dd><p>notInterestedTopicsSource.swap.mapValues(Set(_)).sumByKey.toTypedPipe</p>
</dd>
<dt>userWithFollowedTargetTopics</dt><dd><dl class="simple">
<dt>.groupBy(_._1).leftJoin(userWithNotInterestedTopics).values.map {</dt><dd><dl class="simple">
<dt>case ((userId, followedTopics, targetFollowedTopic), notInterestedOpt) =&gt;</dt><dd><dl class="simple">
<dt>(</dt><dd><p>userId,
followedTopics,
targetFollowedTopic,
notInterestedOpt.getOrElse(Set.empty[TopicId]))</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>}
.map {</p>
<blockquote>
<div><dl class="simple">
<dt>case (userId, followedTopics, targetFollowedTopic, notInterestedTopics) =&gt;</dt><dd><p>(targetFollowedTopic, (userId, followedTopics, notInterestedTopics))</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>}.join(allFollowableTopicsWithMappedIds).map {</dt><dd><dl class="simple">
<dt>case (targetTopic, ((userId, followedTopics, notInterestedTopics), targetTopicIdx)) =&gt;</dt><dd><p>(userId, followedTopics, notInterestedTopics, targetTopic, targetTopicIdx)</p>
</dd>
</dl>
</dd>
</dl>
<p>}
.groupBy(_._1).sketch(4000)
.join(userCountryAndLanguage</p>
<blockquote>
<div><p>.groupBy(_._1)).sketch(4000).leftJoin(userInterestedInData)</p>
</div></blockquote>
<dl>
<dt>.values.map {</dt><dd><dl>
<dt>case (</dt><dd><blockquote>
<div><dl class="simple">
<dt>(</dt><dd><p>(userId, followedTopics, notInterestedTopics, targetTopic, targetTopicIdx),
(_, (userCountry, userLanguage))</p>
</dd>
</dl>
<p>),
userIntOpt) =&gt;</p>
</div></blockquote>
<dl class="simple">
<dt>(</dt><dd><p>userId,
followedTopics,
notInterestedTopics,
targetTopic,
targetTopicIdx,
userCountry,
userLanguage,
userIntOpt.getOrElse(Map.empty))</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Helper function that aggregates user’s followed topics, not-interested topics,</p></li>
<li><p>country, language with join operations and generates the UserTopicTrainingSample</p></li>
<li><p>for each DataRecord</p></li>
</ul>
<p><a href="#id15"><span class="problematic" id="id16">*</span></a>/</p>
</dd>
<dt>def getDataSamplesFromTrainingData(</dt><dd><p>topicFollowGraphSource: TypedPipe[(TopicId, UserId)],
notInterestedTopicsSource: TypedPipe[(TopicId, UserId)],
userCountryAndLanguage: TypedPipe[(UserId, (Country, Language))],
userInterestedInData: TypedPipe[(UserId, Map[Int, Double])],
topicPerLanguageEmbeddings: TypedPipe[((TopicId, Language), Map[Int, Double])],
allFollowableTopicsWithMappedIds: TypedPipe[(TopicId, Int)]</p>
</dd>
<dt>)(</dt><dd><p>implicit uniqueID: UniqueID</p>
</dd>
</dl>
<p>): TypedPipe[UserTopicTrainingSample] = {</p>
<blockquote>
<div><p>implicit val l2b: Long =&gt; Array[Byte] = Injection.long2BigEndian</p>
<dl>
<dt>val allTopicEmbeddingsMap: ValuePipe[Map[(TopicId, Language), Map[Int, Double]]] =</dt><dd><dl class="simple">
<dt>topicPerLanguageEmbeddings.map {</dt><dd><dl class="simple">
<dt>case (topicWithLang, embedding) =&gt;</dt><dd><p>Map(topicWithLang -&gt; embedding)</p>
</dd>
</dl>
</dd>
</dl>
<p>}.sum</p>
</dd>
<dt>val userWithFollowedAndNotInterestedTopics = getFeaturesIntermediateJoin(</dt><dd><p>topicFollowGraphSource,
notInterestedTopicsSource,
allFollowableTopicsWithMappedIds,
userCountryAndLanguage,
userInterestedInData)</p>
</dd>
<dt>userWithFollowedAndNotInterestedTopics.flatMapWithValue(allTopicEmbeddingsMap) {</dt><dd><dl>
<dt>case (</dt><dd><blockquote>
<div><dl class="simple">
<dt>(</dt><dd><p>userId,
followedTopics,
notInterestedTopics,
targetTopic,
targetTopicIdx,
userCountry,
userLanguage,
userInt),</p>
</dd>
</dl>
<p>Some(allTopicEmbeddings)) =&gt;</p>
</div></blockquote>
<dl>
<dt>val averageFollowedTopicsSimClusters = Monoid</dt><dd><dl class="simple">
<dt>.sum(followedTopics.toSeq.map { topicId =&gt;</dt><dd><p>allTopicEmbeddings.getOrElse((topicId, userLanguage), Map.empty)</p>
</dd>
<dt>}).mapValues(v =&gt;</dt><dd><p>v / followedTopics.size) // average simcluster embedding of the followed topics</p>
</dd>
</dl>
</dd>
<dt>val averageNotInterestedTopicsSimClusters = Monoid</dt><dd><dl class="simple">
<dt>.sum(notInterestedTopics.toSeq.map { topicId =&gt;</dt><dd><p>allTopicEmbeddings.getOrElse((topicId, userLanguage), Map.empty)</p>
</dd>
<dt>}).mapValues(v =&gt;</dt><dd><p>v / notInterestedTopics.size) // average simcluster embedding of the notInterested topics</p>
</dd>
</dl>
</dd>
<dt>Some(</dt><dd><dl class="simple">
<dt>UserTopicTrainingSample(</dt><dd><p>userId,
followedTopics,
notInterestedTopics,
userCountry,
userLanguage,
targetTopicIdx,
userInt,
averageFollowedTopicsSimClusters,
averageNotInterestedTopicsSimClusters</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
<p>)</p>
</dd>
<dt>case _ =&gt;</dt><dd><p>None</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Write train and test data</p></li>
</ul>
<p><a href="#id17"><span class="problematic" id="id18">*</span></a>/</p>
</dd>
<dt>def getTrainTestExec(</dt><dd><p>trainingData: TypedPipe[UserTopicTrainingSample],
testingData: TypedPipe[UserTopicTrainingSample],
trainDataset: SnapshotDALDatasetBase[DataRecord],
testDataset: SnapshotDALDatasetBase[DataRecord],
outputPath: String,
adapter: IRecordOneToOneAdapter[UserTopicTrainingSample]</p>
</dd>
<dt>)(</dt><dd><p>implicit dateRange: DateRange</p>
</dd>
<dt>): Execution[Unit] = {</dt><dd><dl class="simple">
<dt>val trainExec =</dt><dd><dl class="simple">
<dt>convertTypedPipeToDataSetPipe(trainingData, adapter)</dt><dd><dl class="simple">
<dt>.writeDALSnapshotExecution(</dt><dd><p>trainDataset,
D.Daily,
D.Suffix(s”$outputPath/training”),
D.EBLzo(),
dateRange.end)</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt>val testExec =</dt><dd><dl class="simple">
<dt>convertTypedPipeToDataSetPipe(testingData, adapter)</dt><dd><dl class="simple">
<dt>.writeDALSnapshotExecution(</dt><dd><p>testDataset,
D.Daily,
D.Suffix(s”$outputPath/testing”),
D.EBLzo(),
dateRange.end)</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>Execution.zip(trainExec, testExec).unit</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>To get the datasetPipe containing datarecords hydrated by datarecordAdapter</p></li>
<li><p>&#64;param userTrainingSamples</p></li>
<li><p>&#64;param adapter</p></li>
<li><p>&#64;return DataSetPipe</p></li>
</ul>
<p><a href="#id19"><span class="problematic" id="id20">*</span></a>/</p>
</dd>
<dt>def convertTypedPipeToDataSetPipe(</dt><dd><p>userTrainingSamples: TypedPipe[UserTopicTrainingSample],
adapter: IRecordOneToOneAdapter[UserTopicTrainingSample]</p>
</dd>
<dt>): DataSetPipe = {</dt><dd><p>userTrainingSamples.toDataSetPipe(adapter)</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../../../../index2.rst.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../../../../index2.rst.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../../../../../_sources/src/scala/com/twitter/simclusters_v2/scalding/topic_recommendations/model_based_topic_recommendations/UserTopicModellingTrainingDataCollectionJob.scala.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>