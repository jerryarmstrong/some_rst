<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../../../../" id="documentation_options" src="../../../../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>package com.twitter.simclusters_v2.scalding.tweet_similarity</p>
<p>import com.twitter.dal.client.dataset.TimePartitionedDALDataset
import com.twitter.ml.api.DataRecord
import com.twitter.ml.api.DataSetPipe
import com.twitter.scalding._
import com.twitter.scalding.typed.TypedPipe
import com.twitter.scalding_internal.dalv2.DAL
import com.twitter.scalding_internal.dalv2.remote_access.ExplicitLocation
import com.twitter.scalding_internal.dalv2.remote_access.Proc3Atla
import com.twitter.scalding_internal.job.TwitterExecutionApp
import com.twitter.simclusters_v2.hdfs_sources.TweetSimilarityUnhydratedPairsSource
import com.twitter.simclusters_v2.scalding.common.LogFavBasedPersistentTweetEmbeddingMhExportSource
import com.twitter.simclusters_v2.scalding.tweet_similarity.TweetPairLabelCollectionUtil.FeaturedTweet
import com.twitter.simclusters_v2.thriftscala.LabelledTweetPairs
import com.twitter.wtf.scalding.jobs.common.ScheduledExecutionApp
import java.util.TimeZone</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Hydrate tweet pairs with features</p></li>
</ul>
<p><a href="#id1"><span class="problematic" id="id2">*</span></a>/</p>
</dd>
<dt>object TrainingDataCollectionJob {</dt><dd><p>val LookbackDays = 2 //lookbackdays considered when looking for author information
val testLookbackHours = 2 //hours in test dataset if doing time-based train/test split
val testRatio = 0.1 //ratio for test dataset if doing query-based train/test split</p>
<dl class="simple">
<dt>def getHydratedDataPipe(</dt><dd><p>dateRange: DateRange,
useAuthorFeatures: Boolean,
unhydratedPairs: TypedPipe[LabelledTweetPairs]</p>
</dd>
<dt>)(</dt><dd><p>implicit timeZone: TimeZone</p>
</dd>
</dl>
<p>): DataSetPipe = {</p>
<blockquote>
<div><dl>
<dt>val persistentEmbeddingRecords =</dt><dd><p>TypedPipe.from(new LogFavBasedPersistentTweetEmbeddingMhExportSource(range = dateRange))</p>
</dd>
<dt>val tweetAuthorPairs =</dt><dd><p>TweetPairLabelCollectionUtil.getTweetAuthorPairs(dateRange.prepend(Days(LookbackDays)))</p>
</dd>
<dt>val labelledPairs = unhydratedPairs</dt><dd><dl>
<dt>.map { labelledPair =&gt;</dt><dd><dl>
<dt>(</dt><dd><dl class="simple">
<dt>FeaturedTweet(</dt><dd><p>labelledPair.queryFeaturedTweet.tweetId,
labelledPair.queryFeaturedTweet.timestamp,
None,
None),</p>
</dd>
<dt>FeaturedTweet(</dt><dd><p>labelledPair.candidateFeaturedTweet.tweetId,
labelledPair.candidateFeaturedTweet.timestamp,
None,
None),</p>
</dd>
</dl>
<p>labelledPair.label</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>TweetPairFeatureHydrationUtil.getDataSetPipeWithFeatures(</dt><dd><p>labelledPairs,
persistentEmbeddingRecords,
tweetAuthorPairs,
useAuthorFeatures)</p>
</dd>
</dl>
</div></blockquote>
<p>}</p>
<dl>
<dt>def getTrainTestExec(</dt><dd><p>dataSetPipe: DataSetPipe,
splitBy: Option[String],
trainDataset: TimePartitionedDALDataset[DataRecord],
testDataset: TimePartitionedDALDataset[DataRecord],
outputPath: String</p>
</dd>
<dt>)(</dt><dd><p>implicit timeZone: TimeZone,
dateRange: DateRange</p>
</dd>
<dt>): Execution[Unit] = {</dt><dd><dl>
<dt>splitBy match {</dt><dd><dl class="simple">
<dt>case Some(“time”) =&gt;</dt><dd><dl class="simple">
<dt>TrainingDataCollectionUtil.getTrainTestByTimeExec(</dt><dd><p>dataSetPipe,
dateRange.end - Hours(testLookbackHours),
trainDataset,
testDataset,
outputPath)(dateRange)</p>
</dd>
</dl>
</dd>
<dt>case Some(“query_tweet”) =&gt;</dt><dd><dl class="simple">
<dt>TrainingDataCollectionUtil.getTrainTestByQueryExec(</dt><dd><p>dataSetPipe,
testRatio,
trainDataset,
testDataset,
outputPath)(dateRange)</p>
</dd>
</dl>
</dd>
</dl>
<p>// Default at no splitting
case _ =&gt;</p>
<blockquote>
<div><dl class="simple">
<dt>TrainingDataCollectionUtil.getTrainTestByQueryExec(</dt><dd><p>dataSetPipe,
0.0,
trainDataset,
testDataset,
outputPath)(dateRange)</p>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<p>/** To run:
scalding remote run –target src/scala/com/twitter/simclusters_v2/scalding/tweet_similarity:training_data_collection-adhoc –user cassowary –submitter hadoopnest2.atla.twitter.com –hadoop-properties “mapreduce.reduce.java.opts=-Xmx8000m mapreduce.reduce.memory.mb=8000 scalding.with.reducers.set.explicitly=true mapreduce.job.reduces=2000 mapreduce.task.timeout=0” –main-class com.twitter.simclusters_v2.scalding.tweet_similarity.TrainingDataCollectionAdhocApp – –date 2020-04-15 –input_path /user/cassowary/adhoc/unhydrated_pairs/2020-04-15_30min/ –output_path /user/cassowary/adhoc/training_data/2020-04-15_30min_2xneg_qtweet_split –split_by query_tweet</p>
<blockquote>
<div><ul class="simple">
<li><p><a href="#id3"><span class="problematic" id="id4">*</span></a>/</p></li>
</ul>
</div></blockquote>
<dl>
<dt>object TrainingDataCollectionAdhocApp extends TwitterExecutionApp {</dt><dd><p>implicit val timeZone: TimeZone = DateOps.UTC
implicit val dateParser: DateParser = DateParser.default</p>
<dl>
<dt>override def job: Execution[Unit] =</dt><dd><dl>
<dt>Execution.withId { implicit uniqueId =&gt;</dt><dd><dl>
<dt>Execution.withArgs { args: Args =&gt;</dt><dd><p>implicit val dateRange: DateRange = DateRange.parse(args.list(“date”))
val useAuthorFeatures: Boolean = args.boolean(“use_author_features”)
val inputPath: String = args(“input_path”)
val outputPath: String = args(“output_path”)
val splitBy: Option[String] = args.optional(“split_by”)</p>
<dl class="simple">
<dt>val labelledPairs = TypedPipe</dt><dd><p>.from(TweetSimilarityUnhydratedPairsSource(inputPath, dateRange))</p>
</dd>
<dt>val dataSetPipe = TrainingDataCollectionJob.getHydratedDataPipe(</dt><dd><p>dateRange,
useAuthorFeatures,
labelledPairs</p>
</dd>
</dl>
<p>)
TrainingDataCollectionJob.getTrainTestExec(</p>
<blockquote>
<div><p>dataSetPipe,
splitBy,
TweetSimilarityTrainDatarecords30MinJavaDataset,
TweetSimilarityTestDatarecords30MinJavaDataset,
outputPath</p>
</div></blockquote>
<p>)</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><blockquote>
<div><p>capesospy-v2 update –build_locally –start_cron training_data_collection_30min src/scala/com/twitter/simclusters_v2/capesos_config/atla_proc3.yaml</p>
</div></blockquote>
<p><a href="#id5"><span class="problematic" id="id6">*</span></a>/</p>
</dd>
</dl>
<p>object TrainingDataCollection30MinScheduledApp extends ScheduledExecutionApp {</p>
<blockquote>
<div><dl class="simple">
<dt>private val outputPath: String =</dt><dd><p>“/user/cassowary/processed/tweet_similarity/training_data_30min”</p>
</dd>
</dl>
<p>override def batchIncrement: Duration = Hours(24)</p>
<p>override def firstTime: RichDate = RichDate(“2020-03-26”)</p>
<dl>
<dt>override def runOnDateRange(</dt><dd><p>args: Args</p>
</dd>
<dt>)(</dt><dd><p>implicit dateRange: DateRange,
timeZone: TimeZone,
uniqueID: UniqueID</p>
</dd>
<dt>): Execution[Unit] = {</dt><dd><p>val useAuthorFeatures: Boolean = args.boolean(“use_author_features”)
val splitBy: Option[String] = args.optional(“split_by”)</p>
<dl class="simple">
<dt>val unhydratedPairs = DAL</dt><dd><p>.read(TweetSimilarityUnhydratedPairs30MinScalaDataset, dateRange)
.withRemoteReadPolicy(ExplicitLocation(Proc3Atla))
.toTypedPipe</p>
</dd>
<dt>val dataSetPipe = TrainingDataCollectionJob.getHydratedDataPipe(</dt><dd><p>dateRange,
useAuthorFeatures,
unhydratedPairs</p>
</dd>
</dl>
<p>)
TrainingDataCollectionJob.getTrainTestExec(</p>
<blockquote>
<div><p>dataSetPipe,
splitBy,
TweetSimilarityTrainDatarecords30MinJavaDataset,
TweetSimilarityTestDatarecords30MinJavaDataset,
outputPath)</p>
</div></blockquote>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
<p>/**
capesospy-v2 update –build_locally –start_cron </p>
<blockquote>
<div><blockquote>
<div><p>training_data_collection_120min src/scala/com/twitter/simclusters_v2/capesos_config/atla_proc3.yaml</p>
</div></blockquote>
<p><a href="#id7"><span class="problematic" id="id8">*</span></a>/</p>
</div></blockquote>
<p>object TrainingDataCollection120MinScheduledApp extends ScheduledExecutionApp {</p>
<blockquote>
<div><dl class="simple">
<dt>private val outputPath: String =</dt><dd><p>“/user/cassowary/processed/tweet_similarity/training_data_120min”</p>
</dd>
</dl>
<p>override def batchIncrement: Duration = Hours(24)</p>
<p>override def firstTime: RichDate = RichDate(“2020-03-26”)</p>
<dl>
<dt>override def runOnDateRange(</dt><dd><p>args: Args</p>
</dd>
<dt>)(</dt><dd><p>implicit dateRange: DateRange,
timeZone: TimeZone,
uniqueID: UniqueID</p>
</dd>
<dt>): Execution[Unit] = {</dt><dd><p>val useAuthorFeatures: Boolean = args.boolean(“use_author_features”)
val splitBy: Option[String] = args.optional(“split_by”)</p>
<dl class="simple">
<dt>val unhydratedPairs = DAL</dt><dd><p>.read(TweetSimilarityUnhydratedPairs120MinScalaDataset, dateRange)
.withRemoteReadPolicy(ExplicitLocation(Proc3Atla))
.toTypedPipe</p>
</dd>
<dt>val dataSetPipe = TrainingDataCollectionJob.getHydratedDataPipe(</dt><dd><p>dateRange,
useAuthorFeatures,
unhydratedPairs</p>
</dd>
</dl>
<p>)</p>
<dl class="simple">
<dt>TrainingDataCollectionJob.getTrainTestExec(</dt><dd><p>dataSetPipe,
splitBy,
TweetSimilarityTrainDatarecords120MinJavaDataset,
TweetSimilarityTestDatarecords120MinJavaDataset,
outputPath)</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../../../index2.rst.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../../../index2.rst.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../../../../_sources/src/scala/com/twitter/simclusters_v2/scalding/tweet_similarity/TrainingDataCollectionJob.scala.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>