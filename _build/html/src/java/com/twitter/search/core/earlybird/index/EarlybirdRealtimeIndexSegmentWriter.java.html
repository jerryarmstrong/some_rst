<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../../../../../" id="documentation_options" src="../../../../../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>package com.twitter.search.core.earlybird.index;</p>
<p>import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;</p>
<p>import javax.annotation.Nullable;</p>
<p>import com.google.common.base.Preconditions;
import com.google.common.collect.Lists;</p>
<p>import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.facet.FacetsConfig;
import org.apache.lucene.index.DocValuesType;
import org.apache.lucene.index.FieldInvertState;
import org.apache.lucene.index.IndexOptions;
import org.apache.lucene.index.IndexableField;
import org.apache.lucene.index.IndexableFieldType;
import org.apache.lucene.search.similarities.Similarity;
import org.apache.lucene.store.Directory;
import org.apache.lucene.util.AttributeSource;
import org.apache.lucene.util.BytesRef;
import org.apache.lucene.util.BytesRefHash;
import org.apache.lucene.util.Version;</p>
<p>import com.twitter.search.common.metrics.SearchRateCounter;
import com.twitter.search.common.schema.base.EarlybirdFieldType;
import com.twitter.search.common.schema.base.Schema;
import com.twitter.search.common.schema.earlybird.EarlybirdFieldConstants;
import com.twitter.search.core.earlybird.facets.FacetCountingArrayWriter;
import com.twitter.search.core.earlybird.facets.FacetIDMap.FacetField;
import com.twitter.search.core.earlybird.facets.FacetLabelProvider;
import com.twitter.search.core.earlybird.facets.FacetUtil;
import com.twitter.search.core.earlybird.index.column.ColumnStrideByteIndex;
import com.twitter.search.core.earlybird.index.extensions.EarlybirdRealtimeIndexExtensionsData;
import com.twitter.search.core.earlybird.index.inverted.EarlybirdCSFDocValuesProcessor;
import com.twitter.search.core.earlybird.index.inverted.InvertedRealtimeIndex;
import com.twitter.search.core.earlybird.index.inverted.InvertedRealtimeIndexWriter;
import com.twitter.search.core.earlybird.index.inverted.TermPointerEncoding;
import com.twitter.search.core.earlybird.index.util.AllDocsIterator;</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>EarlybirdIndexWriter implementation that writes realtime in-memory segments.</p></li>
<li><p>Note that it is used by both Earlybirds and ExpertSearch.</p></li>
</ul>
<p><a href="#id1"><span class="problematic" id="id2">*</span></a>/</p>
</dd>
<dt>public final class EarlybirdRealtimeIndexSegmentWriter extends EarlybirdIndexSegmentWriter {</dt><dd><dl>
<dt>private static final Logger LOG =</dt><dd><p>LoggerFactory.getLogger(EarlybirdRealtimeIndexSegmentWriter.class);</p>
</dd>
<dt>/**</dt><dd><ul class="simple">
<li><p>Maximum tweet length is 10k, setting maximum token position to 25k in case of weird unicode.</p></li>
</ul>
<p><a href="#id3"><span class="problematic" id="id4">*</span></a>/</p>
</dd>
</dl>
<p>private static final int MAX_POSITION = 25000;</p>
<dl class="simple">
<dt>private static final String OUT_OF_ORDER_APPEND_UNSUPPORTED_STATS_PATTERN =</dt><dd><p>“out_of_order_append_unsupported_for_field_%s”;</p>
</dd>
<dt>private static final ConcurrentHashMap&lt;String, SearchRateCounter&gt;</dt><dd><p>UNSUPPORTED_OUT_OF_ORDER_APPEND_MAP = new ConcurrentHashMap&lt;&gt;();</p>
</dd>
<dt>private static final SearchRateCounter NUM_TWEETS_DROPPED =</dt><dd><p>SearchRateCounter.export(“EarlybirdRealtimeIndexSegmentWriter_num_tweets_dropped”);</p>
</dd>
</dl>
<p>private long nextFieldGen;</p>
<p>private HashMap&lt;String, PerField&gt; fields = new HashMap&lt;&gt;();
private List&lt;PerField&gt; fieldsInDocument = new ArrayList&lt;&gt;();</p>
<p>private final EarlybirdCSFDocValuesProcessor docValuesProcessor;</p>
<p>private Map&lt;String, InvertedRealtimeIndexWriter&gt; termHashSync = new HashMap&lt;&gt;();
private Set&lt;String&gt; appendedFields = new HashSet&lt;&gt;();</p>
<p>private final Analyzer analyzer;
private final Similarity similarity;</p>
<p>private final EarlybirdRealtimeIndexSegmentData segmentData;</p>
<p>private final Field allDocsField;</p>
<p>&#64;Nullable
private final FacetCountingArrayWriter facetCountingArrayWriter;</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Creates a new writer for a real-time in-memory Earlybird segment.</p></li>
<li></li>
<li><p>Do not add public constructors to this class. EarlybirdRealtimeIndexSegmentWriter instances</p></li>
<li><p>should be created only by calling</p></li>
<li><p>EarlybirdRealtimeIndexSegmentData.createEarlybirdIndexSegmentWriter(), to make sure everything</p></li>
<li><p>is set up properly (such as CSF readers).</p></li>
</ul>
<p><a href="#id5"><span class="problematic" id="id6">*</span></a>/</p>
</dd>
<dt>EarlybirdRealtimeIndexSegmentWriter(</dt><dd><blockquote>
<div><p>EarlybirdRealtimeIndexSegmentData segmentData,
Analyzer analyzer,
Similarity similarity) {</p>
</div></blockquote>
<p>Preconditions.checkNotNull(segmentData);
this.segmentData = segmentData;
this.facetCountingArrayWriter = segmentData.createFacetCountingArrayWriter();
this.docValuesProcessor = new EarlybirdCSFDocValuesProcessor(segmentData.getDocValuesManager());
this.analyzer = analyzer;
this.similarity = similarity;
this.allDocsField = buildAllDocsField(segmentData);</p>
</dd>
</dl>
<p>}</p>
<p>&#64;Override
public EarlybirdRealtimeIndexSegmentData getSegmentData() {</p>
<blockquote>
<div><p>return segmentData;</p>
</div></blockquote>
<p>}</p>
<p>&#64;Override
public int numDocsNoDelete() {</p>
<blockquote>
<div><p>return segmentData.getDocIDToTweetIDMapper().getNumDocs();</p>
</div></blockquote>
<p>}</p>
<p>&#64;Override
public void addDocument(Document doc) throws IOException {</p>
<blockquote>
<div><p>// This method should be called only from Expertsearch, not tweets Earlybirds.
DocIDToTweetIDMapper docIdToTweetIdMapper = segmentData.getDocIDToTweetIDMapper();
Preconditions.checkState(docIdToTweetIdMapper instanceof SequentialDocIDMapper);</p>
<p>// Make sure we have space for a new doc in this segment.
Preconditions.checkState(docIdToTweetIdMapper.getNumDocs() &lt; segmentData.getMaxSegmentSize(),</p>
<blockquote>
<div><p>“Cannot add a new document to the segment, because it’s full.”);</p>
</div></blockquote>
<p>addDocument(doc, docIdToTweetIdMapper.addMapping(-1L), false);</p>
</div></blockquote>
<p>}</p>
<p>&#64;Override
public void addTweet(Document doc, long tweetId, boolean docIsOffensive) throws IOException {</p>
<blockquote>
<div><p>DocIDToTweetIDMapper docIdToTweetIdMapper = segmentData.getDocIDToTweetIDMapper();
Preconditions.checkState(!(docIdToTweetIdMapper instanceof SequentialDocIDMapper));</p>
<p>// Make sure we have space for a new doc in this segment.
Preconditions.checkState(docIdToTweetIdMapper.getNumDocs() &lt; segmentData.getMaxSegmentSize(),</p>
<blockquote>
<div><p>“Cannot add a new document to the segment, because it’s full.”);</p>
</div></blockquote>
<dl class="simple">
<dt>Preconditions.checkNotNull(doc.getField(</dt><dd><p>EarlybirdFieldConstants.EarlybirdFieldConstant.CREATED_AT_FIELD.getFieldName()));</p>
</dd>
</dl>
<p>addAllDocsField(doc);</p>
<p>int docId = docIdToTweetIdMapper.addMapping(tweetId);
// Make sure we successfully assigned a doc ID to the new document/tweet before proceeding.
// If the docId is DocIDToTweetIDMapper.ID_NOT_FOUND then either:
//  1. the tweet is older than the  OutOfOrderRealtimeTweetIDMapper.segmentBoundaryTimestamp and
//    is too old for this segment
//  2. the OutOfOrderRealtimeTweetIDMapper does not have any available doc ids left
if (docId == DocIDToTweetIDMapper.ID_NOT_FOUND) {</p>
<blockquote>
<div><dl class="simple">
<dt>LOG.info(“Could not assign doc id for tweet. Dropping tweet id “ + tweetId</dt><dd><ul class="simple">
<li><p>“ for segment with timeslice: “ + segmentData.getTimeSliceID());</p></li>
</ul>
</dd>
</dl>
<p>NUM_TWEETS_DROPPED.increment();
return;</p>
</div></blockquote>
<p>}</p>
<p>addDocument(doc, docId, docIsOffensive);</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>private void addDocument(Document doc,</dt><dd><blockquote>
<div><p>int docId,
boolean docIsOffensive) throws IOException {</p>
</div></blockquote>
<p>fieldsInDocument.clear();</p>
<p>long fieldGen = nextFieldGen++;</p>
<p>// NOTE: we need two passes here, in case there are
// multi-valued fields, because we must process all
// instances of a given field at once, since the
// analyzer is free to reuse TokenStream across fields
// (i.e., we cannot have more than one TokenStream
// running “at once”):</p>
<dl>
<dt>try {</dt><dd><dl>
<dt>for (IndexableField field<span class="classifier">doc) {</span></dt><dd><dl class="simple">
<dt>if (!skipField(field.name())) {</dt><dd><p>processField(docId, field, fieldGen, docIsOffensive);</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>} finally {</dt><dd><p>// Finish each indexed field name seen in the document:
for (PerField field : fieldsInDocument) {</p>
<blockquote>
<div><p>field.finish(docId);</p>
</div></blockquote>
<p>}</p>
<p>// When indexing a dummy document for out-of-order updates into a loaded segment, that
// document gets docID set as maxSegment size. So we have to make sure that we never
// sync backwards in document order.
int smallestDocID = Math.min(docId, segmentData.getSyncData().getSmallestDocID());
segmentData.updateSmallestDocID(smallestDocID);</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<p>&#64;Override
protected void appendOutOfOrder(Document doc, int internalDocID) throws IOException {</p>
<blockquote>
<div><p>Preconditions.checkNotNull(doc);
fieldsInDocument.clear();</p>
<p>long fieldGen = nextFieldGen++;</p>
<dl>
<dt>try {</dt><dd><dl>
<dt>for (IndexableField indexableField<span class="classifier">doc) {</span></dt><dd><dl>
<dt>if (!skipField(indexableField.name())) {</dt><dd><p>Schema.FieldInfo fi = segmentData.getSchema().getFieldInfo(indexableField.name());
if (fi == null) {</p>
<blockquote>
<div><p>LOG.error(“FieldInfo for “ + indexableField.name() + “ is null!”);
continue;</p>
</div></blockquote>
<p>}
if (segmentData.isOptimized() &amp;&amp; fi.getFieldType().becomesImmutable()) {</p>
<blockquote>
<div><dl>
<dt>UNSUPPORTED_OUT_OF_ORDER_APPEND_MAP.computeIfAbsent(</dt><dd><p>indexableField.name(),
f -&gt; SearchRateCounter.export(</p>
<blockquote>
<div><p>String.format(OUT_OF_ORDER_APPEND_UNSUPPORTED_STATS_PATTERN, f))</p>
</div></blockquote>
</dd>
</dl>
<p>).increment();
continue;</p>
</div></blockquote>
<p>}
processField(internalDocID, indexableField, fieldGen, false);
appendedFields.add(indexableField.name());</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>} finally {</dt><dd><p>// Finish each indexed field name seen in the document:
for (PerField field : fieldsInDocument) {</p>
<blockquote>
<div><p>field.finish(internalDocID);</p>
</div></blockquote>
<p>}
// force sync
segmentData.updateSmallestDocID(segmentData.getSyncData().getSmallestDocID());</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
<p>&#64;Override
public void addIndexes(Directory… dirs) {</p>
<blockquote>
<div><dl class="simple">
<dt>throw new UnsupportedOperationException(“In realtime mode addIndexes() is currently “</dt><dd><ul class="simple">
<li><p>“not supported.”);</p></li>
</ul>
</dd>
</dl>
</div></blockquote>
<p>}</p>
<p>&#64;Override
public void forceMerge() {</p>
<blockquote>
<div><p>// we always have a single segment in realtime-mode</p>
</div></blockquote>
<p>}</p>
<p>&#64;Override
public void close() {</p>
<blockquote>
<div><p>// nothing to close</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>private void processField(</dt><dd><blockquote>
<div><p>int docId,
IndexableField field,
long fieldGen,
boolean currentDocIsOffensive) throws IOException {</p>
</div></blockquote>
<p>String fieldName = field.name();
IndexableFieldType fieldType = field.fieldType();</p>
<p>// Invert indexed fields:
if (fieldType.indexOptions() != IndexOptions.NONE) {</p>
<blockquote>
<div><p>PerField perField = getOrAddField(fieldName, fieldType);</p>
<p>// Whether this is the first time we have seen this field in this document.
boolean first = perField.fieldGen != fieldGen;
perField.invert(field, docId, first, currentDocIsOffensive);</p>
<dl class="simple">
<dt>if (first) {</dt><dd><p>fieldsInDocument.add(perField);
perField.fieldGen = fieldGen;</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<dl>
<dt>} else {</dt><dd><dl>
<dt>Schema.FieldInfo facetFieldInfo =</dt><dd><p>segmentData.getSchema().getFacetFieldByFieldName(fieldName);</p>
</dd>
<dt>FacetField facetField = facetFieldInfo != null</dt><dd><p>? segmentData.getFacetIDMap().getFacetField(facetFieldInfo) : null;</p>
</dd>
<dt>EarlybirdFieldType facetFieldType = facetFieldInfo != null</dt><dd><p>? facetFieldInfo.getFieldType() : null;</p>
</dd>
<dt>Preconditions.checkState(</dt><dd><p>facetFieldInfo == null || (facetField != null &amp;&amp; facetFieldType != null));</p>
</dd>
<dt>if (facetField != null &amp;&amp; facetFieldType.isUseCSFForFacetCounting()) {</dt><dd><blockquote>
<div><dl>
<dt>segmentData.getFacetLabelProviders().put(</dt><dd><p>facetField.getFacetName(),
Preconditions.checkNotNull(</p>
<blockquote>
<div><p>FacetUtil.chooseFacetLabelProvider(facetFieldType, null)));</p>
</div></blockquote>
</dd>
</dl>
</div></blockquote>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
<dl>
<dt>if (fieldType.docValuesType() != DocValuesType.NONE) {</dt><dd><dl class="simple">
<dt>StoredFieldsConsumerBuilder consumerBuilder = new StoredFieldsConsumerBuilder(</dt><dd><p>fieldName, (EarlybirdFieldType) fieldType);</p>
</dd>
</dl>
<p>EarlybirdRealtimeIndexExtensionsData indexExtension = segmentData.getIndexExtensionsData();
if (indexExtension != null) {</p>
<blockquote>
<div><p>indexExtension.createStoredFieldsConsumer(consumerBuilder);</p>
</div></blockquote>
<p>}
if (consumerBuilder.isUseDefaultConsumer()) {</p>
<blockquote>
<div><p>consumerBuilder.addConsumer(docValuesProcessor);</p>
</div></blockquote>
<p>}</p>
<p>StoredFieldsConsumer storedFieldsConsumer = consumerBuilder.build();
if (storedFieldsConsumer != null) {</p>
<blockquote>
<div><p>storedFieldsConsumer.addField(docId, field);</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/** Returns a previously created <a class="reference external" href="mailto:{&#37;&#52;&#48;link">{<span>&#64;</span>link</a> PerField}, absorbing the type information from</dt><dd><ul class="simple">
<li><p><a class="reference external" href="mailto:{&#37;&#52;&#48;link">{<span>&#64;</span>link</a> org.apache.lucene.document.FieldType}, and creates a new <a class="reference external" href="mailto:{&#37;&#52;&#48;link">{<span>&#64;</span>link</a> PerField} if this field</p></li>
<li><p>name wasn’t seen yet. <a href="#id7"><span class="problematic" id="id8">*</span></a>/</p></li>
</ul>
</dd>
<dt>private PerField getOrAddField(String name, IndexableFieldType fieldType) {</dt><dd><p>// Note that this could be a computeIfAbsent, but that allocates a closure in the hot path and
// slows down indexing.
PerField perField = fields.get(name);
if (perField == null) {</p>
<blockquote>
<div><p>boolean omitNorms = fieldType.omitNorms() || fieldType.indexOptions() == IndexOptions.NONE;
perField = new PerField(this, name, fieldType.indexOptions(), omitNorms);
fields.put(name, perField);</p>
</div></blockquote>
<p>}
return perField;</p>
</dd>
</dl>
<p>}</p>
<p>/** NOTE: not static: accesses at least docState, termsHash. <a href="#id9"><span class="problematic" id="id10">*</span></a>/
private static final class PerField implements Comparable&lt;PerField&gt; {</p>
<blockquote>
<div><p>private final EarlybirdRealtimeIndexSegmentWriter indexSegmentWriter;</p>
<p>private final String fieldName;
private final IndexOptions indexOptions;
private final boolean omitNorms;</p>
<p>private InvertedRealtimeIndex invertedField;
private InvertedDocConsumer indexWriter;</p>
<dl class="simple">
<dt>/** We use this to know when a PerField is seen for the</dt><dd><ul class="simple">
<li><p>first time in the current document. <a href="#id11"><span class="problematic" id="id12">*</span></a>/</p></li>
</ul>
</dd>
</dl>
<p>private long fieldGen = -1;</p>
<p>// reused
private TokenStream tokenStream;</p>
<p>private int currentPosition;
private int currentOffset;
private int currentLength;
private int currentOverlap;
private int lastStartOffset;
private int lastPosition;</p>
<dl>
<dt>public PerField(</dt><dd><blockquote>
<div><p>EarlybirdRealtimeIndexSegmentWriter indexSegmentWriter,
String fieldName,
IndexOptions indexOptions,
boolean omitNorms) {</p>
</div></blockquote>
<p>this.indexSegmentWriter = indexSegmentWriter;
this.fieldName = fieldName;
this.indexOptions = indexOptions;
this.omitNorms = omitNorms;</p>
<p>initInvertState();</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>void initInvertState() {</dt><dd><p>// it’s okay if this is null - in that case TwitterTermHashPerField
// will not add it to the facet array
final Schema.FieldInfo facetFieldInfo</p>
<blockquote>
<div><p>= indexSegmentWriter.segmentData.getSchema().getFacetFieldByFieldName(fieldName);</p>
</div></blockquote>
<dl>
<dt>final FacetField facetField = facetFieldInfo != null</dt><dd><p>? indexSegmentWriter.segmentData.getFacetIDMap().getFacetField(facetFieldInfo) : null;</p>
</dd>
<dt>final EarlybirdFieldType facetFieldType</dt><dd><p>= facetFieldInfo != null ? facetFieldInfo.getFieldType() : null;</p>
</dd>
<dt>Preconditions.checkState(</dt><dd><p>facetFieldInfo == null || (facetField != null &amp;&amp; facetFieldType != null));</p>
</dd>
<dt>if (facetField != null &amp;&amp; facetFieldType.isUseCSFForFacetCounting()) {</dt><dd><dl>
<dt>indexSegmentWriter.segmentData.getFacetLabelProviders().put(</dt><dd><p>facetField.getFacetName(),
Preconditions.checkNotNull(</p>
<blockquote>
<div><p>FacetUtil.chooseFacetLabelProvider(facetFieldType, null)));</p>
</div></blockquote>
</dd>
</dl>
<p>return;</p>
</dd>
</dl>
<p>}</p>
<p>Schema.FieldInfo fi = indexSegmentWriter.segmentData.getSchema().getFieldInfo(fieldName);
final EarlybirdFieldType fieldType = fi.getFieldType();</p>
<dl class="simple">
<dt>InvertedDocConsumerBuilder consumerBuilder = new InvertedDocConsumerBuilder(</dt><dd><p>indexSegmentWriter.segmentData, fieldName, fieldType);</p>
</dd>
<dt>EarlybirdRealtimeIndexExtensionsData indexExtension =</dt><dd><p>indexSegmentWriter.segmentData.getIndexExtensionsData();</p>
</dd>
<dt>if (indexExtension != null) {</dt><dd><p>indexExtension.createInvertedDocConsumer(consumerBuilder);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>if (consumerBuilder.isUseDefaultConsumer()) {</dt><dd><dl class="simple">
<dt>if (indexSegmentWriter.segmentData.getPerFieldMap().containsKey(fieldName)) {</dt><dd><dl class="simple">
<dt>invertedField = (InvertedRealtimeIndex) indexSegmentWriter</dt><dd><p>.segmentData.getPerFieldMap().get(fieldName);</p>
</dd>
</dl>
</dd>
<dt>} else {</dt><dd><dl class="simple">
<dt>invertedField = new InvertedRealtimeIndex(</dt><dd><p>fieldType,
TermPointerEncoding.DEFAULT_ENCODING,
fieldName);</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
<dl>
<dt>InvertedRealtimeIndexWriter fieldWriter = new InvertedRealtimeIndexWriter(</dt><dd><p>invertedField, facetField, indexSegmentWriter.facetCountingArrayWriter);</p>
</dd>
<dt>if (facetField != null) {</dt><dd><dl>
<dt>Map&lt;String, FacetLabelProvider&gt; providerMap =</dt><dd><p>indexSegmentWriter.segmentData.getFacetLabelProviders();</p>
</dd>
<dt>if (!providerMap.containsKey(facetField.getFacetName())) {</dt><dd><dl>
<dt>providerMap.put(</dt><dd><p>facetField.getFacetName(),
Preconditions.checkNotNull(</p>
<blockquote>
<div><p>FacetUtil.chooseFacetLabelProvider(facetFieldType, invertedField)));</p>
</div></blockquote>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<p>indexSegmentWriter.segmentData.addField(fieldName, invertedField);</p>
<dl class="simple">
<dt>if (indexSegmentWriter.appendedFields.contains(fieldName)) {</dt><dd><p>indexSegmentWriter.termHashSync.put(fieldName, fieldWriter);</p>
</dd>
</dl>
<p>}</p>
<p>consumerBuilder.addConsumer(fieldWriter);</p>
</dd>
</dl>
<p>}</p>
<p>indexWriter = consumerBuilder.build();</p>
</dd>
</dl>
<p>}</p>
<p>&#64;Override
public int compareTo(PerField other) {</p>
<blockquote>
<div><p>return this.fieldName.compareTo(other.fieldName);</p>
</div></blockquote>
<p>}</p>
<p>&#64;Override
public boolean equals(Object other) {</p>
<blockquote>
<div><dl class="simple">
<dt>if (!(other instanceof PerField)) {</dt><dd><p>return false;</p>
</dd>
</dl>
<p>}</p>
<p>return this.fieldName.equals(((PerField) other).fieldName);</p>
</div></blockquote>
<p>}</p>
<p>&#64;Override
public int hashCode() {</p>
<blockquote>
<div><p>return fieldName.hashCode();</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>public void finish(int docId) {</dt><dd><dl class="simple">
<dt>if (indexWriter != null) {</dt><dd><p>indexWriter.finish();</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>if (!omitNorms) {</dt><dd><dl class="simple">
<dt>FieldInvertState state = new FieldInvertState(</dt><dd><p>Version.LATEST.major,
fieldName,
indexOptions,
currentPosition,
currentLength,
currentOverlap,
currentOffset,
0,   // maxTermFrequency
0);  // uniqueTermCount</p>
</dd>
<dt>ColumnStrideByteIndex normsIndex =</dt><dd><p>indexSegmentWriter.segmentData.createNormIndex(fieldName);</p>
</dd>
<dt>if (normsIndex != null) {</dt><dd><p>normsIndex.setValue(docId, (byte) indexSegmentWriter.similarity.computeNorm(state));</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/** Inverts one field for one document; first is true</dt><dd><ul class="simple">
<li><p>if this is the first time we are seeing this field</p></li>
<li><p>name in this document. <a href="#id13"><span class="problematic" id="id14">*</span></a>/</p></li>
</ul>
</dd>
<dt>public void invert(IndexableField field,</dt><dd><blockquote>
<div><p>int docId,
boolean first,
boolean currentDocIsOffensive) throws IOException {</p>
</div></blockquote>
<dl class="simple">
<dt>if (indexWriter == null) {</dt><dd><p>return;</p>
</dd>
</dl>
<p>}
if (first) {</p>
<blockquote>
<div><p>currentPosition = -1;
currentOffset = 0;
lastPosition = 0;
lastStartOffset = 0;</p>
<dl class="simple">
<dt>if (invertedField != null) {</dt><dd><p>invertedField.incrementNumDocs();</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
<p>IndexableFieldType fieldType = field.fieldType();
final boolean analyzed = fieldType.tokenized() &amp;&amp; indexSegmentWriter.analyzer != null;
boolean succeededInProcessingField = false;
try {</p>
<blockquote>
<div><p>tokenStream = field.tokenStream(indexSegmentWriter.analyzer, tokenStream);
tokenStream.reset();</p>
<dl class="simple">
<dt>PositionIncrementAttribute posIncrAttribute =</dt><dd><p>tokenStream.addAttribute(PositionIncrementAttribute.class);</p>
</dd>
</dl>
<p>OffsetAttribute offsetAttribute = tokenStream.addAttribute(OffsetAttribute.class);
TermToBytesRefAttribute termAtt = tokenStream.addAttribute(TermToBytesRefAttribute.class);</p>
<p>Set&lt;BytesRef&gt; seenTerms = new HashSet&lt;&gt;();
indexWriter.start(tokenStream, currentDocIsOffensive);
while (tokenStream.incrementToken()) {</p>
<blockquote>
<div><p>// If we hit an exception in stream.next below
// (which is fairly common, e.g. if analyzer
// chokes on a given document), then it’s
// non-aborting and (above) this one document
// will be marked as deleted, but still
// consume a docID</p>
<p>int posIncr = posIncrAttribute.getPositionIncrement();
currentPosition += posIncr;
if (currentPosition &lt; lastPosition) {</p>
<blockquote>
<div><dl class="simple">
<dt>if (posIncr == 0) {</dt><dd><dl class="simple">
<dt>throw new IllegalArgumentException(</dt><dd><p>“first position increment must be &gt; 0 (got 0) for field ‘” + field.name() + “’”);</p>
</dd>
</dl>
</dd>
<dt>} else if (posIncr &lt; 0) {</dt><dd><dl class="simple">
<dt>throw new IllegalArgumentException(</dt><dd><p>“position increments (and gaps) must be &gt;= 0 (got “ + posIncr + “) for field ‘”
+ field.name() + “’”);</p>
</dd>
</dl>
</dd>
<dt>} else {</dt><dd><dl class="simple">
<dt>throw new IllegalArgumentException(</dt><dd><p>“position overflowed Integer.MAX_VALUE (got posIncr=” + posIncr + “ lastPosition=”
+ lastPosition + “ position=” + currentPosition + “) for field ‘” + field.name()
+ “’”);</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<dl class="simple">
<dt>} else if (currentPosition &gt; MAX_POSITION) {</dt><dd><dl class="simple">
<dt>throw new IllegalArgumentException(</dt><dd><p>“position “ + currentPosition + “ is too large for field ‘” + field.name()
+ “’: max allowed position is “ + MAX_POSITION);</p>
</dd>
</dl>
</dd>
</dl>
<p>}
lastPosition = currentPosition;
if (posIncr == 0) {</p>
<blockquote>
<div><p>currentOverlap++;</p>
</div></blockquote>
<p>}</p>
<p>int startOffset = currentOffset + offsetAttribute.startOffset();
int endOffset = currentOffset + offsetAttribute.endOffset();
if (startOffset &lt; lastStartOffset || endOffset &lt; startOffset) {</p>
<blockquote>
<div><dl class="simple">
<dt>throw new IllegalArgumentException(</dt><dd><p>“startOffset must be non-negative, and endOffset must be &gt;= startOffset, and ”
+ “offsets must not go backwards startOffset=” + startOffset + “,endOffset=”
+ endOffset + “,lastStartOffset=” + lastStartOffset + “ for field ‘” + field.name()
+ “’”);</p>
</dd>
</dl>
</div></blockquote>
<p>}
lastStartOffset = startOffset;
indexWriter.add(docId, currentPosition);
currentLength++;</p>
<p>BytesRef term = termAtt.getBytesRef();
if (seenTerms.add(term) &amp;&amp; (invertedField != null)) {</p>
<blockquote>
<div><p>invertedField.incrementSumTermDocFreq();</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>}</p>
<p>tokenStream.end();</p>
<p>currentPosition += posIncrAttribute.getPositionIncrement();
currentOffset += offsetAttribute.endOffset();
succeededInProcessingField = true;</p>
</div></blockquote>
<dl>
<dt>} catch (BytesRefHash.MaxBytesLengthExceededException e) {</dt><dd><p>byte[] prefix = new byte[30];
BytesRef bigTerm = tokenStream.getAttribute(TermToBytesRefAttribute.class).getBytesRef();
System.arraycopy(bigTerm.bytes, bigTerm.offset, prefix, 0, 30);
String msg = “Document contains at least one immense term in field=&quot;” + fieldName</p>
<blockquote>
<div><ul class="simple">
<li><p>“&quot; (whose UTF8 encoding is longer than the max length), all of “</p></li>
<li><p>“which were skipped.” + “Please correct the analyzer to not produce such terms. “</p></li>
<li><p>“The prefix of the first immense term is: ‘” + Arrays.toString(prefix)</p></li>
<li><p>“…’, original message: “ + e.getMessage();</p></li>
</ul>
</div></blockquote>
<p>LOG.warn(msg);
// Document will be deleted above:
throw new IllegalArgumentException(msg, e);</p>
</dd>
<dt>} finally {</dt><dd><dl class="simple">
<dt>if (!succeededInProcessingField) {</dt><dd><p>LOG.warn(“An exception was thrown while processing field “ + fieldName);</p>
</dd>
</dl>
<p>}
if (tokenStream != null) {</p>
<blockquote>
<div><dl>
<dt>try {</dt><dd><p>tokenStream.close();</p>
</dd>
<dt>} catch (IOException e) {</dt><dd><dl class="simple">
<dt>if (succeededInProcessingField) {</dt><dd><p>// only throw this exception if no other exception already occurred above
throw e;</p>
</dd>
<dt>} else {</dt><dd><p>LOG.warn(“Exception while trying to close TokenStream.”, e);</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>}</p>
<dl class="simple">
<dt>if (analyzed) {</dt><dd><p>currentPosition += indexSegmentWriter.analyzer.getPositionIncrementGap(fieldName);
currentOffset += indexSegmentWriter.analyzer.getOffsetGap(fieldName);</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
<p>&#64;Override
public int numDocs() {</p>
<blockquote>
<div><p>return segmentData.getDocIDToTweetIDMapper().getNumDocs();</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>public interface InvertedDocConsumer {</dt><dd><dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Called for each document before inversion starts.</p></li>
</ul>
<p><a href="#id15"><span class="problematic" id="id16">*</span></a>/</p>
</dd>
</dl>
<p>void start(AttributeSource attributeSource, boolean currentDocIsOffensive);</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Called for each token in the current document.</p></li>
<li><p>&#64;param docID Document id.</p></li>
<li><p>&#64;param position Position in the token stream for this document.</p></li>
</ul>
<p><a href="#id17"><span class="problematic" id="id18">*</span></a>/</p>
</dd>
</dl>
<p>void add(int docID, int position) throws IOException;</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Called after the last token was added and before the next document is processed.</p></li>
</ul>
<p><a href="#id19"><span class="problematic" id="id20">*</span></a>/</p>
</dd>
</dl>
<p>void finish();</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>public interface StoredFieldsConsumer {</dt><dd><dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Adds a new stored fields.</p></li>
</ul>
<p><a href="#id21"><span class="problematic" id="id22">*</span></a>/</p>
</dd>
</dl>
<p>void addField(int docID, IndexableField field) throws IOException;</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>This Builder allows registering listeners for a particular field of an indexable document.</p></li>
<li><p>For each field name any number of listeners can be added.</p></li>
<li></li>
<li><p>Using <a class="reference external" href="mailto:{&#37;&#52;&#48;link">{<span>&#64;</span>link</a> #useDefaultConsumer} it can be specified whether this index writer will use</p></li>
<li><p>the default consumer in addition to any additionally registered consumers.</p></li>
</ul>
<p><a href="#id23"><span class="problematic" id="id24">*</span></a>/</p>
</dd>
<dt>public abstract static class ConsumerBuilder&lt;T&gt; {</dt><dd><p>private boolean useDefaultConsumer;
private final List&lt;T&gt; consumers;
private final EarlybirdFieldType fieldType;
private final String fieldName;</p>
<dl class="simple">
<dt>private ConsumerBuilder(String fieldName, EarlybirdFieldType fieldType) {</dt><dd><p>useDefaultConsumer = true;
consumers = Lists.newArrayList();
this.fieldName = fieldName;
this.fieldType = fieldType;</p>
</dd>
</dl>
<p>}</p>
<dl class="simple">
<dt>public String getFieldName() {</dt><dd><p>return fieldName;</p>
</dd>
</dl>
<p>}</p>
<dl class="simple">
<dt>public EarlybirdFieldType getFieldType() {</dt><dd><p>return fieldType;</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>If set to true, <a class="reference external" href="mailto:{&#37;&#52;&#48;link">{<span>&#64;</span>link</a> EarlybirdRealtimeIndexSegmentWriter} will use the default consumer</p></li>
<li><p>(e.g. build a default inverted index for an inverted field) in addition to any consumers</p></li>
<li><p>added via <a class="reference external" href="mailto:{&#37;&#52;&#48;link">{<span>&#64;</span>link</a> #addConsumer(Object)}.</p></li>
</ul>
<p><a href="#id25"><span class="problematic" id="id26">*</span></a>/</p>
</dd>
<dt>public void setUseDefaultConsumer(boolean useDefaultConsumer) {</dt><dd><p>this.useDefaultConsumer = useDefaultConsumer;</p>
</dd>
</dl>
<p>}</p>
<dl class="simple">
<dt>public boolean isUseDefaultConsumer() {</dt><dd><p>return useDefaultConsumer;</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Allows registering any number of additional consumers for the field associated with this</p></li>
<li><p>builder.</p></li>
</ul>
<p><a href="#id27"><span class="problematic" id="id28">*</span></a>/</p>
</dd>
<dt>public void addConsumer(T consumer) {</dt><dd><p>consumers.add(consumer);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>T build() {</dt><dd><dl class="simple">
<dt>if (consumers.isEmpty()) {</dt><dd><p>return null;</p>
</dd>
<dt>} else if (consumers.size() == 1) {</dt><dd><p>return consumers.get(0);</p>
</dd>
<dt>} else {</dt><dd><p>return build(consumers);</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<p>abstract T build(List&lt;T&gt; consumerList);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>public static final class StoredFieldsConsumerBuilder</dt><dd><blockquote>
<div><p>extends ConsumerBuilder&lt;StoredFieldsConsumer&gt; {</p>
</div></blockquote>
<dl class="simple">
<dt>private StoredFieldsConsumerBuilder(String fieldName, EarlybirdFieldType fieldType) {</dt><dd><p>super(fieldName, fieldType);</p>
</dd>
</dl>
<p>}</p>
<p>&#64;Override
StoredFieldsConsumer build(final List&lt;StoredFieldsConsumer&gt; consumers) {</p>
<blockquote>
<div><dl>
<dt>return (docID, field) -&gt; {</dt><dd><dl class="simple">
<dt>for (StoredFieldsConsumer consumer<span class="classifier">consumers) {</span></dt><dd><p>consumer.addField(docID, field);</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>};</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>public static final class InvertedDocConsumerBuilder</dt><dd><blockquote>
<div><p>extends ConsumerBuilder&lt;InvertedDocConsumer&gt; {</p>
</div></blockquote>
<p>private final EarlybirdIndexSegmentData segmentData;</p>
<dl>
<dt>private InvertedDocConsumerBuilder(</dt><dd><blockquote>
<div><p>EarlybirdIndexSegmentData segmentData, String fieldName, EarlybirdFieldType fieldType) {</p>
</div></blockquote>
<p>super(fieldName, fieldType);
this.segmentData = segmentData;</p>
</dd>
</dl>
<p>}</p>
<p>&#64;Override
InvertedDocConsumer build(final List&lt;InvertedDocConsumer&gt; consumers) {</p>
<blockquote>
<div><dl>
<dt>return new InvertedDocConsumer() {</dt><dd><p>&#64;Override
public void start(AttributeSource attributeSource, boolean currentDocIsOffensive) {</p>
<blockquote>
<div><dl class="simple">
<dt>for (InvertedDocConsumer consumer<span class="classifier">consumers) {</span></dt><dd><p>consumer.start(attributeSource, currentDocIsOffensive);</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
<p>&#64;Override
public void finish() {</p>
<blockquote>
<div><dl class="simple">
<dt>for (InvertedDocConsumer consumer<span class="classifier">consumers) {</span></dt><dd><p>consumer.finish();</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
<p>&#64;Override
public void add(int docID, int position) throws IOException {</p>
<blockquote>
<div><dl class="simple">
<dt>for (InvertedDocConsumer consumer<span class="classifier">consumers) {</span></dt><dd><p>consumer.add(docID, position);</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>};</p>
</div></blockquote>
<p>}</p>
<dl class="simple">
<dt>public EarlybirdIndexSegmentData getSegmentData() {</dt><dd><p>return segmentData;</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Returns true, if a field should not be indexed.</p></li>
<li><p>&#64;deprecated This writer should be able to process all fields in the future.</p></li>
</ul>
<p><a href="#id29"><span class="problematic" id="id30">*</span></a>/</p>
</dd>
</dl>
<p>&#64;Deprecated
private static boolean skipField(String fieldName) {</p>
<blockquote>
<div><p>// ignore lucene facet fields for realtime index, we are handling it differently for now.
return fieldName.startsWith(FacetsConfig.DEFAULT_INDEX_FIELD_NAME);</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>private static Field buildAllDocsField(EarlybirdRealtimeIndexSegmentData segmentData) {</dt><dd><p>String fieldName = EarlybirdFieldConstants.EarlybirdFieldConstant.INTERNAL_FIELD.getFieldName();
if (segmentData.getSchema().hasField(fieldName)) {</p>
<blockquote>
<div><dl class="simple">
<dt>Schema.FieldInfo fi = Preconditions.checkNotNull(</dt><dd><p>segmentData.getSchema().getFieldInfo(fieldName));</p>
</dd>
</dl>
<p>return new Field(fi.getName(), AllDocsIterator.ALL_DOCS_TERM, fi.getFieldType());</p>
</div></blockquote>
<p>}</p>
<p>return null;</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Every document must have this field and term, so that we can safely iterate through documents</p></li>
<li><p>using <a class="reference external" href="mailto:{&#37;&#52;&#48;link">{<span>&#64;</span>link</a> AllDocsIterator}. This is to prevent the problem of adding a tweet to the doc ID</p></li>
<li><p>mapper, and returning it for a match-all query when the rest of the document hasn’t been</p></li>
<li><p>published. This could lead to queries returning incorrect results for queries that are only</p></li>
<li><p>negations.</p></li>
<li><p><a href="#id31"><span class="problematic" id="id32">*</span></a>/</p></li>
</ul>
</dd>
<dt>private void addAllDocsField(Document doc) {</dt><dd><dl class="simple">
<dt>if (allDocsField != null) {</dt><dd><p>doc.add(allDocsField);</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../../../../index2.rst.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../../../../index2.rst.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../../../../../_sources/src/java/com/twitter/search/core/earlybird/index/EarlybirdRealtimeIndexSegmentWriter.java.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>