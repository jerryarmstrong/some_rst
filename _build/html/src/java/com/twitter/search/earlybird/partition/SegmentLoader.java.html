<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../../../../" id="documentation_options" src="../../../../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>package com.twitter.search.earlybird.partition;</p>
<p>import java.io.File;
import java.io.IOException;
import java.util.concurrent.TimeUnit;</p>
<p>import org.apache.commons.io.FileUtils;
import org.apache.commons.io.IOUtils;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;</p>
<p>import com.twitter.common.util.Clock;
import com.twitter.search.common.metrics.SearchRateCounter;
import com.twitter.search.common.metrics.Timer;
import com.twitter.search.common.partitioning.snowflakeparser.SnowflakeIdParser;
import com.twitter.search.common.util.io.flushable.PersistentFile;
import com.twitter.search.earlybird.exception.CriticalExceptionHandler;
import com.twitter.search.earlybird.exception.FlushVersionMismatchException;
import com.twitter.search.earlybird.stats.SegmentSyncStats;</p>
<dl>
<dt>public class SegmentLoader {</dt><dd><p>private static final Logger LOG = LoggerFactory.getLogger(SegmentLoader.class);
private static final SegmentSyncStats SEGMENT_LOAD_FROM_HDFS_STATS =</p>
<blockquote>
<div><p>new SegmentSyncStats(“load_from_hdfs”);</p>
</div></blockquote>
<p>private final CriticalExceptionHandler criticalExceptionHandler;
private final SegmentSyncConfig segmentSyncConfig;</p>
<p>private final Clock clock;</p>
<dl>
<dt>public SegmentLoader(SegmentSyncConfig sync,</dt><dd><blockquote>
<div><p>CriticalExceptionHandler criticalExceptionHandler) {</p>
</div></blockquote>
<p>this(sync, criticalExceptionHandler, Clock.SYSTEM_CLOCK);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>public SegmentLoader(SegmentSyncConfig sync,</dt><dd><blockquote>
<div><p>CriticalExceptionHandler criticalExceptionHandler,
Clock clock) {</p>
</div></blockquote>
<p>this.criticalExceptionHandler = criticalExceptionHandler;
this.segmentSyncConfig = sync;
this.clock = clock;</p>
</dd>
</dl>
<p>}</p>
<dl class="simple">
<dt>public boolean load(SegmentInfo segmentInfo) {</dt><dd><p>return downloadSegment(segmentInfo) &amp;&amp; loadSegmentFromDisk(segmentInfo);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Determines if the Earlybird should attempt to download the given segment from HDFS. This</p></li>
<li><p>returns true if the segment is not already present on local disk, and the segment does exist</p></li>
<li><p>on HDFS.</p></li>
</ul>
<p><a href="#id1"><span class="problematic" id="id2">*</span></a>/</p>
</dd>
<dt>public boolean shouldDownloadSegmentWhileInServerSet(SegmentInfo segmentInfo) {</dt><dd><dl class="simple">
<dt>if (isValidSegmentOnDisk(segmentInfo)) {</dt><dd><p>return false;</p>
</dd>
</dl>
<p>}
try (FileSystem fs = HdfsUtil.getHdfsFileSystem()) {</p>
<blockquote>
<div><p>return HdfsUtil.segmentExistsOnHdfs(fs, segmentInfo);</p>
</div></blockquote>
<dl class="simple">
<dt>} catch (IOException e) {</dt><dd><p>LOG.error(“Failed to check HDFS for segment “ + segmentInfo, e);
return false;</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Verifies if the data for the given segment is present on the local disk, and if it’s not,</p></li>
<li><p>downloads it from HDFS.</p></li>
</ul>
<p><a href="#id3"><span class="problematic" id="id4">*</span></a>/</p>
</dd>
<dt>public boolean downloadSegment(SegmentInfo segmentInfo) {</dt><dd><dl class="simple">
<dt>if (!segmentInfo.isEnabled()) {</dt><dd><p>LOG.debug(“Segment is disabled: “ + segmentInfo);
return false;</p>
</dd>
</dl>
<p>}</p>
<dl class="simple">
<dt>if (segmentInfo.isIndexing() || segmentInfo.getSyncInfo().isLoaded()) {</dt><dd><p>LOG.debug(“Cannot load indexing or loaded segment: “ + segmentInfo);
return false;</p>
</dd>
</dl>
<p>}</p>
<p>// Return whether the appropriate version is on disk, and if not, download it from HDFS.
return isValidSegmentOnDisk(segmentInfo) || checkSegmentOnHdfsAndCopyLocally(segmentInfo);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Loads the data for the given segment from the local disk.</p></li>
</ul>
<p><a href="#id5"><span class="problematic" id="id6">*</span></a>/</p>
</dd>
<dt>public boolean loadSegmentFromDisk(SegmentInfo segmentInfo) {</dt><dd><dl class="simple">
<dt>if (segmentInfo.isIndexing()) {</dt><dd><p>LOG.error(“Tried to load current segment!”);
return false;</p>
</dd>
</dl>
<p>}</p>
<p>segmentInfo.setIndexing(true);
try {</p>
<blockquote>
<div><p>File flushDir = new File(segmentInfo.getSyncInfo().getLocalSyncDir());
Directory loadDir = FSDirectory.open(flushDir.toPath());</p>
<p>segmentInfo.load(loadDir);</p>
<dl>
<dt>if (!verifySegmentStatusCountLargeEnough(segmentInfo)) {</dt><dd><dl class="simple">
<dt>SearchRateCounter.export(</dt><dd><p>“<a href="#id9"><span class="problematic" id="id10">segment_loader_failed_too_few_tweets_in_segment_</span></a>” + segmentInfo.getSegmentName())
.increment();</p>
</dd>
</dl>
<p>return false;</p>
</dd>
</dl>
<p>}</p>
<p>segmentInfo.setIndexing(false);
segmentInfo.setComplete(true);
segmentInfo.getSyncInfo().setLoaded(true);
return true;</p>
</div></blockquote>
<dl class="simple">
<dt>} catch (FlushVersionMismatchException e) {</dt><dd><p>handleException(segmentInfo, e);
// If earlybird is in starting state, handler will terminate it
criticalExceptionHandler.handle(this, e);</p>
</dd>
<dt>} catch (Exception e) {</dt><dd><p>handleException(segmentInfo, e);</p>
</dd>
</dl>
<p>}</p>
<p>SearchRateCounter.export(”<a href="#id11"><span class="problematic" id="id12">segment_loader_failed_</span></a>” + segmentInfo.getSegmentName()).increment();
return false;</p>
</dd>
</dl>
<p>}</p>
<p>// Check to see if the segment exists on disk, and its checksum passes.
private boolean isValidSegmentOnDisk(SegmentInfo segment) {</p>
<blockquote>
<div><p>String loadDirStr = segment.getSyncInfo().getLocalSyncDir();
File loadDir = new File(loadDirStr);</p>
<dl class="simple">
<dt>if (!loadDir.exists()) {</dt><dd><p>return false;</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>for (String persistentFileName<span class="classifier">segmentSyncConfig.getPersistentFileNames(segment)) {</span></dt><dd><dl class="simple">
<dt>if (!verifyInfoChecksum(loadDir, persistentFileName)) {</dt><dd><p>return false;</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<p>return true;</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>private static boolean verifyInfoChecksum(File loadDir, String databaseName) {</dt><dd><dl>
<dt>if (checksumFileExists(loadDir, databaseName)) {</dt><dd><dl>
<dt>try {</dt><dd><p>Directory dir = FSDirectory.open(loadDir.toPath());
PersistentFile.Reader reader = PersistentFile.getReader(dir, databaseName);
try {</p>
<blockquote>
<div><p>reader.verifyInfoChecksum();
return true;</p>
</div></blockquote>
<dl class="simple">
<dt>} finally {</dt><dd><p>IOUtils.closeQuietly(reader);
IOUtils.closeQuietly(dir);</p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>} catch (PersistentFile.CorruptFileException e) {</dt><dd><p>LOG.error(“Failed checksum verification.”, e);</p>
</dd>
<dt>} catch (IOException e) {</dt><dd><p>LOG.error(“Error while trying to read checksum file”, e);</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}
return false;</p>
</dd>
</dl>
<p>}</p>
<p>// Check that the loaded segment’s status count is higher than the configured threshold
private boolean verifySegmentStatusCountLargeEnough(SegmentInfo segmentInfo) {</p>
<blockquote>
<div><p>long segmentStatusCount = segmentInfo.getIndexStats().getStatusCount();
if (segmentStatusCount &gt; segmentSyncConfig.getMinSegmentStatusCountThreshold()) {</p>
<blockquote>
<div><p>return true;</p>
</div></blockquote>
<dl>
<dt>} else if (segmentInfo.getEarlybirdIndexConfig().isIndexStoredOnDisk()</dt><dd><blockquote>
<div><p>&amp;&amp; couldBeMostRecentArchiveSegment(segmentInfo)) {</p>
</div></blockquote>
<p>// The most recent archive earlybird segment is expected to be incomplete
LOG.info(“Segment status count (” + segmentStatusCount + “) is below the threshold of “</p>
<blockquote>
<div><ul class="simple">
<li><p>segmentSyncConfig.getMinSegmentStatusCountThreshold()</p></li>
<li><p>“, but this is expected because the most recent segment is expected to be incomplete: “</p></li>
<li><p>segmentInfo);</p></li>
</ul>
</div></blockquote>
<p>return true;</p>
</dd>
<dt>} else {</dt><dd><p>// The segment status count is small so the segment is likely incomplete.
LOG.error(“Segment status count (” + segmentStatusCount + “) is below the threshold of “</p>
<blockquote>
<div><ul class="simple">
<li><p>segmentSyncConfig.getMinSegmentStatusCountThreshold() + “: “ + segmentInfo);</p></li>
</ul>
</div></blockquote>
<p>segmentInfo.setIndexing(false);
segmentInfo.getSyncInfo().setLoaded(false);</p>
<p>// Remove segment from local disk
if (!segmentInfo.deleteLocalIndexedSegmentDirectoryImmediately()) {</p>
<blockquote>
<div><p>LOG.error(“Failed to cleanup unloadable segment directory.”);</p>
</div></blockquote>
<p>}</p>
<p>return false;</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
<p>// Check if this segment could be the most recent archive earlybird segment (would be on the
// latest tier). Archive segments tend to span around 12 days, so using a conservative threshold
// of 20 days.
private boolean couldBeMostRecentArchiveSegment(SegmentInfo segmentInfo) {</p>
<blockquote>
<div><dl class="simple">
<dt>long timesliceAgeMs =</dt><dd><p>SnowflakeIdParser.getTweetAgeInMs(clock.nowMillis(), segmentInfo.getTimeSliceID());</p>
</dd>
</dl>
<p>return (timesliceAgeMs / 1000 / 60 / 60 / 24) &lt;= 20;</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Check to see if the segment exists on hdfs. Will look for the correct segment version</p></li>
<li><p>uploaded by any of the hosts.</p></li>
<li><p>If the segment exists on hdfs, the segment will be copied from hdfs to the local file</p></li>
<li><p>system, and we will verify the checksum against the copied version.</p></li>
<li><p>&#64;return true iff the segment was copied to local disk, and the checksum is verified.</p></li>
</ul>
<p><a href="#id7"><span class="problematic" id="id8">*</span></a>/</p>
</dd>
<dt>private boolean checkSegmentOnHdfsAndCopyLocally(SegmentInfo segment) {</dt><dd><dl class="simple">
<dt>if (!segmentSyncConfig.isSegmentLoadFromHdfsEnabled()) {</dt><dd><p>return isValidSegmentOnDisk(segment);</p>
</dd>
</dl>
<p>}</p>
<p>LOG.info(“About to start downloading segment from hdfs: “ + segment);
Timer timer = new Timer(TimeUnit.MILLISECONDS);
String status = null;
String localBaseDir = segment.getSyncInfo().getLocalSyncDir();
FileSystem fs = null;
try {</p>
<blockquote>
<div><p>fs = HdfsUtil.getHdfsFileSystem();</p>
<p>String hdfsBaseDirPrefix = segment.getSyncInfo().getHdfsSyncDirPrefix();
FileStatus[] statuses = fs.globStatus(new Path(hdfsBaseDirPrefix));
if (statuses != null &amp;&amp; statuses.length &gt; 0) {</p>
<blockquote>
<div><p>Path hdfsSyncPath = statuses[0].getPath();
copySegmentFilesFromHdfs(segment, segmentSyncConfig, fs, hdfsSyncPath);
status = “loaded”;</p>
</div></blockquote>
<dl class="simple">
<dt>} else {</dt><dd><p>LOG.info(“No segments found in hdfs under: “ + hdfsBaseDirPrefix);
status = “notloaded”;</p>
</dd>
</dl>
<p>}
fs.close();</p>
</div></blockquote>
<dl>
<dt>} catch (IOException ex) {</dt><dd><dl class="simple">
<dt>LOG.error(“Failed copying segment from hdfs: “ + segment + “ after: “</dt><dd><ul class="simple">
<li><p>timer.stop() + “ ms”, ex);</p></li>
</ul>
</dd>
</dl>
<p>status = “exception”;
SEGMENT_LOAD_FROM_HDFS_STATS.recordError();
try {</p>
<blockquote>
<div><p>FileUtils.deleteDirectory(new File(localBaseDir));</p>
</div></blockquote>
<dl class="simple">
<dt>} catch (IOException e) {</dt><dd><p>LOG.error(“Error cleaning up local segment directory: “ + segment, e);</p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>} finally {</dt><dd><p>timer.stop();
SEGMENT_LOAD_FROM_HDFS_STATS.actionComplete(timer);
LOG.info(“Download from hdfs completed in “</p>
<blockquote>
<div><ul class="simple">
<li><p>timer.getElapsed() + “ milliseconds: “ + segment + “ status: “ + status);</p></li>
</ul>
</div></blockquote>
<p>IOUtils.closeQuietly(fs);</p>
</dd>
</dl>
<p>}</p>
<p>// now check to see if we have successfully copied the segment
return isValidSegmentOnDisk(segment);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>private static void copySegmentFilesFromHdfs(SegmentInfo segment,</dt><dd><blockquote>
<div><p>SegmentSyncConfig syncConfig,
FileSystem fs,
Path hdfsSyncPath) throws IOException {</p>
</div></blockquote>
<p>String localBaseDir = segment.getSyncInfo().getLocalSyncDir();
File localBaseDirFile = new File(localBaseDir);
FileUtils.deleteQuietly(localBaseDirFile);
if (localBaseDirFile.exists()) {</p>
<blockquote>
<div><p>LOG.warn(“Cannot delete the existing path: “ + localBaseDir);</p>
</div></blockquote>
<p>}
for (String fileName : syncConfig.getAllSyncFileNames(segment)) {</p>
<blockquote>
<div><p>Path hdfsFilePath = new Path(hdfsSyncPath, fileName);
String localFileName = localBaseDir + “/” + fileName;
LOG.debug(“About to start loading from hdfs: “ + fileName + “ from: “</p>
<blockquote>
<div><ul class="simple">
<li><p>hdfsFilePath + “ to: “ + localFileName);</p></li>
</ul>
</div></blockquote>
<p>Timer timer = new Timer(TimeUnit.MILLISECONDS);
fs.copyToLocalFile(hdfsFilePath, new Path(localFileName));
LOG.debug(“Loaded segment file from hdfs: “ + fileName + “ from: “</p>
<blockquote>
<div><ul class="simple">
<li><p>hdfsFilePath + “ to: “ + localFileName + “ in: “ + timer.stop() + “ ms.”);</p></li>
</ul>
</div></blockquote>
</div></blockquote>
<p>}</p>
<p>LOG.info(“Finished downloading segments from “ + hdfsSyncPath);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>private static boolean checksumFileExists(File loadDir, String databaseName) {</dt><dd><p>String checksumFileName = PersistentFile.genChecksumFileName(databaseName);
File checksumFile = new File(loadDir, checksumFileName);</p>
<p>return checksumFile.exists();</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>private void handleException(SegmentInfo segmentInfo, Exception e) {</dt><dd><dl class="simple">
<dt>LOG.error(“Exception while loading IndexSegment from “</dt><dd><ul class="simple">
<li><p>segmentInfo.getSyncInfo().getLocalSyncDir(), e);</p></li>
</ul>
</dd>
</dl>
<p>segmentInfo.setIndexing(false);
segmentInfo.getSyncInfo().setLoaded(false);
if (!segmentInfo.deleteLocalIndexedSegmentDirectoryImmediately()) {</p>
<blockquote>
<div><p>LOG.error(“Failed to cleanup unloadable segment directory.”);</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../../../index2.rst.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../../../index2.rst.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../../../../_sources/src/java/com/twitter/search/earlybird/partition/SegmentLoader.java.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>