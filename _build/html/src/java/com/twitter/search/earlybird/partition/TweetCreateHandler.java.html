<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../../../../" id="documentation_options" src="../../../../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>package com.twitter.search.earlybird.partition;</p>
<p>import java.io.IOException;
import java.util.Iterator;</p>
<p>import scala.runtime.BoxedUnit;</p>
<p>import com.google.common.annotations.VisibleForTesting;
import com.google.common.base.Preconditions;
import com.google.common.base.Stopwatch;
import com.google.common.base.Verify;</p>
<p>import org.slf4j.Logger;
import org.slf4j.LoggerFactory;</p>
<p>import com.twitter.search.common.config.Config;
import com.twitter.search.common.indexing.thriftjava.ThriftVersionedEvents;
import com.twitter.search.common.metrics.SearchCounter;
import com.twitter.search.common.metrics.SearchLongGauge;
import com.twitter.search.common.metrics.SearchRateCounter;
import com.twitter.search.common.metrics.SearchTimer;
import com.twitter.search.common.partitioning.snowflakeparser.SnowflakeIdParser;
import com.twitter.search.common.util.GCUtil;
import com.twitter.search.earlybird.EarlybirdStatus;
import com.twitter.search.earlybird.common.CaughtUpMonitor;
import com.twitter.search.earlybird.exception.CriticalExceptionHandler;
import com.twitter.search.earlybird.index.OutOfOrderRealtimeTweetIDMapper;
import com.twitter.search.earlybird.querycache.QueryCacheManager;
import com.twitter.search.earlybird.util.CoordinatedEarlybirdActionInterface;
import com.twitter.util.Await;
import com.twitter.util.Duration;
import com.twitter.util.Future;
import com.twitter.util.TimeoutException;</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>This class handles incoming new Tweets. It is responsible for creating segments for the incoming</p></li>
<li><p>Tweets when necessary, triggering optimization on those segments, and writing Tweets to the</p></li>
<li><p>correct segment.</p></li>
</ul>
<p><a href="#id1"><span class="problematic" id="id2">*</span></a>/</p>
</dd>
<dt>public class TweetCreateHandler {</dt><dd><p>private static final Logger LOG = LoggerFactory.getLogger(TweetCreateHandler.class);</p>
<p>public static final long LATE_TWEET_TIME_BUFFER_MS = Duration.fromMinutes(1).inMilliseconds();</p>
<p>private static final String STATS_PREFIX = “<a href="#id13"><span class="problematic" id="id14">tweet_create_handler_</span></a>”;</p>
<p>// To get a better idea of which of these succeeded and so on, see stats in SegmentManager.
private IndexingResultCounts indexingResultCounts;
private static final SearchRateCounter TWEETS_IN_WRONG_SEGMENT =</p>
<blockquote>
<div><p>SearchRateCounter.export(STATS_PREFIX + “tweets_in_wrong_segment”);</p>
</div></blockquote>
<dl class="simple">
<dt>private static final SearchRateCounter SEGMENTS_CLOSED_EARLY =</dt><dd><p>SearchRateCounter.export(STATS_PREFIX + “segments_closed_early”);</p>
</dd>
<dt>private static final SearchRateCounter INSERTED_IN_CURRENT_SEGMENT =</dt><dd><p>SearchRateCounter.export(STATS_PREFIX + “inserted_in_current_segment”);</p>
</dd>
<dt>private static final SearchRateCounter INSERTED_IN_PREVIOUS_SEGMENT =</dt><dd><p>SearchRateCounter.export(STATS_PREFIX + “inserted_in_previous_segment”);</p>
</dd>
</dl>
<p>private static final NewSegmentStats NEW_SEGMENT_STATS = new NewSegmentStats();
private static final SearchCounter CREATED_SEGMENTS =</p>
<blockquote>
<div><p>SearchCounter.export(STATS_PREFIX + “created_segments”);</p>
</div></blockquote>
<dl class="simple">
<dt>private static final SearchRateCounter INCOMING_TWEETS =</dt><dd><p>SearchRateCounter.export(STATS_PREFIX + “incoming_tweets”);</p>
</dd>
<dt>private static final SearchRateCounter INDEXING_SUCCESS =</dt><dd><p>SearchRateCounter.export(STATS_PREFIX + “indexing_success”);</p>
</dd>
<dt>private static final SearchRateCounter INDEXING_FAILURE =</dt><dd><p>SearchRateCounter.export(STATS_PREFIX + “indexing_failure”);</p>
</dd>
</dl>
<p>// Various stats and logging around creation of new segments, put in this
// class so that the code is not watered down too much by this.
private static class NewSegmentStats {</p>
<blockquote>
<div><dl class="simple">
<dt>private static final String NEW_SEGMENT_STATS_PREFIX =</dt><dd><p>STATS_PREFIX + “<a href="#id15"><span class="problematic" id="id16">new_segment_</span></a>”;</p>
</dd>
<dt>private static final SearchCounter START_NEW_AFTER_REACHING_LIMIT =</dt><dd><p>SearchCounter.export(NEW_SEGMENT_STATS_PREFIX + “start_after_reaching_limit”);</p>
</dd>
<dt>private static final SearchCounter START_NEW_AFTER_EXCEEDING_MAX_ID =</dt><dd><p>SearchCounter.export(NEW_SEGMENT_STATS_PREFIX + “start_after_exceeding_max_id”);</p>
</dd>
<dt>private static final SearchCounter TIMESLICE_SET_TO_CURRENT_ID =</dt><dd><p>SearchCounter.export(NEW_SEGMENT_STATS_PREFIX + “timeslice_set_to_current_id”);</p>
</dd>
<dt>private static final SearchCounter TIMESLICE_SET_TO_MAX_ID =</dt><dd><p>SearchCounter.export(NEW_SEGMENT_STATS_PREFIX + “timeslice_set_to_max_id”);</p>
</dd>
<dt>private static final SearchLongGauge TIMESPAN_BETWEEN_MAX_AND_CURRENT =</dt><dd><p>SearchLongGauge.export(NEW_SEGMENT_STATS_PREFIX + “timespan_between_id_and_max”);</p>
</dd>
<dt>void recordCreateNewSegment() {</dt><dd><p>CREATED_SEGMENTS.increment();</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>void recordStartAfterReachingTweetsLimit(int numDocs, int numDocsCutoff,</dt><dd><blockquote>
<div><p>int maxSegmentSize, int lateTweetBuffer) {</p>
</div></blockquote>
<p>START_NEW_AFTER_REACHING_LIMIT.increment();
LOG.info(String.format(</p>
<blockquote>
<div><dl class="simple">
<dt>“Will create new segment: numDocs=%,d, numDocsCutoff=%,d”</dt><dd><ul class="simple">
<li><p>“ | maxSegmentSize=%,d, lateTweetBuffer=%,d”,</p></li>
</ul>
</dd>
</dl>
<p>numDocs, numDocsCutoff, maxSegmentSize, lateTweetBuffer));</p>
</div></blockquote>
</dd>
</dl>
<p>}</p>
<dl>
<dt>void recordStartAfterExceedingLargestValidTweetId(long tweetId, long largestValidTweetId) {</dt><dd><p>START_NEW_AFTER_EXCEEDING_MAX_ID.increment();
LOG.info(String.format(</p>
<blockquote>
<div><p>“Will create new segment: tweetDd=%,d, largestValidTweetID for segment=%,d”,
tweetId, largestValidTweetId));</p>
</div></blockquote>
</dd>
</dl>
<p>}</p>
<dl>
<dt>void recordSettingTimesliceToCurrentTweet(long tweetID) {</dt><dd><p>TIMESLICE_SET_TO_CURRENT_ID.increment();
LOG.info(“Creating new segment: tweet that triggered it has the largest id we’ve seen. “</p>
<blockquote>
<div><ul class="simple">
<li><p>“ id={}”, tweetID);</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
<p>}</p>
<dl>
<dt>void recordSettingTimesliceToMaxTweetId(long tweetID, long maxTweetID) {</dt><dd><p>TIMESLICE_SET_TO_MAX_ID.increment();
LOG.info(“Creating new segment: tweet that triggered it doesn’t have the largest id”</p>
<blockquote>
<div><ul class="simple">
<li><p>“ we’ve seen. tweetId={}, maxTweetId={}”,</p></li>
</ul>
<p>tweetID, maxTweetID);</p>
</div></blockquote>
<dl class="simple">
<dt>long timeDifference =</dt><dd><p>SnowflakeIdParser.getTimeDifferenceBetweenTweetIDs(maxTweetID, tweetID);</p>
</dd>
</dl>
<p>LOG.info(“Time difference between max seen and last seen: {} ms”, timeDifference);
TIMESPAN_BETWEEN_MAX_AND_CURRENT.set(timeDifference);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>void wrapNewSegmentCreation(long tweetID, long maxTweetID,</dt><dd><blockquote>
<div><p>long currentSegmentTimesliceBoundary,
long largestValidTweetIDForCurrentSegment) {</p>
</div></blockquote>
<dl>
<dt>long timeDifferenceStartToMax = SnowflakeIdParser.getTimeDifferenceBetweenTweetIDs(</dt><dd><p>largestValidTweetIDForCurrentSegment,
currentSegmentTimesliceBoundary);</p>
</dd>
<dt>LOG.info(“Time between timeslice boundary and largest valid tweet id: {} ms”,</dt><dd><p>timeDifferenceStartToMax);</p>
</dd>
<dt>LOG.info(“Created new segment: (tweetId={}, maxTweetId={}, maxTweetId-tweetId={} “</dt><dd><blockquote>
<div><ul class="simple">
<li><p>“ | currentSegmentTimesliceBoundary={}, largestValidTweetIDForSegment={})”,</p></li>
</ul>
</div></blockquote>
<p>tweetID, maxTweetID, maxTweetID - tweetID, currentSegmentTimesliceBoundary,
largestValidTweetIDForCurrentSegment);</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
<p>private final SegmentManager segmentManager;
private final MultiSegmentTermDictionaryManager multiSegmentTermDictionaryManager;
private final int maxSegmentSize;
private final int lateTweetBuffer;</p>
<p>private long maxTweetID = Long.MIN_VALUE;</p>
<p>private long largestValidTweetIDForCurrentSegment;
private long currentSegmentTimesliceBoundary;
private OptimizingSegmentWriter currentSegment;
private OptimizingSegmentWriter previousSegment;
private final QueryCacheManager queryCacheManager;
private final CriticalExceptionHandler criticalExceptionHandler;
private final SearchIndexingMetricSet searchIndexingMetricSet;
private final CoordinatedEarlybirdActionInterface postOptimizationRebuildsAction;
private final CoordinatedEarlybirdActionInterface gcAction;
private final CaughtUpMonitor indexCaughtUpMonitor;
private final OptimizationAndFlushingCoordinationLock optimizationAndFlushingCoordinationLock;</p>
<dl>
<dt>public TweetCreateHandler(</dt><dd><p>SegmentManager segmentManager,
SearchIndexingMetricSet searchIndexingMetricSet,
CriticalExceptionHandler criticalExceptionHandler,
MultiSegmentTermDictionaryManager multiSegmentTermDictionaryManager,
QueryCacheManager queryCacheManager,
CoordinatedEarlybirdActionInterface postOptimizationRebuildsAction,
CoordinatedEarlybirdActionInterface gcAction,
int lateTweetBuffer,
int maxSegmentSize,
CaughtUpMonitor indexCaughtUpMonitor,
OptimizationAndFlushingCoordinationLock optimizationAndFlushingCoordinationLock</p>
</dd>
<dt>) {</dt><dd><p>this.segmentManager = segmentManager;
this.criticalExceptionHandler = criticalExceptionHandler;
this.multiSegmentTermDictionaryManager = multiSegmentTermDictionaryManager;
this.queryCacheManager = queryCacheManager;
this.indexingResultCounts = new IndexingResultCounts();
this.searchIndexingMetricSet = searchIndexingMetricSet;
this.postOptimizationRebuildsAction = postOptimizationRebuildsAction;
this.gcAction = gcAction;
this.indexCaughtUpMonitor = indexCaughtUpMonitor;</p>
<p>Preconditions.checkState(lateTweetBuffer &lt; maxSegmentSize);
this.lateTweetBuffer = lateTweetBuffer;
this.maxSegmentSize = maxSegmentSize;
this.optimizationAndFlushingCoordinationLock = optimizationAndFlushingCoordinationLock;</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>void prepareAfterStartingWithIndex(long maxIndexedTweetId) {</dt><dd><p>LOG.info(“Preparing after starting with an index.”);</p>
<dl class="simple">
<dt>Iterator&lt;SegmentInfo&gt; segmentInfosIterator =</dt><dd><dl class="simple">
<dt>segmentManager</dt><dd><p>.getSegmentInfos(SegmentManager.Filter.All, SegmentManager.Order.NEW_TO_OLD)
.iterator();</p>
</dd>
</dl>
</dd>
</dl>
<p>// Setup the last segment.
Verify.verify(segmentInfosIterator.hasNext(), “at least one segment expected”);
ISegmentWriter lastWriter = segmentManager.getSegmentWriterForID(</p>
<blockquote>
<div><p>segmentInfosIterator.next().getTimeSliceID());</p>
</div></blockquote>
<p>Verify.verify(lastWriter != null);</p>
<p>LOG.info(“TweetCreateHandler found last writer: {}”, lastWriter.getSegmentInfo().toString());
this.currentSegmentTimesliceBoundary = lastWriter.getSegmentInfo().getTimeSliceID();
this.largestValidTweetIDForCurrentSegment =</p>
<blockquote>
<div><p>OutOfOrderRealtimeTweetIDMapper.calculateMaxTweetID(currentSegmentTimesliceBoundary);</p>
</div></blockquote>
<p>this.currentSegment = (OptimizingSegmentWriter) lastWriter;</p>
<dl class="simple">
<dt>if (maxIndexedTweetId == -1) {</dt><dd><p>maxTweetID = lastWriter.getSegmentInfo().getIndexSegment().getMaxTweetId();
LOG.info(“Max tweet id = {}”, maxTweetID);</p>
</dd>
<dt>} else {</dt><dd><p>// See SEARCH-31032
maxTweetID = maxIndexedTweetId;</p>
</dd>
</dl>
<p>}</p>
<p>// If we have a previous segment that’s not optimized, set it up too, we still need to pick
// it up for optimization and we might still be able to add tweets to it.
if (segmentInfosIterator.hasNext()) {</p>
<blockquote>
<div><p>SegmentInfo previousSegmentInfo = segmentInfosIterator.next();
if (!previousSegmentInfo.isOptimized()) {</p>
<blockquote>
<div><dl class="simple">
<dt>ISegmentWriter previousSegmentWriter = segmentManager.getSegmentWriterForID(</dt><dd><p>previousSegmentInfo.getTimeSliceID());</p>
</dd>
<dt>if (previousSegmentWriter != null) {</dt><dd><p>LOG.info(“Picked previous segment”);
this.previousSegment = (OptimizingSegmentWriter) previousSegmentWriter;</p>
</dd>
<dt>} else {</dt><dd><p>// Should not happen.
LOG.error(“Not found previous segment writer”);</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<dl class="simple">
<dt>} else {</dt><dd><p>LOG.info(“Previous segment info is optimized”);</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<dl class="simple">
<dt>} else {</dt><dd><p>LOG.info(“Previous segment info not found, we only have one segment”);</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>private void updateIndexFreshness() {</dt><dd><p>searchIndexingMetricSet.highestStatusId.set(maxTweetID);</p>
<dl class="simple">
<dt>long tweetTimestamp = SnowflakeIdParser.getTimestampFromTweetId(</dt><dd><p>searchIndexingMetricSet.highestStatusId.get());</p>
</dd>
</dl>
<p>searchIndexingMetricSet.freshestTweetTimeMillis.set(tweetTimestamp);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Index a new TVE representing a Tweet create event.</p></li>
</ul>
<p><a href="#id3"><span class="problematic" id="id4">*</span></a>/</p>
</dd>
<dt>public void handleTweetCreate(ThriftVersionedEvents tve) throws IOException {</dt><dd><p>INCOMING_TWEETS.increment();
long id = tve.getId();
maxTweetID = Math.max(id, maxTweetID);</p>
<p>updateIndexFreshness();</p>
<p>boolean shouldCreateNewSegment = false;</p>
<dl>
<dt>if (currentSegment == null) {</dt><dd><p>shouldCreateNewSegment = true;
LOG.info(“Will create new segment: current segment is null”);</p>
</dd>
<dt>} else {</dt><dd><p>int numDocs = currentSegment.getSegmentInfo().getIndexSegment().getNumDocs();
int numDocsCutoff = maxSegmentSize - lateTweetBuffer;
if (numDocs &gt;= numDocsCutoff) {</p>
<blockquote>
<div><dl class="simple">
<dt>NEW_SEGMENT_STATS.recordStartAfterReachingTweetsLimit(numDocs, numDocsCutoff,</dt><dd><p>maxSegmentSize, lateTweetBuffer);</p>
</dd>
</dl>
<p>shouldCreateNewSegment = true;</p>
</div></blockquote>
<dl>
<dt>} else if (id &gt; largestValidTweetIDForCurrentSegment) {</dt><dd><dl class="simple">
<dt>NEW_SEGMENT_STATS.recordStartAfterExceedingLargestValidTweetId(id,</dt><dd><p>largestValidTweetIDForCurrentSegment);</p>
</dd>
</dl>
<p>shouldCreateNewSegment = true;</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<dl class="simple">
<dt>if (shouldCreateNewSegment) {</dt><dd><p>createNewSegment(id);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>if (previousSegment != null) {</dt><dd><p>// Inserts and some updates can’t be applied to an optimized segment, so we want to wait at
// least LATE_TWEET_TIME_BUFFER between when we created the new segment and when we optimize
// the previous segment, in case there are late tweets.
// We leave a large (150k, typically) buffer in the segment so that we don’t have to close
// the previousSegment before LATE_TWEET_TIME_BUFFER has passed, but if we index
// lateTweetBuffer Tweets before optimizing, then we must optimize,
// so that we don’t insert more than max segment size tweets into the previous segment.
long relativeTweetAgeMs =</p>
<blockquote>
<div><p>SnowflakeIdParser.getTimeDifferenceBetweenTweetIDs(id, currentSegmentTimesliceBoundary);</p>
</div></blockquote>
<p>boolean needToOptimize = false;
int numDocs = previousSegment.getSegmentInfo().getIndexSegment().getNumDocs();
String previousSegmentName = previousSegment.getSegmentInfo().getSegmentName();
if (numDocs &gt;= maxSegmentSize) {</p>
<blockquote>
<div><dl class="simple">
<dt>LOG.info(String.format(“Previous segment (%s) reached maxSegmentSize, need to optimize it.”</dt><dd><ul class="simple">
<li><p>“ numDocs=%,d, maxSegmentSize=%,d”, previousSegmentName, numDocs, maxSegmentSize));</p></li>
</ul>
</dd>
</dl>
<p>needToOptimize = true;</p>
</div></blockquote>
<dl>
<dt>} else if (relativeTweetAgeMs &gt; LATE_TWEET_TIME_BUFFER_MS) {</dt><dd><dl>
<dt>LOG.info(String.format(“Previous segment (%s) is old enough, we can optimize it.”</dt><dd><ul class="simple">
<li><p>“ Got tweet past time buffer of %,d ms by: %,d ms”, previousSegmentName,</p></li>
</ul>
<p>LATE_TWEET_TIME_BUFFER_MS, relativeTweetAgeMs - LATE_TWEET_TIME_BUFFER_MS));</p>
</dd>
</dl>
<p>needToOptimize = true;</p>
</dd>
</dl>
<p>}</p>
<dl class="simple">
<dt>if (needToOptimize) {</dt><dd><p>optimizePreviousSegment();</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<p>ISegmentWriter segmentWriter;
if (id &gt;= currentSegmentTimesliceBoundary) {</p>
<blockquote>
<div><p>INSERTED_IN_CURRENT_SEGMENT.increment();
segmentWriter = currentSegment;</p>
</div></blockquote>
<dl>
<dt>} else if (previousSegment != null) {</dt><dd><p>INSERTED_IN_PREVIOUS_SEGMENT.increment();
segmentWriter = previousSegment;</p>
</dd>
<dt>} else {</dt><dd><p>TWEETS_IN_WRONG_SEGMENT.increment();
LOG.info(“Inserting TVE ({}) into the current segment ({}) even though it should have gone “</p>
<blockquote>
<div><ul class="simple">
<li><p>“in a previous segment.”, id, currentSegmentTimesliceBoundary);</p></li>
</ul>
</div></blockquote>
<p>segmentWriter = currentSegment;</p>
</dd>
</dl>
<p>}</p>
<p>SearchTimer timer = searchIndexingMetricSet.statusStats.startNewTimer();
ISegmentWriter.Result result = segmentWriter.indexThriftVersionedEvents(tve);
searchIndexingMetricSet.statusStats.stopTimerAndIncrement(timer);</p>
<dl class="simple">
<dt>if (result == ISegmentWriter.Result.SUCCESS) {</dt><dd><p>INDEXING_SUCCESS.increment();</p>
</dd>
<dt>} else {</dt><dd><p>INDEXING_FAILURE.increment();</p>
</dd>
</dl>
<p>}</p>
<p>indexingResultCounts.countResult(result);</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Many tests need to verify behavior with segments optimized &amp; unoptimized, so we need to expose</p></li>
<li><p>this.</p></li>
</ul>
<p><a href="#id5"><span class="problematic" id="id6">*</span></a>/</p>
</dd>
</dl>
<p>&#64;VisibleForTesting
public Future&lt;SegmentInfo&gt; optimizePreviousSegment() {</p>
<blockquote>
<div><p>String segmentName = previousSegment.getSegmentInfo().getSegmentName();
previousSegment.getSegmentInfo().setIndexing(false);
LOG.info(“Optimizing previous segment: {}”, segmentName);
segmentManager.logState(“Starting optimization for segment: “ + segmentName);</p>
<dl>
<dt>Future&lt;SegmentInfo&gt; future = previousSegment</dt><dd><p>.startOptimization(gcAction, optimizationAndFlushingCoordinationLock)
.map(this::postOptimizationSteps)
.onFailure(t -&gt; {</p>
<blockquote>
<div><p>criticalExceptionHandler.handle(this, t);
return BoxedUnit.UNIT;</p>
</div></blockquote>
<p>});</p>
</dd>
</dl>
<p>waitForOptimizationIfInTest(future);</p>
<p>previousSegment = null;
return future;</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>In tests, it’s easier if when a segment starts optimizing, we know that it will finish</p></li>
<li><p>optimizing. This way we have no race condition where we’re surprised that something that</p></li>
<li><p>started optimizing is not ready.</p></li>
<li></li>
<li><p>In prod we don’t have this problem. Segments run for 10 hours and optimization is 20 minutes</p></li>
<li><p>so there’s no need for extra synchronization.</p></li>
</ul>
<p><a href="#id7"><span class="problematic" id="id8">*</span></a>/</p>
</dd>
<dt>private void waitForOptimizationIfInTest(Future&lt;SegmentInfo&gt; future) {</dt><dd><dl>
<dt>if (Config.environmentIsTest()) {</dt><dd><dl class="simple">
<dt>try {</dt><dd><p>Await.ready(future);
LOG.info(“Optimizing is done”);</p>
</dd>
<dt>} catch (InterruptedException | TimeoutException ex) {</dt><dd><p>LOG.info(“Exception while optimizing”, ex);</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>private SegmentInfo postOptimizationSteps(SegmentInfo optimizedSegmentInfo) {</dt><dd><p>segmentManager.updateStats();
// See SEARCH-32175
optimizedSegmentInfo.setComplete(true);</p>
<p>String segmentName = optimizedSegmentInfo.getSegmentName();
LOG.info(“Finished optimization for segment: “ + segmentName);
segmentManager.logState(</p>
<blockquote>
<div><p>“Finished optimization for segment: “ + segmentName);</p>
</div></blockquote>
<dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>Building the multi segment term dictionary causes GC pauses. The reason for this is because</p></li>
<li><p>it’s pretty big (possible ~15GB). When it’s allocated, we have to copy a lot of data from</p></li>
<li><p>survivor space to old gen. That causes several GC pauses. See SEARCH-33544</p></li>
<li></li>
<li><p>GC pauses are in general not fatal, but since all instances finish a segment at roughly the</p></li>
<li><p>same time, they might happen at the same time and then it’s a problem.</p></li>
<li></li>
<li><p>Some possible solutions to this problem would be to build this dictionary in some data</p></li>
<li><p>structures that are pre-allocated or to build only the part for the last segment, as</p></li>
<li><p>everything else doesn’t change. These solutions are a bit difficult to implement and this</p></li>
<li><p>here is an easy workaround.</p></li>
<li></li>
<li><p>Note that we might finish optimizing a segment and then it might take ~60+ minutes until it’s</p></li>
<li><p>a particular Earlybird’s turn to run this code. The effect of this is going to be that we</p></li>
<li><p>are not going to use the multi segment dictionary for the last two segments, one of which is</p></li>
<li><p>still pretty small. That’s not terrible, since right before optimization we’re not using</p></li>
<li><p>the dictionary for the last segment anyways, since it’s still not optimized.</p></li>
</ul>
<p><a href="#id9"><span class="problematic" id="id10">*</span></a>/</p>
</dd>
<dt>try {</dt><dd><p>LOG.info(“Acquire coordination lock before beginning post_optimization_rebuilds action.”);
optimizationAndFlushingCoordinationLock.lock();
LOG.info(“Successfully acquired coordination lock for post_optimization_rebuilds action.”);
postOptimizationRebuildsAction.retryActionUntilRan(</p>
<blockquote>
<div><dl>
<dt>“post optimization rebuilds”, () -&gt; {</dt><dd><p>Stopwatch stopwatch = Stopwatch.createStarted();
LOG.info(“Starting to build multi term dictionary for {}”, segmentName);
boolean result = multiSegmentTermDictionaryManager.buildDictionary();
LOG.info(“Done building multi term dictionary for {} in {}, result: {}”,</p>
<blockquote>
<div><p>segmentName, stopwatch, result);</p>
</div></blockquote>
<dl class="simple">
<dt>queryCacheManager.rebuildQueryCachesAfterSegmentOptimization(</dt><dd><p>optimizedSegmentInfo);</p>
</dd>
</dl>
<p>// This is a serial full GC and it defragments the memory so things can run smoothly
// until the next segment rolls. What we have observed is that if we don’t do that
// later on some earlybirds can have promotion failures on an old gen that hasn’t
// reached the initiating occupancy limit and these promotions failures can trigger a
// long (1.5 min) full GC. That usually happens because of fragmentation issues.
GCUtil.runGC();
// Wait for indexing to catch up before rejoining the serverset. We only need to do
// this if the host has already finished startup.
if (EarlybirdStatus.hasStarted()) {</p>
<blockquote>
<div><p>indexCaughtUpMonitor.resetAndWaitUntilCaughtUp();</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>});</p>
</div></blockquote>
</dd>
<dt>} finally {</dt><dd><p>LOG.info(“Finished post_optimization_rebuilds action. Releasing coordination lock.”);
optimizationAndFlushingCoordinationLock.unlock();</p>
</dd>
</dl>
<p>}</p>
<p>return optimizedSegmentInfo;</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Many tests rely on precise segment boundaries, so we expose this to allow them to create a</p></li>
<li><p>particular segment.</p></li>
</ul>
<p><a href="#id11"><span class="problematic" id="id12">*</span></a>/</p>
</dd>
</dl>
<p>&#64;VisibleForTesting
public void createNewSegment(long tweetID) throws IOException {</p>
<blockquote>
<div><p>NEW_SEGMENT_STATS.recordCreateNewSegment();</p>
<dl>
<dt>if (previousSegment != null) {</dt><dd><p>// We shouldn’t have more than one unoptimized segment, so if we get to this point and the
// previousSegment has not been optimized and set to null, start optimizing it before
// creating the next one. Note that this is a weird case and would only happen if we get
// Tweets with drastically different IDs than we expect, or there is a large amount of time
// where no Tweets are created in this partition.
LOG.error(“Creating new segment for Tweet {} when the previous segment {} was not sealed. “</p>
<blockquote>
<div><ul class="simple">
<li><p>“Current segment: {}. Documents: {}. largestValidTweetIDForSegment: {}.”,</p></li>
</ul>
<p>tweetID,
previousSegment.getSegmentInfo().getTimeSliceID(),
currentSegment.getSegmentInfo().getTimeSliceID(),
currentSegment.getSegmentInfo().getIndexSegment().getNumDocs(),
largestValidTweetIDForCurrentSegment);</p>
</div></blockquote>
<p>optimizePreviousSegment();
SEGMENTS_CLOSED_EARLY.increment();</p>
</dd>
</dl>
<p>}</p>
<p>previousSegment = currentSegment;</p>
<p>// We have two cases:
//
// Case 1:
// If the greatest Tweet ID we have seen is tweetID, then when we want to create a new segment
// with that ID, so the Tweet being processed goes into the new segment.
//
// Case 2:
// If the tweetID is bigger than the max tweetID, then this method is being called directly from
// tests, so we didn’t update the maxTweetID, so we can create a new segment with the new
// Tweet ID.
//
// Case 3:
// If it’s not the greatest Tweet ID we have seen, then we don’t want to create a
// segment boundary that is lower than any Tweet IDs in the current segment, because then
// some tweets from the previous segment would be in the wrong segment, so create a segment
// that has a greater ID than any Tweets that we have seen.
//
//   Example:
//     - We have seen tweets 3, 10, 5, 6.
//     - We now see tweet 7 and we decide it’s time to create a new segment.
//     - The new segment will start at tweet 11. It can’t start at tweet 7, because
//       tweet 10 will be in the wrong segment.
//     - Tweet 7 that we just saw will end up in the previous segment.
if (maxTweetID &lt;= tweetID) {</p>
<blockquote>
<div><p>currentSegmentTimesliceBoundary = tweetID;
NEW_SEGMENT_STATS.recordSettingTimesliceToCurrentTweet(tweetID);</p>
</div></blockquote>
<dl class="simple">
<dt>} else {</dt><dd><p>currentSegmentTimesliceBoundary = maxTweetID + 1;
NEW_SEGMENT_STATS.recordSettingTimesliceToMaxTweetId(tweetID, maxTweetID);</p>
</dd>
</dl>
<p>}
currentSegment = segmentManager.createAndPutOptimizingSegmentWriter(</p>
<blockquote>
<div><p>currentSegmentTimesliceBoundary);</p>
</div></blockquote>
<p>currentSegment.getSegmentInfo().setIndexing(true);</p>
<dl class="simple">
<dt>largestValidTweetIDForCurrentSegment =</dt><dd><p>OutOfOrderRealtimeTweetIDMapper.calculateMaxTweetID(currentSegmentTimesliceBoundary);</p>
</dd>
<dt>NEW_SEGMENT_STATS.wrapNewSegmentCreation(tweetID, maxTweetID,</dt><dd><p>currentSegmentTimesliceBoundary, largestValidTweetIDForCurrentSegment);</p>
</dd>
</dl>
<p>segmentManager.removeExcessSegments();</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>void logState() {</dt><dd><p>LOG.info(“TweetCreateHandler:”);
LOG.info(String.format(”  tweets sent for indexing: %,d”,</p>
<blockquote>
<div><p>indexingResultCounts.getIndexingCalls()));</p>
</div></blockquote>
<dl class="simple">
<dt>LOG.info(String.format(”  non-retriable failure: %,d”,</dt><dd><p>indexingResultCounts.getFailureNotRetriable()));</p>
</dd>
<dt>LOG.info(String.format(”  retriable failure: %,d”,</dt><dd><p>indexingResultCounts.getFailureRetriable()));</p>
</dd>
<dt>LOG.info(String.format(”  successfully indexed: %,d”,</dt><dd><p>indexingResultCounts.getIndexingSuccess()));</p>
</dd>
</dl>
<p>LOG.info(String.format(”  tweets in wrong segment: %,d”, TWEETS_IN_WRONG_SEGMENT.getCount()));
LOG.info(String.format(”  segments closed early: %,d”, SEGMENTS_CLOSED_EARLY.getCount()));</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../../../index2.rst.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../../../index2.rst.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../../../../_sources/src/java/com/twitter/search/earlybird/partition/TweetCreateHandler.java.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>