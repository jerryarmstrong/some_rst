<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p># pylint: disable=arguments-differ, invalid-name
“””
This file contains the DataRecordTrainer class.
“””
import warnings</p>
<p>import twml
from twml.trainers import DataRecordTrainer</p>
<dl>
<dt>class BatchPredictionRequestTrainer(DataRecordTrainer):  # pylint: disable=abstract-method</dt><dd><p>“””
The <code class="docutils literal notranslate"><span class="pre">BatchPredictionRequestTrainer</span></code> implementation is intended to satisfy use cases
that input is BatchPredictionRequest at Twitter and also where only the build_graph methods
needs to be overridden. For this reason, <code class="docutils literal notranslate"><span class="pre">Trainer.[train,eval]_input_fn</span></code> methods
assume a DataRecord dataset partitioned into part files stored in compressed (e.g. gzip) format.</p>
<p>For use-cases that differ from this common Twitter use-case,
further Trainer methods can be overridden.
If that still doesn’t provide enough flexibility, the user can always
use the tf.estimator.Esimator or tf.session.run directly.
“””</p>
<dl>
<dt>def __init__(</dt><dd><blockquote>
<div><p>self, name, params,
build_graph_fn,
feature_config=None,
<a href="#id1"><span class="problematic" id="id2">**</span></a>kwargs):</p>
</div></blockquote>
<p>“””
The BatchPredictionRequestTrainer constructor builds a
<code class="docutils literal notranslate"><span class="pre">tf.estimator.Estimator</span></code> and stores it in self.estimator.
For this reason, BatchPredictionRequestTrainer accepts the same Estimator constructor arguments.
It also accepts additional arguments to facilitate metric evaluation and multi-phase training
(init_from_dir, init_map).</p>
<dl>
<dt>Args:</dt><dd><dl>
<dt>parent arguments:</dt><dd><p>See the <a href="#id8"><span class="problematic" id="id9">`Trainer constructor &lt;#twml.trainers.Trainer.__init__&gt;`_</span></a> documentation
for a full list of arguments accepted by the parent class.</p>
</dd>
<dt>name, params, build_graph_fn (and other parent class args):</dt><dd><p>see documentation for twml.Trainer and twml.DataRecordTrainer doc.</p>
</dd>
<dt>feature_config:</dt><dd><p>An object of type FeatureConfig describing what features to decode.
Defaults to None. But it is needed in the following cases:</p>
<blockquote>
<div><ul class="simple">
<li><p><cite>get_train_input_fn()</cite> / <cite>get_eval_input_fn()</cite> is called without a <cite>parse_fn</cite></p></li>
<li><p><cite>learn()</cite>, <cite>train()</cite>, <cite>eval()</cite>, <cite>calibrate()</cite> are called without providing <cite>*input_fn</cite>.</p></li>
</ul>
</div></blockquote>
</dd>
<dt><a href="#id3"><span class="problematic" id="id4">**</span></a>kwargs:</dt><dd><p>further kwargs can be specified and passed to the Estimator constructor.</p>
</dd>
</dl>
</dd>
</dl>
<p>“””</p>
<p># Check and update train_batch_size and eval_batch_size in params before initialization
# to print correct parameter logs and does not stop running
# This overwrites batch_size parameter constrains in twml.trainers.Trainer.check_params
updated_params = self.check_batch_size_params(params)
super(BatchPredictionRequestTrainer, self).__init__(</p>
<blockquote>
<div><p>name=name, params=updated_params, build_graph_fn=build_graph_fn, <a href="#id5"><span class="problematic" id="id6">**</span></a>kwargs)</p>
</div></blockquote>
</dd>
<dt>def check_batch_size_params(self, params):</dt><dd><p>“”” Verify that params has the correct key,values “””
# updated_params is an instance of tensorflow.contrib.training.HParams
updated_params = twml.util.convert_to_hparams(params)
param_values = updated_params.values()</p>
<p># twml.trainers.Trainer.check_params already checks other constraints,
# such as being an integer
if ‘train_batch_size’ in param_values:</p>
<blockquote>
<div><dl>
<dt>if not isinstance(updated_params.train_batch_size, int):</dt><dd><p>raise ValueError(“Expecting params.train_batch_size to be an integer.”)</p>
</dd>
<dt>if param_values[‘train_batch_size’] != 1:</dt><dd><p># This can be a bit annoying to force users to pass the batch sizes,
# but it is good to let them know what they actually use in the models
# Use warning instead of ValueError in there to continue the run
# and print out that train_batch_size is changed
warnings.warn(‘You are processing BatchPredictionRequest data, ‘</p>
<blockquote>
<div><p>‘train_batch_size is always 1.n’
‘The number of DataRecords in a batch is determined by the size ‘
‘of each BatchPredictionRequest.n’
‘If you did not pass train.batch_size or eval.batch_size, and ‘
‘the default batch_size 32 was in use,n’
‘please pass –train.batch_size 1 –eval.batch_size 1’)</p>
</div></blockquote>
<p># If the upper error warning, change/pass –train.batch_size 1
# so that train_batch_size = 1
updated_params.train_batch_size = 1</p>
</dd>
</dl>
</div></blockquote>
<dl>
<dt>if ‘eval_batch_size’ in param_values:</dt><dd><dl>
<dt>if not isinstance(updated_params.train_batch_size, int):</dt><dd><p>raise ValueError(‘Expecting params.eval_batch_size to be an integer.’)</p>
</dd>
<dt>if param_values[‘eval_batch_size’] != 1:</dt><dd><p># This can be a bit annoying to force users to pass the batch sizes,
# but it is good to let them know what they actually use in the models
# Use warning instead of ValueError in there to continue the run
# and print out that eval_batch_size is changed
warnings.warn(‘You are processing BatchPredictionRequest data, ‘</p>
<blockquote>
<div><p>‘eval_batch_size is also always 1.n’
‘The number of DataRecords in a batch is determined by the size ‘
‘of each BatchPredictionRequest.n’
‘If you did not pass train.batch_size or eval.batch_size, and ‘
‘the default batch_size 32 was in use,n’
‘please pass –train.batch_size 1 –eval.batch_size 1’)</p>
</div></blockquote>
<p># If the upper warning raises, change/pass –eval.batch_size 1
# so that eval_batch_size = 1
updated_params.eval_batch_size = 1</p>
</dd>
</dl>
</dd>
<dt>if ‘eval_batch_size’ not in param_values:</dt><dd><p>updated_params.eval_batch_size = 1</p>
</dd>
<dt>if not updated_params.eval_batch_size:</dt><dd><p>updated_params.eval_batch_size = 1</p>
</dd>
</dl>
<p>return updated_params</p>
</dd>
</dl>
<p>&#64;staticmethod
def add_batch_prediction_request_arguments():</p>
<blockquote>
<div><p>“””
Add commandline args to parse typically for the BatchPredictionRequestTrainer class.
Typically, the user calls this function and then parses cmd-line arguments
into an argparse.Namespace object which is then passed to the Trainer constructor
via the params argument.</p>
<p>See the <a class="reference external" href="_modules/twml/argument_parser.html#get_trainer_parser">code</a>
for a list and description of all cmd-line arguments.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>argparse.ArgumentParser instance with some useful args already added.</p>
</dd>
</dl>
<p>“””
parser = super(BatchPredictionRequestTrainer,</p>
<blockquote>
<div><p>BatchPredictionRequestTrainer).add_parser_arguments()</p>
</div></blockquote>
<p># mlp arguments
parser.add_argument(</p>
<blockquote>
<div><p>‘–model.use_existing_discretizer’, action=’store_true’,
dest=”model_use_existing_discretizer”,
help=’Load a pre-trained calibration or train a new one’)</p>
</div></blockquote>
<dl class="simple">
<dt>parser.add_argument(</dt><dd><p>‘–model.use_binary_values’, action=’store_true’,
dest=’model_use_binary_values’,
help=’Use the use_binary_values optimization’)</p>
</dd>
</dl>
<p># control hom many featues we keep in sparse tensors
# 12 is enough for learning-to-rank for now
parser.add_argument(</p>
<blockquote>
<div><p>‘–input_size_bits’, type=int, default=12,
help=’Number of bits allocated to the input size’)</p>
</div></blockquote>
<dl class="simple">
<dt>parser.add_argument(</dt><dd><p>‘–loss_function’, type=str, default=’ranknet’,
dest=’loss_function’,
help=’Options are pairwise: ranknet (default), lambdarank, ‘
‘listnet, listmle, attrank, ‘
‘pointwise’)</p>
</dd>
</dl>
<p># whether convert sparse tensors to dense tensor
# in order to use dense normalization methods
parser.add_argument(</p>
<blockquote>
<div><p>‘–use_dense_tensor’, action=’store_true’,
dest=’use_dense_tensor’,
default=False,
help=’If use_dense_tensor is False, ‘
‘sparse tensor and spare normalization are in use. ‘
‘If use_dense_tensor is True, ‘
‘dense tensor and dense normalization are in use.’)</p>
</div></blockquote>
<dl class="simple">
<dt>parser.add_argument(</dt><dd><p>‘–dense_normalization’, type=str, default=’mean_max_normalizaiton’,
dest=’dense_normalization’,
help=’Options are mean_max_normalizaiton (default), standard_normalizaiton’)</p>
</dd>
<dt>parser.add_argument(</dt><dd><p>‘–sparse_normalization’, type=str, default=’SparseMaxNorm’,
dest=’sparse_normalization’,
help=’Options are SparseMaxNorm (default), SparseBatchNorm’)</p>
</dd>
</dl>
<p># so far only used in pairwise learning-to-rank
parser.add_argument(</p>
<blockquote>
<div><p>‘–mask’, type=str, default=’full_mask’,
dest=’mask’,
help=’Options are full_mask (default), diag_mask’)</p>
</div></blockquote>
<p>return parser</p>
</div></blockquote>
</dd>
</dl>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index2.rst.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index2.rst.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../_sources/twml/twml/contrib/trainers/batch_prediction_request_trainer.py.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>