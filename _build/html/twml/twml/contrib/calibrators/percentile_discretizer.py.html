<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p># pylint: disable=arguments-differ,no-member,too-many-statements
‘’’ Contains PercentileDiscretizerFeature and PercentileDiscretizerCalibrator used </p>
<blockquote>
<div><p>for PercentileDiscretizer calibration ‘’’</p>
</div></blockquote>
<p>from .calibrator import CalibrationFeature, Calibrator</p>
<p>import os
import numpy as np
import tensorflow.compat.v1 as tf
import tensorflow_hub as hub
import twml
import twml.layers</p>
<p>DEFAULT_SAMPLE_WEIGHT = 1</p>
<dl>
<dt>class PercentileDiscretizerFeature(CalibrationFeature):</dt><dd><p>‘’’ Accumulates and calibrates a single sparse PercentileDiscretizer feature. ‘’’</p>
<p>&#64;staticmethod
def _gather_debug_info(values, indices, bin_vals, bin_counts_buffer):</p>
<blockquote>
<div><p>‘’’
Determine how many training values fell into a given bin during calibration.
This is calculated by finding the index of the first appearance of each bin
boundary in values (values may repeat, so that isn’t trivially in indices.)
Subtracting each bin boundary index from the next tells you how many values fall in
that bin.
To get this to calculate the last bin correctly, len(values) is appended to the
list of bound indices.</p>
<p>This assumes that <code class="docutils literal notranslate"><span class="pre">bin_vals</span></code> excludes np.inf bin boundaries when
PercentileDiscretizer was calibrated
with fewer values than bins.</p>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>values:</dt><dd><p>1D ndarray of the PercentileDiscretizerFeature’s accumulated values, sorted ascending</p>
</dd>
<dt>indices:</dt><dd><p>1D int32 ndarray of the indices (in values) of the bin boundaries</p>
</dd>
<dt>bin_vals:</dt><dd><p>1D ndarray containing the bin boundaries</p>
</dd>
<dt>bin_counts_buffer:</dt><dd><p>ndarray buffer for returning the PercentileDiscretizer histogram</p>
</dd>
</dl>
</dd>
</dl>
<p>‘’’
# np.flatnonzero(np.diff(x)) gives you the indices i in x s.t. x[i] != x[i+1]
# append index of the last bin since that cannot be empty with how
# PercentileDiscretizer is implemented
nonempty_bins = np.append(np.flatnonzero(np.diff(bin_vals)), len(bin_vals) - 1)
bin_start_indices = indices.take(nonempty_bins)</p>
<p># if multiples of a bin’s lower bound value exist, find the first one
for (i, idx) in enumerate(bin_start_indices):</p>
<blockquote>
<div><p>cur_idx = idx
while cur_idx &gt; 0 and values[cur_idx] == values[cur_idx - 1]:</p>
<blockquote>
<div><p>bin_start_indices[i] = cur_idx = cur_idx - 1</p>
</div></blockquote>
</div></blockquote>
<p># the end of each bin is the start of the next bin,
# until the last, which is the end of the array
# broadcast the counts to the nonempty bins, 0 otherwise
bin_counts_buffer[:] = 0
bin_counts_buffer[nonempty_bins] = np.diff(np.append(bin_start_indices, values.size))</p>
</div></blockquote>
<dl>
<dt>def calibrate(</dt><dd><blockquote>
<div><p>self,
bin_vals, percentiles, percentile_indices,
bin_counts_buffer=None):</p>
</div></blockquote>
<p>‘’’Calibrates the PercentileDiscretizerFeature into bin values for
use in PercentileDiscretizerCalibrator.
Note that this method can only be called once.</p>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>bin_vals:</dt><dd><p>Row in the PercentileDiscretizerCalibrator.bin_vals matrix corresponding to this feature.
Will be updated with the results of the calibration.
A 1D ndarray.</p>
</dd>
<dt>percentiles:</dt><dd><p>1D array of size n_bin with values ranging from 0 to 1.
For example, <code class="docutils literal notranslate"><span class="pre">percentiles</span> <span class="pre">=</span> <span class="pre">np.linspace(0,</span> <span class="pre">1,</span> <span class="pre">num=self._n_bin+1,</span> <span class="pre">dtype=np.float32)</span></code></p>
</dd>
<dt>percentile_indices:</dt><dd><p>Empty 1D array of size n_bin used to store intermediate results when
calling twml.twml_optim_nearest_interpolation().
For example, np.empty(self._n_bin + 1, dtype=np.float32).</p>
</dd>
<dt>bin_counts_buffer:</dt><dd><p>optional ndarray buffer used for retaining count of values per PercentileDiscretizer
bucket (for debug and feature exploration purposes)</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>calibrated bin_vals for use by <code class="docutils literal notranslate"><span class="pre">PercentileDiscretizerCalibrator</span></code></p>
</dd>
</dl>
<p>‘’’
if self._calibrated:</p>
<blockquote>
<div><p>raise RuntimeError(“Can only calibrate once”)</p>
</div></blockquote>
<dl class="simple">
<dt>if bin_vals.ndim != 1:</dt><dd><p>raise RuntimeError(“Expecting bin_vals row”)</p>
</dd>
</dl>
<p># # concatenate values and weights buffers
self._concat_arrays()
feature_values = self._features_dict[‘values’]
feature_weights = self._features_dict[‘weights’]</p>
<p># get features ready for the bins, order array indices by feature values.
indices = np.argsort(feature_values)</p>
<p># get ordered values and weights using array indices
values = feature_values.take(indices)
weights = feature_weights.take(indices)</p>
<p># Normalizes the sum of weights to be between 0 and 1
weights = np.cumsum(weights, out=feature_weights)
weights -= weights[0]
if weights[-1] &gt; 0:  # prevent zero-division</p>
<blockquote>
<div><p>weights /= weights[-1]</p>
</div></blockquote>
<p># Check if we have less values than bin_vals
if values.size &lt; bin_vals.size:</p>
<blockquote>
<div><p># Fills all the bins with a value that won’t ever be reached
bin_vals.fill(np.inf)
# Forces the first to be -inf
bin_vals[0] = -np.inf
# Copies the values as boundaries
bin_vals[1:values.size + 1] = values</p>
<dl>
<dt>if bin_counts_buffer is not None:</dt><dd><p># slice out bins with +/-np.inf boundary – their count will be zero anyway
# we can’t just assume all other bins will have 1 value since there can be dups
short_indices = np.arange(values.size, dtype=np.int32)
bin_counts_buffer.fill(0)
self._gather_debug_info(</p>
<blockquote>
<div><p>values, short_indices, bin_vals[1:values.size + 1],
bin_counts_buffer[1:values.size + 1])</p>
</div></blockquote>
</dd>
</dl>
</div></blockquote>
<dl>
<dt>else:</dt><dd><p># Gets the indices for the values that define the boundary for the bins
indices_float = np.arange(0, weights.size, dtype=np.float32)</p>
<p># Gets things in the correct shape for the linear interpolation
weights = weights.reshape(1, weights.size)
indices_float = indices_float.reshape(1, weights.size)</p>
<p># wrap ndarrays into twml.Array
percentiles_tarray = twml.Array(percentiles.reshape(percentiles.size, 1))
weights_tarray = twml.Array(weights)
indices_float_tarray = twml.Array(indices_float)
percentile_indices_tarray = twml.Array(percentile_indices.reshape(percentiles.size, 1))</p>
<p># Performs the binary search to find the indices corresponding to the percentiles
err = twml.CLIB.twml_optim_nearest_interpolation(</p>
<blockquote>
<div><p>percentile_indices_tarray.handle, percentiles_tarray.handle,  # output, input
weights_tarray.handle, indices_float_tarray.handle  # xs, ys</p>
</div></blockquote>
<p>)
if err != 1000:</p>
<blockquote>
<div><dl class="simple">
<dt>raise ValueError(“””twml.CLIB.twml_optim_nearest_interpolation</dt><dd><p>caught an error (see previous stdout). Error code: “”” % err)</p>
</dd>
</dl>
</div></blockquote>
<p>indices = indices[:bin_vals.size]
indices[:] = percentile_indices
indices[0] = 0
indices[-1] = weights.size - 1</p>
<p># Gets the values at those indices and copies them into bin_vals
values.take(indices, out=bin_vals)</p>
<p># get # of values per bucket
if bin_counts_buffer is not None:</p>
<blockquote>
<div><p>self._gather_debug_info(values, indices, bin_vals, bin_counts_buffer)</p>
</div></blockquote>
</dd>
</dl>
<p>self._calibrated = True</p>
</dd>
</dl>
</dd>
<dt>class PercentileDiscretizerCalibrator(Calibrator):</dt><dd><p>‘’’ Accumulates features and their respective values for PercentileDiscretizer calibration.
Internally, each feature’s values is accumulated via its own
<code class="docutils literal notranslate"><span class="pre">PercentileDiscretizerFeature</span></code> object.
The steps for calibration are typically as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>accumulate feature values from batches by calling <code class="docutils literal notranslate"><span class="pre">accumulate()</span></code>;</p></li>
<li><p>calibrate all feature into PercentileDiscretizer bin_vals by calling <code class="docutils literal notranslate"><span class="pre">calibrate()</span></code>; and</p></li>
<li><p>convert to a twml.layers.PercentileDiscretizer layer by calling <code class="docutils literal notranslate"><span class="pre">to_layer()</span></code>.</p></li>
</ol>
</div></blockquote>
<p>‘’’</p>
<dl>
<dt>def __init__(self, n_bin, out_bits, bin_histogram=True,</dt><dd><blockquote>
<div><p>allow_empty_calibration=False, <a href="#id1"><span class="problematic" id="id2">**</span></a>kwargs):</p>
</div></blockquote>
<p>‘’’ Constructs an PercentileDiscretizerCalibrator instance.</p>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>n_bin:</dt><dd><p>the number of bins per feature to use for PercentileDiscretizer.
Note that each feature actually maps to n_bin+1 output IDs.</p>
</dd>
<dt>out_bits:</dt><dd><p>The maximum number of bits to use for the output IDs.
2**out_bits must be greater than bin_ids.size or an error is raised.</p>
</dd>
<dt>bin_histogram:</dt><dd><p>When True (the default), gathers information during calibration
to build a bin_histogram.</p>
</dd>
<dt>allow_empty_calibration:</dt><dd><p>allows operation where we might not calibrate any features.
Default False to error out if no features were calibrated.
Typically, values of uncalibrated features pass through discretizers
untouched (though the feature ids will be truncated to obey out_bits).</p>
</dd>
</dl>
</dd>
</dl>
<p>‘’’
super(PercentileDiscretizerCalibrator, self).__init__(<a href="#id3"><span class="problematic" id="id4">**</span></a>kwargs)
self._n_bin = n_bin
self._out_bits = out_bits</p>
<p>self._bin_ids = None
self._bin_vals = np.empty(0, dtype=np.float32)  # Note changed from 64 (v1) to 32 (v2)</p>
<p>self._bin_histogram = bin_histogram
self._bin_histogram_dict = None</p>
<p>self._hash_map_counter = 0
self._hash_map = {}</p>
<p>self._discretizer_feature_dict = {}
self._allow_empty_calibration = allow_empty_calibration</p>
</dd>
</dl>
<p>&#64;property
def bin_ids(self):</p>
<blockquote>
<div><p>‘’’
Gets bin_ids
‘’’
return self._bin_ids</p>
</div></blockquote>
<p>&#64;property
def bin_vals(self):</p>
<blockquote>
<div><p>‘’’
Gets bin_vals
‘’’
return self._bin_vals</p>
</div></blockquote>
<p>&#64;property
def hash_map(self):</p>
<blockquote>
<div><p>‘’’
Gets hash_map
‘’’
return self._hash_map</p>
</div></blockquote>
<p>&#64;property
def discretizer_feature_dict(self):</p>
<blockquote>
<div><p>‘’’
Gets feature_dict
‘’’
return self._discretizer_feature_dict</p>
</div></blockquote>
<dl>
<dt>def accumulate_features(self, inputs, name):</dt><dd><p>‘’’
Wrapper around accumulate for PercentileDiscretizer.
Arguments:</p>
<blockquote>
<div><dl class="simple">
<dt>inputs:</dt><dd><p>batch that will be accumulated</p>
</dd>
<dt>name:</dt><dd><p>name of the tensor that will be accumulated</p>
</dd>
</dl>
</div></blockquote>
<p>‘’’
sparse_tf = inputs[name]
indices = sparse_tf.indices[:, 1]
ids = sparse_tf.indices[:, 0]
weights = np.take(inputs[“weights”], ids)
return self.accumulate(indices, sparse_tf.values, weights)</p>
</dd>
<dt>def accumulate_feature(self, output):</dt><dd><p>‘’’
Wrapper around accumulate for trainer API.
Arguments:</p>
<blockquote>
<div><dl class="simple">
<dt>output:</dt><dd><p>output of prediction of build_graph for calibrator</p>
</dd>
</dl>
</div></blockquote>
<p>‘’’
return self.accumulate(output[‘feature_ids’], output[‘feature_values’], output[‘weights’])</p>
</dd>
<dt>def accumulate(self, feature_keys, feature_vals, weights=None):</dt><dd><p>‘’’Accumulate a single batch of feature keys, values and weights.</p>
<p>These are accumulate until <code class="docutils literal notranslate"><span class="pre">calibrate()</span></code> is called.</p>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>feature_keys:</dt><dd><p>1D int64 array of feature keys.</p>
</dd>
<dt>feature_vals:</dt><dd><p>1D float array of feature values. Each element of this array
maps to the commensurate element in <code class="docutils literal notranslate"><span class="pre">feature_keys</span></code>.</p>
</dd>
<dt>weights:</dt><dd><p>Defaults to weights of 1.
1D array containing the weights of each feature key, value pair.
Typically, this is the weight of each sample (but you still need
to provide one weight per key,value pair).
Each element of this array maps to the commensurate element in feature_keys.</p>
</dd>
</dl>
</dd>
</dl>
<p>‘’’
if feature_keys.ndim != 1:</p>
<blockquote>
<div><p>raise ValueError(‘Expecting 1D feature_keys, got %dD’ % feature_keys.ndim)</p>
</div></blockquote>
<dl>
<dt>if feature_vals.ndim != 1:</dt><dd><p>raise ValueError(‘Expecting 1D feature_values, got %dD’ % feature_vals.ndim)</p>
</dd>
<dt>if feature_vals.size != feature_keys.size:</dt><dd><dl class="simple">
<dt>raise ValueError(</dt><dd><p>‘Expecting feature_keys.size == feature_values.size, got %d != %d’ %
(feature_keys.size, feature_vals.size))</p>
</dd>
</dl>
</dd>
<dt>if weights is not None:</dt><dd><p>weights = np.squeeze(weights)
if weights.ndim != 1:</p>
<blockquote>
<div><p>raise ValueError(‘Expecting 1D weights, got %dD’ % weights.ndim)</p>
</div></blockquote>
<dl class="simple">
<dt>elif weights.size != feature_keys.size:</dt><dd><dl class="simple">
<dt>raise ValueError(</dt><dd><p>‘Expecting feature_keys.size == weights.size, got %d != %d’ %
(feature_keys.size, weights.size))</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt>if weights is None:</dt><dd><p>weights = np.full(feature_vals.size, fill_value=DEFAULT_SAMPLE_WEIGHT)</p>
</dd>
</dl>
<p>unique_keys = np.unique(feature_keys)
for feature_id in unique_keys:</p>
<blockquote>
<div><p>idx = np.where(feature_keys == feature_id)
if feature_id not in self._discretizer_feature_dict:</p>
<blockquote>
<div><p>self._hash_map[feature_id] = self._hash_map_counter
# unlike v1, the hash_map_counter is incremented AFTER assignment.
# This makes the hash_map features zero-indexed: 0, 1, 2 instead of 1, 2, 3
self._hash_map_counter += 1
# creates a new cache if we never saw the feature before
discretizer_feature = PercentileDiscretizerFeature(feature_id)
self._discretizer_feature_dict[feature_id] = discretizer_feature</p>
</div></blockquote>
<dl class="simple">
<dt>else:</dt><dd><p>discretizer_feature = self._discretizer_feature_dict[feature_id]</p>
</dd>
</dl>
<p>discretizer_feature.add_values({‘values’: feature_vals[idx], ‘weights’: weights[idx]})</p>
</div></blockquote>
</dd>
<dt>def calibrate(self, debug=False):</dt><dd><p>‘’’
Calibrates each PercentileDiscretizer feature after accumulation is complete.</p>
<dl>
<dt>Arguments:</dt><dd><dl class="simple">
<dt>debug:</dt><dd><p>Boolean to request debug info be returned by the method.
(see Returns section below)</p>
</dd>
</dl>
</dd>
<dt>The calibration results are stored in two matrices:</dt><dd><dl class="simple">
<dt>bin_ids:</dt><dd><p>2D array of size number of accumulate <code class="docutils literal notranslate"><span class="pre">features</span> <span class="pre">x</span> <span class="pre">n_bin+1</span></code>.
Contains the new IDs generated by PercentileDiscretizer. Each row maps to a feature.
Each row maps to different value bins. The IDs
are in the range <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">-&gt;</span> <span class="pre">bin_ids.size+1</span></code></p>
</dd>
<dt>bin_vals:</dt><dd><p>2D array of the same size as bin_ids.
Each row maps to a feature. Each row contains the bin boundaries.
These boundaries represent feature values.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>if debug is True, the method returns</p>
<blockquote>
<div><ul class="simple">
<li><p>1D int64 array of feature_ids</p></li>
<li><p>2D float32 array copy of bin_vals (the bin boundaries) for each feature</p></li>
<li><p>2D int64 array of bin counts corresponding to the bin boundaries</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
<p>‘’’
n_feature = len(self._discretizer_feature_dict)
if n_feature == 0 and not self._allow_empty_calibration:</p>
<blockquote>
<div><dl class="simple">
<dt>raise RuntimeError(“Need to accumulate some features for calibrationn”</dt><dd><p>“Likely, the calibration data is empty. This cann”
“happen if the dataset is small, or if the followingn”
“cli args are set too low:n”
“  –discretizer_keep_rate (default=0.0008)n”
“  –discretizer_parts_downsampling_rate (default=0.2)n”
“Consider increasing the values of these args.n”
“To allow empty calibration data (and degenerate discretizer),n”
“use the allow_empty_calibration input of the constructor.”)</p>
</dd>
</dl>
</div></blockquote>
<p>self._bin_ids = np.arange(1, n_feature * (self._n_bin + 1) + 1)
self._bin_ids = self._bin_ids.reshape(n_feature, self._n_bin + 1)</p>
<p>self._bin_vals.resize(n_feature, self._n_bin + 1)</p>
<p># buffers shared by PercentileDiscretizerFeature.calibrate()
percentile_indices = np.empty(self._n_bin + 1, dtype=np.float32)</p>
<p># Tensor from 0 to 1 in the number of steps provided
percentiles = np.linspace(0, 1, num=self._n_bin + 1, dtype=np.float32)</p>
<dl class="simple">
<dt>if debug or self._bin_histogram:</dt><dd><p>debug_feature_ids = np.empty(n_feature, dtype=np.int64)
bin_counts = np.empty((n_feature, self._n_bin + 1), dtype=np.int64)</p>
</dd>
</dl>
<p># progress bar for calibration phase
progress_bar = tf.keras.utils.Progbar(n_feature)</p>
<p>discretizer_features_dict = self._discretizer_feature_dict
for i, feature_id in enumerate(discretizer_features_dict):</p>
<blockquote>
<div><dl class="simple">
<dt>if debug or self._bin_histogram:</dt><dd><p>debug_feature_ids[self._hash_map[feature_id]] = feature_id
bin_counts_buffer = bin_counts[self._hash_map[feature_id]]</p>
</dd>
<dt>else:</dt><dd><p>bin_counts_buffer = None</p>
</dd>
</dl>
<p># calibrate each PercentileDiscretizer feature (puts results in bin_vals)
discretizer_features_dict[feature_id].calibrate(</p>
<blockquote>
<div><p>self._bin_vals[self._hash_map[feature_id]],  # Gets feature-values
percentiles, percentile_indices,
bin_counts_buffer=bin_counts_buffer</p>
</div></blockquote>
<p>)</p>
<p># update progress bar 20 times
if (i % max(1.0, round(n_feature / 20)) == 0) or (i == n_feature - 1):</p>
<blockquote>
<div><p>progress_bar.update(i + 1)</p>
</div></blockquote>
</div></blockquote>
<p>super(PercentileDiscretizerCalibrator, self).calibrate()</p>
<dl>
<dt>if self._bin_histogram:</dt><dd><p># save bin histogram data for later
self._bin_histogram_dict = {</p>
<blockquote>
<div><p>‘feature_ids’: debug_feature_ids,
‘bin_counts’: bin_counts,
‘bin_vals’: self._bin_vals,
‘out_bits’: self._out_bits,</p>
</div></blockquote>
<p>}</p>
</dd>
<dt>if debug:</dt><dd><p>return debug_feature_ids, self._bin_vals.copy(), bin_counts</p>
</dd>
</dl>
<p>return None</p>
</dd>
<dt>def _create_discretizer_layer(self, n_feature, hash_map_keys, hash_map_values,</dt><dd><blockquote>
<div><p>feature_offsets, name):</p>
</div></blockquote>
<dl class="simple">
<dt>return twml.layers.PercentileDiscretizer(</dt><dd><p>n_feature=n_feature,
n_bin=self._n_bin,
out_bits=self._out_bits,
bin_values=self._bin_vals.flatten(),
hash_keys=hash_map_keys,
hash_values=hash_map_values.astype(np.int64),
bin_ids=self._bin_ids.flatten().astype(np.int64),
feature_offsets=feature_offsets,
name=name,
<a href="#id5"><span class="problematic" id="id6">**</span></a>self._kwargs</p>
</dd>
</dl>
<p>)</p>
</dd>
<dt>def to_layer(self, name=None):</dt><dd><p>“””
Returns a twml.layers.PercentileDiscretizer Layer
that can be used for feature discretization.</p>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>name:</dt><dd><p>name-scope of the PercentileDiscretizer layer</p>
</dd>
</dl>
</dd>
</dl>
<p>“””
n_feature = len(self._discretizer_feature_dict)
max_discretizer_feature = n_feature * (self._n_bin + 1)</p>
<dl class="simple">
<dt>if not self._calibrated:</dt><dd><p>raise RuntimeError(“Expecting prior call to calibrate()”)</p>
</dd>
<dt>if self._bin_ids.shape[0] != n_feature:</dt><dd><dl class="simple">
<dt>raise RuntimeError(“Expecting self._bin_ids.shape[0] </dt><dd><p>!= len(self._discretizer_feature_dict)”)</p>
</dd>
</dl>
</dd>
<dt>if self._bin_vals.shape[0] != n_feature:</dt><dd><dl class="simple">
<dt>raise RuntimeError(“Expecting self._bin_vals.shape[0] </dt><dd><p>!= len(self._discretizer_feature_dict)”)</p>
</dd>
</dl>
</dd>
</dl>
<p># can add at most #features * (n_bin+1) new feature ids
if 2**self._out_bits &lt;= max_discretizer_feature:</p>
<blockquote>
<div><dl>
<dt>raise ValueError(“””Maximum number of features created by discretizer is</dt><dd><p>%d but requested that the output be limited to %d values (%d bits),
which is smaller than that. Please ensure the output has enough bits
to represent at least the new features”””</p>
<blockquote>
<div><p>% (max_discretizer_feature, 2**self._out_bits, self._out_bits))</p>
</div></blockquote>
</dd>
</dl>
</div></blockquote>
<p># build feature_offsets, hash_map_keys, hash_map_values
feature_offsets = np.arange(0, max_discretizer_feature,</p>
<blockquote>
<div><p>self._n_bin + 1, dtype=’int64’)</p>
</div></blockquote>
<p>hash_map_keys = np.array(list(self._hash_map.keys()), dtype=np.int64)
hash_map_values = np.array(list(self._hash_map.values()), dtype=np.float32)</p>
<dl class="simple">
<dt>discretizer = self._create_discretizer_layer(n_feature, hash_map_keys,</dt><dd><p>hash_map_values, feature_offsets, name)</p>
</dd>
</dl>
<p>return discretizer</p>
</dd>
<dt>def get_layer_args(self):</dt><dd><p>‘’’
Returns layer arguments required to implement multi-phase training.
See twml.calibrator.Calibrator.get_layer_args for more detailed documentation.
‘’’
layer_args = {</p>
<blockquote>
<div><p>‘n_feature’: len(self._discretizer_feature_dict),
‘n_bin’: self._n_bin,
‘out_bits’: self._out_bits,</p>
</div></blockquote>
<p>}</p>
<p>return layer_args</p>
</dd>
<dt>def add_hub_signatures(self, name):</dt><dd><p>“””
Add Hub Signatures for each calibrator</p>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>name:</dt><dd><p>Calibrator name</p>
</dd>
</dl>
</dd>
</dl>
<p>“””
sparse_tf = tf.sparse_placeholder(tf.float32)
calibrator_layer = self.to_layer()
hub.add_signature(</p>
<blockquote>
<div><p>inputs=sparse_tf,
outputs=calibrator_layer(sparse_tf, keep_inputs=False),
name=name)</p>
</div></blockquote>
</dd>
<dt>def write_summary(self, writer, sess=None):</dt><dd><p>“””
This method is called by save() to write a histogram of
PercentileDiscretizer feature bins to disk. A histogram is included for each
feature.</p>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>writer:</dt><dd><p>tf.summary.FilteWriter instance.
used to add summaries to event files for inclusion in tensorboard.</p>
</dd>
<dt>sess:</dt><dd><p>tf.Session instance. Used to produces summaries for the writer.</p>
</dd>
</dl>
</dd>
</dl>
<p>“””
bin_counts_ph = tf.placeholder(tf.int64)
bin_counts = self._bin_histogram_dict[‘bin_counts’]</p>
<p># Record that distribution into a histogram summary
histo = tf.summary.histogram(“discretizer_feature_bin_counts”, bin_counts_ph)
for i in range(bin_counts.shape[0]):</p>
<blockquote>
<div><p>bin_counts_summary = sess.run(histo, feed_dict={bin_counts_ph: bin_counts[i]})
writer.add_summary(bin_counts_summary, global_step=i)</p>
</div></blockquote>
</dd>
<dt>def write_summary_json(self, save_dir, name=”default”):</dt><dd><p>“””
Export bin information to HDFS.</p>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>save_dir:</dt><dd><p>name of the saving directory.</p>
</dd>
<dt>name:</dt><dd><p>prefix of the saved hub signature. Default (string): “default”.</p>
</dd>
</dl>
</dd>
</dl>
<p>“””
# Since the size is small: (# of bins) * (# of features), we always dump the file.
discretizer_export_bin_filename = os.path.join(save_dir, name + ‘_bin.json’)
discretizer_export_bin_dict = {</p>
<blockquote>
<div><p>‘feature_ids’: self._bin_histogram_dict[‘feature_ids’].tolist(),
‘bin_boundaries’: self._bin_histogram_dict[‘bin_vals’].tolist(),
‘output_bits’: self._bin_histogram_dict[‘out_bits’]</p>
</div></blockquote>
<p>}
twml.write_file(discretizer_export_bin_filename, discretizer_export_bin_dict, encode=’json’)</p>
</dd>
<dt>def save(self, save_dir, name=”default”, verbose=False):</dt><dd><p>‘’’Save the calibrator into the given save_directory using TF Hub.
Arguments:</p>
<blockquote>
<div><dl class="simple">
<dt>save_dir:</dt><dd><p>name of the saving directory.</p>
</dd>
<dt>name:</dt><dd><p>prefix of the saved hub signature. Default (string): “default”.</p>
</dd>
</dl>
</div></blockquote>
<p>‘’’
if not self._calibrated:</p>
<blockquote>
<div><p>raise RuntimeError(“Expecting prior call to calibrate().Cannot save() prior to calibrate()”)</p>
</div></blockquote>
<p># This module allows for the calibrator to save be saved as part of
# Tensorflow Hub (this will allow it to be used in further steps)
def calibrator_module():</p>
<blockquote>
<div><p># Note that this is usually expecting a sparse_placeholder
inputs = tf.sparse_placeholder(tf.float32)
calibrator_layer = self.to_layer()
# creates the signature to the calibrator module
hub.add_signature(</p>
<blockquote>
<div><p>inputs=inputs,
outputs=calibrator_layer(inputs, keep_inputs=False),
name=name)</p>
</div></blockquote>
<p># and another signature for keep_inputs mode
hub.add_signature(</p>
<blockquote>
<div><p>inputs=inputs,
outputs=calibrator_layer(inputs, keep_inputs=True),
name=name + ‘_keep_inputs’)</p>
</div></blockquote>
</div></blockquote>
<p># exports the module to the save_dir
spec = hub.create_module_spec(calibrator_module)
with tf.Graph().as_default():</p>
<blockquote>
<div><p>module = hub.Module(spec)
with tf.Session() as session:</p>
<blockquote>
<div><p>module.export(save_dir, session)</p>
</div></blockquote>
</div></blockquote>
<p>self.write_summary_json(save_dir, name)</p>
</dd>
</dl>
</dd>
</dl>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index2.rst.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index2.rst.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../_sources/twml/twml/contrib/calibrators/percentile_discretizer.py.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>