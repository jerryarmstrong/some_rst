<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>“””
Preprocessors applied on DDS workers in order to modify the dataset on the fly.
Some of these preprocessors are also applied to the model at serving time.
“””
from tml.projects.home.recap import config as config_mod
from absl import logging
import tensorflow as tf
import numpy as np</p>
<dl>
<dt>class TruncateAndSlice(tf.keras.Model):</dt><dd><p>“””Class for truncating and slicing.”””</p>
<dl>
<dt>def __init__(self, truncate_and_slice_config):</dt><dd><p>super().__init__()
self._truncate_and_slice_config = truncate_and_slice_config</p>
<dl>
<dt>if self._truncate_and_slice_config.continuous_feature_mask_path:</dt><dd><dl class="simple">
<dt>with tf.io.gfile.GFile(</dt><dd><p>self._truncate_and_slice_config.continuous_feature_mask_path, “rb”</p>
</dd>
<dt>) as f:</dt><dd><p>self._continuous_mask = np.load(f).nonzero()[0]</p>
</dd>
</dl>
<p>logging.info(f”Slicing {np.sum(self._continuous_mask)} continuous features.”)</p>
</dd>
<dt>else:</dt><dd><p>self._continuous_mask = None</p>
</dd>
<dt>if self._truncate_and_slice_config.binary_feature_mask_path:</dt><dd><dl class="simple">
<dt>with tf.io.gfile.GFile(self._truncate_and_slice_config.binary_feature_mask_path, “rb”) as f:</dt><dd><p>self._binary_mask = np.load(f).nonzero()[0]</p>
</dd>
</dl>
<p>logging.info(f”Slicing {np.sum(self._binary_mask)} binary features.”)</p>
</dd>
<dt>else:</dt><dd><p>self._binary_mask = None</p>
</dd>
</dl>
</dd>
<dt>def call(self, inputs, training=None, mask=None):</dt><dd><p>outputs = tf.nest.pack_sequence_as(inputs, tf.nest.flatten(inputs))
if self._truncate_and_slice_config.continuous_feature_truncation:</p>
<blockquote>
<div><p>logging.info(“Truncating continuous”)
outputs[“continuous”] = outputs[“continuous”][</p>
<blockquote>
<div><p>:, : self._truncate_and_slice_config.continuous_feature_truncation</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<dl>
<dt>if self._truncate_and_slice_config.binary_feature_truncation:</dt><dd><p>logging.info(“Truncating binary”)
outputs[“binary”] = outputs[“binary”][</p>
<blockquote>
<div><p>:, : self._truncate_and_slice_config.binary_feature_truncation</p>
</div></blockquote>
<p>]</p>
</dd>
<dt>if self._continuous_mask is not None:</dt><dd><p>outputs[“continuous”] = tf.gather(outputs[“continuous”], self._continuous_mask, axis=1)</p>
</dd>
<dt>if self._binary_mask is not None:</dt><dd><p>outputs[“binary”] = tf.gather(outputs[“binary”], self._binary_mask, axis=1)</p>
</dd>
</dl>
<p>return outputs</p>
</dd>
</dl>
</dd>
<dt>class DownCast(tf.keras.Model):</dt><dd><p>“””Class for Down casting dataset before serialization and transferring to training host.
Depends on the data type and the actual data range, the down casting can be lossless or not.
It is strongly recommended to compare the metrics before and after down casting.
“””</p>
<dl>
<dt>def __init__(self, downcast_config):</dt><dd><p>super().__init__()
self.config = downcast_config
self._type_map = {</p>
<blockquote>
<div><p>“bfloat16”: tf.bfloat16,
“bool”: tf.bool,</p>
</div></blockquote>
<p>}</p>
</dd>
<dt>def call(self, inputs, training=None, mask=None):</dt><dd><p>outputs = tf.nest.pack_sequence_as(inputs, tf.nest.flatten(inputs))
for feature, type_str in self.config.features.items():</p>
<blockquote>
<div><p>assert type_str in self._type_map
if type_str == “bfloat16”:</p>
<blockquote>
<div><dl class="simple">
<dt>logging.warning(</dt><dd><p>“Although bfloat16 and float32 have the same number of exponent bits, this down casting is not 100% lossless. Please double check metrics.”</p>
</dd>
</dl>
<p>)</p>
</div></blockquote>
<p>down_cast_data_type = self._type_map[type_str]
outputs[feature] = tf.cast(outputs[feature], dtype=down_cast_data_type)</p>
</div></blockquote>
<p>return outputs</p>
</dd>
</dl>
</dd>
<dt>class RectifyLabels(tf.keras.Model):</dt><dd><p>“””Class for rectifying labels”””</p>
<dl>
<dt>def __init__(self, rectify_label_config):</dt><dd><p>super().__init__()
self._config = rectify_label_config
self._window = int(self._config.label_rectification_window_in_hours * 60 * 60 * 1000)</p>
</dd>
<dt>def call(self, inputs, training=None, mask=None):</dt><dd><p>served_ts_field = self._config.served_timestamp_field
impressed_ts_field = self._config.impressed_timestamp_field</p>
<dl>
<dt>for label, engaged_ts_field in self._config.label_to_engaged_timestamp_field.items():</dt><dd><p>impressed = inputs[impressed_ts_field]
served = inputs[served_ts_field]
engaged = inputs[engaged_ts_field]</p>
<p>keep = tf.math.logical_and(inputs[label] &gt; 0, impressed - served &lt; self._window)
keep = tf.math.logical_and(keep, engaged - served &lt; self._window)
inputs[label] = tf.where(keep, inputs[label], tf.zeros_like(inputs[label]))</p>
</dd>
</dl>
<p>return inputs</p>
</dd>
</dl>
</dd>
<dt>class ExtractFeatures(tf.keras.Model):</dt><dd><p>“””Class for extracting individual features from dense tensors by their index.”””</p>
<dl class="simple">
<dt>def __init__(self, extract_features_config):</dt><dd><p>super().__init__()
self._config = extract_features_config</p>
</dd>
</dl>
<p>def call(self, inputs, training=None, mask=None):</p>
<blockquote>
<div><dl class="simple">
<dt>for row in self._config.extract_feature_table:</dt><dd><p>inputs[row.name] = inputs[row.source_tensor][:, row.index]</p>
</dd>
</dl>
<p>return inputs</p>
</div></blockquote>
</dd>
<dt>class DownsampleNegatives(tf.keras.Model):</dt><dd><p>“””Class for down-sampling/dropping negatives and updating the weights.</p>
<p>If inputs[‘fav’] = [1, 0, 0, 0] and inputs[‘weights’] = [1.0, 1.0, 1.0, 1.0]
inputs are transformed to inputs[‘fav’] = [1, 0] and inputs[‘weights’] = [1.0, 3.0]
when batch_multiplier=2 and engagements_list=[‘fav’]</p>
<p>It supports multiple engagements (union/logical_or is used to aggregate engagements), so we don’t
drop positives for any engagement.
“””</p>
<dl>
<dt>def __init__(self, downsample_negatives_config):</dt><dd><p>super().__init__()
self.config = downsample_negatives_config</p>
</dd>
<dt>def call(self, inputs, training=None, mask=None):</dt><dd><p>labels = self.config.engagements_list
# union of engagements
mask = tf.squeeze(tf.reduce_any(tf.stack([inputs[label] == 1 for label in labels], 1), 1))
n_positives = tf.reduce_sum(tf.cast(mask, tf.int32))
batch_size = tf.cast(tf.shape(inputs[labels[0]])[0] / self.config.batch_multiplier, tf.int32)
negative_weights = tf.math.divide_no_nan(</p>
<blockquote>
<div><p>tf.cast(self.config.batch_multiplier * batch_size - n_positives, tf.float32),
tf.cast(batch_size - n_positives, tf.float32),</p>
</div></blockquote>
<p>)
new_weights = tf.cast(mask, tf.float32) + (1 - tf.cast(mask, tf.float32)) * negative_weights</p>
<dl>
<dt>def _split_by_label_concatenate_and_truncate(input_tensor):</dt><dd><p># takes positive examples and concatenate with negative examples and truncate
# DANGER: if n_positives &gt; batch_size down-sampling is incorrect (do not use pb_50)
return tf.concat(</p>
<blockquote>
<div><dl class="simple">
<dt>[</dt><dd><p>input_tensor[mask],
input_tensor[tf.math.logical_not(mask)],</p>
</dd>
</dl>
<p>],
0,</p>
</div></blockquote>
<p>)[:batch_size]</p>
</dd>
<dt>if “weights” not in inputs:</dt><dd><p># add placeholder so logic below applies even if weights aren’t present in inputs
inputs[“weights”] = tf.ones([tf.shape(inputs[labels[0]])[0], self.config.num_engagements])</p>
</dd>
<dt>for tensor in inputs:</dt><dd><dl class="simple">
<dt>if tensor == “weights”:</dt><dd><p>inputs[tensor] = inputs[tensor] * tf.reshape(new_weights, [-1, 1])</p>
</dd>
</dl>
<p>inputs[tensor] = _split_by_label_concatenate_and_truncate(inputs[tensor])</p>
</dd>
</dl>
<p>return inputs</p>
</dd>
</dl>
</dd>
<dt>def build_preprocess(preprocess_config, mode=config_mod.JobMode.TRAIN):</dt><dd><p>“””Builds a preprocess model to apply all preprocessing stages.”””
if mode == config_mod.JobMode.INFERENCE:</p>
<blockquote>
<div><p>logging.info(“Not building preprocessors for dataloading since we are in Inference mode.”)
return None</p>
</div></blockquote>
<p>preprocess_models = []
if preprocess_config.downsample_negatives:</p>
<blockquote>
<div><p>preprocess_models.append(DownsampleNegatives(preprocess_config.downsample_negatives))</p>
</div></blockquote>
<dl>
<dt>if preprocess_config.truncate_and_slice:</dt><dd><p>preprocess_models.append(TruncateAndSlice(preprocess_config.truncate_and_slice))</p>
</dd>
<dt>if preprocess_config.downcast:</dt><dd><p>preprocess_models.append(DownCast(preprocess_config.downcast))</p>
</dd>
<dt>if preprocess_config.rectify_labels:</dt><dd><p>preprocess_models.append(RectifyLabels(preprocess_config.rectify_labels))</p>
</dd>
<dt>if preprocess_config.extract_features:</dt><dd><p>preprocess_models.append(ExtractFeatures(preprocess_config.extract_features))</p>
</dd>
<dt>if len(preprocess_models) == 0:</dt><dd><p>raise ValueError(“No known preprocessor.”)</p>
</dd>
<dt>class PreprocessModel(tf.keras.Model):</dt><dd><dl>
<dt>def __init__(self, preprocess_models):</dt><dd><p>super().__init__()
self.preprocess_models = preprocess_models</p>
</dd>
<dt>def call(self, inputs, training=None, mask=None):</dt><dd><p>outputs = inputs
for model in self.preprocess_models:</p>
<blockquote>
<div><p>outputs = model(outputs, training, mask)</p>
</div></blockquote>
<p>return outputs</p>
</dd>
</dl>
</dd>
<dt>if len(preprocess_models) &gt; 1:</dt><dd><dl class="simple">
<dt>logging.warning(</dt><dd><p>“With multiple preprocessing models, we apply these models in a predefined order. Future works may introduce customized models and orders.”</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
<p>return PreprocessModel(preprocess_models)</p>
</dd>
</dl>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index2.rst.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index2.rst.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../_sources/projects/home/recap/data/preprocessors.py.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>