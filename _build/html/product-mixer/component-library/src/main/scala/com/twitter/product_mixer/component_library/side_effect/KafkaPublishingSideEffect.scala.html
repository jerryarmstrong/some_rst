<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../../../../../../../" id="documentation_options" src="../../../../../../../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../../../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../../../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../../../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>package com.twitter.product_mixer.component_library.side_effect</p>
<p>import com.twitter.conversions.DurationOps._
import com.twitter.conversions.StorageUnitOps._
import com.twitter.finatra.kafka.producers.FinagleKafkaProducerBuilder
import com.twitter.finatra.kafka.producers.KafkaProducerBase
import com.twitter.finatra.kafka.producers.TwitterKafkaProducerConfig
import com.twitter.product_mixer.core.functional_component.side_effect.PipelineResultSideEffect
import com.twitter.product_mixer.core.model.common.presentation.CandidateWithDetails
import com.twitter.product_mixer.core.model.marshalling.HasMarshalling
import com.twitter.product_mixer.core.pipeline.PipelineQuery
import com.twitter.stitch.Stitch
import com.twitter.util.Duration
import com.twitter.util.StorageUnit
import org.apache.kafka.clients.producer.ProducerRecord
import org.apache.kafka.common.serialization.Serializer
import org.apache.kafka.common.record.CompressionType</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>The Kafka publishing side effect.</p></li>
<li><p>This class creates a Kafka producer with provided and default parameters.</p></li>
<li><p>Note that callers may not provide arbitrary params as this class will do validity check on some</p></li>
<li><p>params, e.g. maxBlock, to make sure it is safe for online services.</p></li>
<li></li>
<li><p>PLEASE NOTE: caller needs to add the following to the Aurora file to successfully enable the TLS</p></li>
<li><p>‘-com.twitter.finatra.kafka.producers.principal={{role}}’,</p></li>
<li></li>
<li><p>&#64;tparam K type of the key</p></li>
<li><p>&#64;tparam V type of the value</p></li>
<li><p>&#64;tparam Query pipeline query</p></li>
</ul>
<p><a href="#id1"><span class="problematic" id="id2">*</span></a>/</p>
</dd>
<dt>trait KafkaPublishingSideEffect[K, V, Query &lt;: PipelineQuery, ResponseType &lt;: HasMarshalling]</dt><dd><blockquote>
<div><p>extends PipelineResultSideEffect[Query, ResponseType] {</p>
</div></blockquote>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Kafka servers list. It is usually a WilyNs name at Twitter</p></li>
</ul>
<p><a href="#id3"><span class="problematic" id="id4">*</span></a>/</p>
</dd>
</dl>
<p>val bootstrapServer: String</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>The serde of the key</p></li>
</ul>
<p><a href="#id5"><span class="problematic" id="id6">*</span></a>/</p>
</dd>
</dl>
<p>val keySerde: Serializer[K]</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>The serde of the value</p></li>
</ul>
<p><a href="#id7"><span class="problematic" id="id8">*</span></a>/</p>
</dd>
</dl>
<p>val valueSerde: Serializer[V]</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>An id string to pass to the server when making requests.</p></li>
<li><p>The purpose of this is to be able to track the source of requests beyond just ip/port by</p></li>
<li><p>allowing a logical application name to be included in server-side request logging.</p></li>
</ul>
<p><a href="#id9"><span class="problematic" id="id10">*</span></a>/</p>
</dd>
</dl>
<p>val clientId: String</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>The configuration controls how long &lt;code&gt;KafkaProducer.send()&lt;/code&gt; and</p></li>
<li><p>&lt;code&gt;KafkaProducer.partitionsFor()&lt;/code&gt; will block.</p></li>
<li><p>These methods can be blocked either because the buffer is full or metadata unavailable.</p></li>
<li><p>Blocking in the user-supplied serializers or partitioner will not be counted against this timeout.</p></li>
<li></li>
<li><p>Set 200ms by default to not blocking the thread too long which is critical to most ProMixer</p></li>
<li><p>powered services. Please note that there is a hard limit check of not greater than 1 second.</p></li>
<li></li>
</ul>
<p><a href="#id11"><span class="problematic" id="id12">*</span></a>/</p>
</dd>
</dl>
<p>val maxBlock: Duration = 200.milliseconds</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Retries due to broker failures, etc., may write duplicates of the retried message in the</p></li>
<li><p>stream. Note that enabling idempotence requires</p></li>
<li><p>&lt;code&gt; MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION &lt;/code&gt; to be less than or equal to 5,</p></li>
<li><p>&lt;code&gt; RETRIES_CONFIG &lt;/code&gt; to be greater than 0 and &lt;code&gt; ACKS_CONFIG &lt;/code&gt;</p></li>
<li><p>must be ‘all’. If these values are not explicitly set by the user, suitable values will be</p></li>
<li><p>chosen. If incompatible values are set, a &lt;code&gt;ConfigException&lt;/code&gt; will be thrown.</p></li>
<li></li>
<li><p>false by default, setting to true may introduce issues to brokers since brokers will keep</p></li>
<li><p>tracking all requests which is resource expensive.</p></li>
</ul>
<p><a href="#id13"><span class="problematic" id="id14">*</span></a>/</p>
</dd>
</dl>
<p>val idempotence: Boolean = false</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>The producer will attempt to batch records together into fewer requests whenever multiple</p></li>
<li><p>records are being sent to the same partition. This helps performance on both the client and</p></li>
<li><p>the server. This configuration controls the default batch size in bytes.</p></li>
<li><p>No attempt will be made to batch records larger than this size.</p></li>
<li><p>Requests sent to brokers will contain multiple batches, one for each partition with data</p></li>
<li><p>available to be sent. A small batch size will make batching less common and may reduce</p></li>
<li><p>throughput (a batch size of zero will disable batching entirely).</p></li>
<li><p>A very large batch size may use memory a bit more wastefully as we will always allocate a</p></li>
<li><p>buffer of the specified batch size in anticipation of additional records.</p></li>
<li></li>
<li><p>Default 16KB which comes from Kafka’s default</p></li>
</ul>
<p><a href="#id15"><span class="problematic" id="id16">*</span></a>/</p>
</dd>
</dl>
<p>val batchSize: StorageUnit = 16.kilobytes</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>The producer groups together any records that arrive in between request transmissions into</p></li>
<li><p>a single batched request. “Normally this occurs only under load when records arrive faster</p></li>
<li><p>than they can be sent out. However in some circumstances the client may want to reduce the</p></li>
<li><p>number of requests even under moderate load. This setting accomplishes this by adding a</p></li>
<li><p>small amount of artificial delay&amp;mdash;that is, rather than immediately sending out a record</p></li>
<li><p>the producer will wait for up to the given delay to allow other records to be sent so that</p></li>
<li><p>the sends can be batched together. This can be thought of as analogous to Nagle’s algorithm</p></li>
<li><p>in TCP. This setting gives the upper bound on the delay for batching: once we get</p></li>
<li><p>BATCH_SIZE_CONFIG worth of records for a partition it will be sent immediately regardless</p></li>
<li><p>of this setting, however if we have fewer than this many bytes accumulated for this</p></li>
<li><p>partition we will ‘linger’ for the specified time waiting for more records to show up.</p></li>
<li><p>This setting defaults to 0 (i.e. no delay). Setting LINGER_MS_CONFIG=5, for example,</p></li>
<li><p>would have the effect of reducing the number of requests sent but would add up to 5ms of</p></li>
<li><p>latency to records sent in the absence of load.</p></li>
<li></li>
<li><p>Default 0ms, which is Kafka’s default. If the record size is much larger than the batchSize,</p></li>
<li><p>you may consider to enlarge both batchSize and linger to have better compression (only when</p></li>
<li><p>compression is enabled.)</p></li>
</ul>
<p><a href="#id17"><span class="problematic" id="id18">*</span></a>/</p>
</dd>
</dl>
<p>val linger: Duration = 0.milliseconds</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>The total bytes of memory the producer can use to buffer records waiting to be sent to the</p></li>
<li><p>server. If records are sent faster than they can be delivered to the server the producer</p></li>
<li><p>will block for MAX_BLOCK_MS_CONFIG after which it will throw an exception.</p></li>
<li><p>This setting should correspond roughly to the total memory the producer will use, but is not</p></li>
<li><p>a hard bound since not all memory the producer uses is used for buffering.</p></li>
<li><p>Some additional memory will be used for compression (if compression is enabled) as well as</p></li>
<li><p>for maintaining in-flight requests.</p></li>
<li></li>
<li><p>Default 32MB which is Kafka’s default. Please consider to enlarge this value if the EPS and</p></li>
<li><p>the per-record size is large (millions EPS with &gt;1KB per-record size) in case the broker has</p></li>
<li><p>issues (which fills the buffer pretty quickly.)</p></li>
</ul>
<p><a href="#id19"><span class="problematic" id="id20">*</span></a>/</p>
</dd>
</dl>
<p>val bufferMemorySize: StorageUnit = 32.megabytes</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Producer compression type</p></li>
<li></li>
<li><p>Default LZ4 which is a good tradeoff between compression and efficiency.</p></li>
<li><p>Please be careful of choosing ZSTD, which the compression rate is better it might introduce</p></li>
<li><p>huge burden to brokers once the topic is consumed, which needs decompression at the broker side.</p></li>
</ul>
<p><a href="#id21"><span class="problematic" id="id22">*</span></a>/</p>
</dd>
</dl>
<p>val compressionType: CompressionType = CompressionType.LZ4</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Setting a value greater than zero will cause the client to resend any request that fails</p></li>
<li><p>with a potentially transient error</p></li>
<li></li>
<li><p>Default set to 3, to intentionally reduce the retries.</p></li>
</ul>
<p><a href="#id23"><span class="problematic" id="id24">*</span></a>/</p>
</dd>
</dl>
<p>val retries: Int = 3</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>The amount of time to wait before attempting to retry a failed request to a given topic</p></li>
<li><p>partition. This avoids repeatedly sending requests in a tight loop under some failure</p></li>
<li><p>scenarios</p></li>
</ul>
<p><a href="#id25"><span class="problematic" id="id26">*</span></a>/</p>
</dd>
</dl>
<p>val retryBackoff: Duration = 1.second</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>The configuration controls the maximum amount of time the client will wait</p></li>
<li><p>for the response of a request. If the response is not received before the timeout</p></li>
<li><p>elapses the client will resend the request if necessary or fail the request if</p></li>
<li><p>retries are exhausted.</p></li>
<li></li>
<li><p>Default 5 seconds which is intentionally low but not too low.</p></li>
<li><p>Since Kafka’s publishing is async this is in general safe (as long as the bufferMem is not full.)</p></li>
</ul>
<p><a href="#id27"><span class="problematic" id="id28">*</span></a>/</p>
</dd>
</dl>
<p>val requestTimeout: Duration = 5.seconds</p>
<dl>
<dt>require(</dt><dd><p>maxBlock.inMilliseconds &lt;= 1000,
“We intentionally set the maxBlock to be smaller than 1 second to not block the thread for too long!”)</p>
</dd>
<dt>lazy val kafkaProducer: KafkaProducerBase[K, V] = {</dt><dd><p>val jaasConfig = TwitterKafkaProducerConfig().configMap
val builder = FinagleKafkaProducerBuilder[K, V]()</p>
<blockquote>
<div><p>.keySerializer(keySerde)
.valueSerializer(valueSerde)
.dest(bootstrapServer, 1.second) // NOTE: this method blocks!
.clientId(clientId)
.maxBlock(maxBlock)
.batchSize(batchSize)
.linger(linger)
.bufferMemorySize(bufferMemorySize)
.maxRequestSize(4.megabytes)
.compressionType(compressionType)
.enableIdempotence(idempotence)
.maxInFlightRequestsPerConnection(5)
.retries(retries)
.retryBackoff(retryBackoff)
.requestTimeout(requestTimeout)
.withConfig(“acks”, “all”)
.withConfig(“delivery.timeout.ms”, requestTimeout + linger)</p>
</div></blockquote>
<p>builder.withConfig(jaasConfig).build()</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Build the record to be published to Kafka from query, selections and response</p></li>
<li><p>&#64;param query PipelineQuery</p></li>
<li><p>&#64;param selectedCandidates Result after Selectors are executed</p></li>
<li><p>&#64;param remainingCandidates Candidates which were not selected</p></li>
<li><p>&#64;param droppedCandidates Candidates dropped during selection</p></li>
<li><p>&#64;param response Result after Unmarshalling</p></li>
<li><p>&#64;return A sequence of to-be-published ProducerRecords</p></li>
</ul>
<p><a href="#id29"><span class="problematic" id="id30">*</span></a>/</p>
</dd>
<dt>def buildRecords(</dt><dd><p>query: Query,
selectedCandidates: Seq[CandidateWithDetails],
remainingCandidates: Seq[CandidateWithDetails],
droppedCandidates: Seq[CandidateWithDetails],
response: ResponseType</p>
</dd>
</dl>
<p>): Seq[ProducerRecord[K, V]]</p>
<dl>
<dt>final override def apply(</dt><dd><p>inputs: PipelineResultSideEffect.Inputs[Query, ResponseType]</p>
</dd>
<dt>): Stitch[Unit] = {</dt><dd><dl class="simple">
<dt>val records = buildRecords(</dt><dd><p>query = inputs.query,
selectedCandidates = inputs.selectedCandidates,
remainingCandidates = inputs.remainingCandidates,
droppedCandidates = inputs.droppedCandidates,
response = inputs.response</p>
</dd>
</dl>
<p>)</p>
<dl>
<dt>Stitch</dt><dd><dl>
<dt>.collect(</dt><dd><dl>
<dt>records</dt><dd><dl class="simple">
<dt>.map { record =&gt;</dt><dd><p>Stitch.callFuture(kafkaProducer.send(record))</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
<p>).unit</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../../../../../../index2.rst.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../../../../../../index2.rst.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../../../../../../../_sources/product-mixer/component-library/src/main/scala/com/twitter/product_mixer/component_library/side_effect/KafkaPublishingSideEffect.scala.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>