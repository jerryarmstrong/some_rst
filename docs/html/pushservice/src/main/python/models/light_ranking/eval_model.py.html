<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../../../" id="documentation_options" src="../../../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>from datetime import datetime
from functools import partial
import os</p>
<dl class="simple">
<dt>from ..libs.group_metrics import (</dt><dd><p>run_group_metrics_light_ranking,
run_group_metrics_light_ranking_in_bq,</p>
</dd>
</dl>
<p>)
from ..libs.metric_fn_utils import get_metric_fn
from ..libs.model_args import get_arg_parser_light_ranking
from ..libs.model_utils import read_config
from .deep_norm import build_graph, DataRecordTrainer, get_config_func, logging</p>
<p># checkstyle: noqa</p>
<dl>
<dt>if __name__ == “__main__”:</dt><dd><p>parser = get_arg_parser_light_ranking()
parser.add_argument(</p>
<blockquote>
<div><p>“–eval_checkpoint”,
default=None,
type=str,
help=”Which checkpoint to use for evaluation”,</p>
</div></blockquote>
<p>)
parser.add_argument(</p>
<blockquote>
<div><p>“–saved_model_path”,
default=None,
type=str,
help=”Path to saved model for evaluation”,</p>
</div></blockquote>
<p>)
parser.add_argument(</p>
<blockquote>
<div><p>“–run_binary_metrics”,
default=False,
action=”store_true”,
help=”Whether to compute the basic binary metrics for Light Ranking.”,</p>
</div></blockquote>
<p>)</p>
<p>opt = parser.parse_args()
logging.info(“parse is: “)
logging.info(opt)</p>
<p>feature_list = read_config(opt.feature_list).items()
feature_config = get_config_func(opt.feat_config_type)(</p>
<blockquote>
<div><p>data_spec_path=opt.data_spec,
feature_list_provided=feature_list,
opt=opt,
add_gbdt=opt.use_gbdt_features,
run_light_ranking_group_metrics_in_bq=opt.run_light_ranking_group_metrics_in_bq,</p>
</div></blockquote>
<p>)</p>
<p># ———————————————–
#        Create Trainer
# ———————————————–
trainer = DataRecordTrainer(</p>
<blockquote>
<div><p>name=opt.model_trainer_name,
params=opt,
build_graph_fn=partial(build_graph, run_light_ranking_group_metrics_in_bq=True),
save_dir=opt.save_dir,
run_config=None,
feature_config=feature_config,
metric_fn=get_metric_fn(opt.task_name, use_stratify_metrics=False),</p>
</div></blockquote>
<p>)</p>
<p># ———————————————–
#         Model Evaluation
# ———————————————–
logging.info(“Evaluating…”)
start = datetime.now()</p>
<dl>
<dt>if opt.run_binary_metrics:</dt><dd><p>eval_input_fn = trainer.get_eval_input_fn(repeat=False, shuffle=False)
eval_steps = None if (opt.eval_steps is not None and opt.eval_steps &lt; 0) else opt.eval_steps
trainer.estimator.evaluate(eval_input_fn, steps=eval_steps, checkpoint_path=opt.eval_checkpoint)</p>
</dd>
<dt>if opt.run_light_ranking_group_metrics_in_bq:</dt><dd><dl class="simple">
<dt>run_group_metrics_light_ranking_in_bq(</dt><dd><p>trainer=trainer, params=opt, checkpoint_path=opt.eval_checkpoint</p>
</dd>
</dl>
<p>)</p>
</dd>
<dt>if opt.run_light_ranking_group_metrics:</dt><dd><dl class="simple">
<dt>run_group_metrics_light_ranking(</dt><dd><p>trainer=trainer,
data_dir=os.path.join(opt.eval_data_dir, opt.eval_start_datetime),
model_path=opt.saved_model_path,
parse_fn=feature_config.get_parse_fn(),</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
<p>end = datetime.now()
logging.info(“Evaluating time: “ + str(end - start))</p>
</dd>
</dl>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../../index.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../../../_sources/pushservice/src/main/python/models/light_ranking/eval_model.py.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>