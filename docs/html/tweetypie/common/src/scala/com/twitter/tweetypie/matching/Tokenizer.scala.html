<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../../../../../" id="documentation_options" src="../../../../../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>package com.twitter.tweetypie.matching</p>
<p>import com.twitter.common.text.language.LocaleUtil
import com.twitter.common_internal.text.pipeline.TwitterTextNormalizer
import com.twitter.common_internal.text.pipeline.TwitterTextTokenizer
import com.twitter.common_internal.text.version.PenguinVersion
import com.twitter.concurrent.Once
import com.twitter.io.StreamIO
import java.util.Locale
import scala.collection.JavaConverters._</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Extract a sequence of normalized tokens from the input text. The</p></li>
<li><p>normalization and tokenization are properly configured for keyword</p></li>
<li><p>matching between texts.</p></li>
</ul>
<p><a href="#id1"><span class="problematic" id="id2">*</span></a>/</p>
</dd>
<dt>trait Tokenizer {</dt><dd><p>def tokenize(input: String): TokenSequence</p>
</dd>
</dl>
<p>}</p>
<p>object Tokenizer {</p>
<blockquote>
<div><dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>When a Penguin version is not explicitly specified, use this</p></li>
<li><p>version of Penguin to perform normalization and tokenization. If</p></li>
<li><p>you cache tokenized text, be sure to store the version as well, to</p></li>
<li><p>avoid comparing text that was normalized with different algorithms.</p></li>
</ul>
<p><a href="#id3"><span class="problematic" id="id4">*</span></a>/</p>
</dd>
</dl>
<p>val DefaultPenguinVersion: PenguinVersion = PenguinVersion.PENGUIN_6</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>If you already know the locale of the text that is being tokenized,</p></li>
<li><p>use this method to get a tokenizer that is much more efficient than</p></li>
<li><p>the Tweet or Query tokenizer, since it does not have to perform</p></li>
<li><p>language detection.</p></li>
</ul>
<p><a href="#id5"><span class="problematic" id="id6">*</span></a>/</p>
</dd>
</dl>
<p>def forLocale(locale: Locale): Tokenizer = get(locale, DefaultPenguinVersion)</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Obtain a <cite>Tokenizer</cite> that will tokenize the text for the given</p></li>
<li><p>locale and version of the Penguin library.</p></li>
</ul>
<p><a href="#id7"><span class="problematic" id="id8">*</span></a>/</p>
</dd>
<dt>def get(locale: Locale, version: PenguinVersion): Tokenizer =</dt><dd><p>TokenizerFactories(version).forLocale(locale)</p>
</dd>
<dt>/**</dt><dd><ul class="simple">
<li><p>Encapsulates the configuration and use of [[TwitterTextTokenizer]]</p></li>
<li><p>and [[TwitterTextNormalizer]].</p></li>
</ul>
<p><a href="#id9"><span class="problematic" id="id10">*</span></a>/</p>
</dd>
<dt>private[this] class TokenizerFactory(version: PenguinVersion) {</dt><dd><p>// The normalizer is thread-safe, so share one instance.
private[this] val normalizer =</p>
<blockquote>
<div><p>(new TwitterTextNormalizer.Builder(version)).build()</p>
</div></blockquote>
<p>// The TwitterTextTokenizer is relatively expensive to build,
// and is not thread safe, so keep instances of it in a
// ThreadLocal.
private[this] val local =</p>
<blockquote>
<div><dl class="simple">
<dt>new ThreadLocal[TwitterTextTokenizer] {</dt><dd><dl class="simple">
<dt>override def initialValue: TwitterTextTokenizer =</dt><dd><p>(new TwitterTextTokenizer.Builder(version)).build()</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Obtain a [[Tokenizer]] for this combination of [[PenguinVersion]]</p></li>
<li><p>and [[Locale]].</p></li>
</ul>
<p><a href="#id11"><span class="problematic" id="id12">*</span></a>/</p>
</dd>
<dt>def forLocale(locale: Locale): Tokenizer =</dt><dd><dl>
<dt>new Tokenizer {</dt><dd><dl class="simple">
<dt>override def tokenize(input: String): TokenSequence = {</dt><dd><p>val stream = local.get.getTwitterTokenStreamFor(locale)
stream.reset(normalizer.normalize(input, locale))
val builder = IndexedSeq.newBuilder[CharSequence]
while (stream.incrementToken) builder += stream.term()
TokenSequence(builder.result())</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Since there are a small number of Penguin versions, eagerly</p></li>
<li><p>initialize a TokenizerFactory for each version, to avoid managing</p></li>
<li><p>mutable state.</p></li>
</ul>
<p><a href="#id13"><span class="problematic" id="id14">*</span></a>/</p>
</dd>
<dt>private[this] val TokenizerFactories: PenguinVersion =&gt; TokenizerFactory =</dt><dd><p>PenguinVersion.values.map(v =&gt; v -&gt; new TokenizerFactory(v)).toMap</p>
</dd>
<dt>/**</dt><dd><ul class="simple">
<li><p>The set of locales used in warmup. These locales are mentioned in</p></li>
<li><p>the logic of TwitterTextTokenizer and TwitterTextNormalizer.</p></li>
</ul>
<p><a href="#id15"><span class="problematic" id="id16">*</span></a>/</p>
</dd>
<dt>private[this] val WarmUpLocales: Seq[Locale] =</dt><dd><dl>
<dt>Seq</dt><dd><dl>
<dt>.concat(</dt><dd><dl class="simple">
<dt>Seq(</dt><dd><p>Locale.JAPANESE,
Locale.KOREAN,
LocaleUtil.UNKNOWN,
LocaleUtil.THAI,
LocaleUtil.ARABIC,
LocaleUtil.SWEDISH</p>
</dd>
</dl>
<p>),
LocaleUtil.CHINESE_JAPANESE_LOCALES.asScala,
LocaleUtil.CJK_LOCALES.asScala</p>
</dd>
</dl>
<p>)
.toSet
.toArray
.toSeq</p>
</dd>
</dl>
</dd>
<dt>/**</dt><dd><ul class="simple">
<li><p>Load the default inputs that are used for warming up this library.</p></li>
</ul>
<p><a href="#id17"><span class="problematic" id="id18">*</span></a>/</p>
</dd>
<dt>def warmUpCorpus(): Seq[String] = {</dt><dd><p>val stream = getClass.getResourceAsStream(“warmup-text.txt”)
val bytes =</p>
<blockquote>
<div><p>try StreamIO.buffer(stream)
finally stream.close()</p>
</div></blockquote>
<p>bytes.toString(“UTF-8”).linesIterator.toArray.toSeq</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Exercise the functionality of this library on the specified</p></li>
<li><p>strings. In general, prefer [[warmUp]] to this method.</p></li>
</ul>
<p><a href="#id19"><span class="problematic" id="id20">*</span></a>/</p>
</dd>
<dt>def warmUpWith(ver: PenguinVersion, texts: Iterable[String]): Unit =</dt><dd><dl>
<dt>texts.foreach { txt =&gt;</dt><dd><p>// Exercise each locale
WarmUpLocales.foreach { loc =&gt;</p>
<blockquote>
<div><p>Tokenizer.get(loc, ver).tokenize(txt)
UserMutes.builder().withPenguinVersion(ver).withLocale(loc).validate(txt)</p>
</div></blockquote>
<p>}</p>
<p>// Exercise language detection
TweetTokenizer.get(ver).tokenize(txt)
UserMutes.builder().withPenguinVersion(ver).validate(txt)</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>private[this] val warmUpOnce = Once(warmUpWith(DefaultPenguinVersion, warmUpCorpus()))</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>The creation of the first TwitterTextTokenizer is relatively</p></li>
<li><p>expensive, and tokenizing some texts may cause significant</p></li>
<li><p>initialization.</p></li>
<li></li>
<li><p>This method exercises the functionality of this library</p></li>
<li><p>with a range of texts in order to perform as much initialization as</p></li>
<li><p>possible before the library is used in a latency-sensitive way.</p></li>
<li></li>
<li><p>The warmup routine will only run once. Subsequent invocations of</p></li>
<li><p><cite>warmUp</cite> will no do additional work, and will return once warmup is</p></li>
<li><p>complete.</p></li>
<li></li>
<li><p>The warmup will take on the order of seconds.</p></li>
</ul>
<p><a href="#id21"><span class="problematic" id="id22">*</span></a>/</p>
</dd>
</dl>
<p>def warmUp(): Unit = warmUpOnce()</p>
</div></blockquote>
<p>}</p>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../../../../index.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../../../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../../../../../_sources/tweetypie/common/src/scala/com/twitter/tweetypie/matching/Tokenizer.scala.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>