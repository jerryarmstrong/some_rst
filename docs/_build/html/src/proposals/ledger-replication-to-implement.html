<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>docs/src/proposals/ledger-replication-to-implement.md &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="docs-src-proposals-ledger-replication-to-implement-md">
<h1>docs/src/proposals/ledger-replication-to-implement.md<a class="headerlink" href="#docs-src-proposals-ledger-replication-to-implement-md" title="Permalink to this heading">¶</a></h1>
<p>Last edited: 2023-08-11 21:38:33</p>
<p>Contents:</p>
<div class="highlight-md notranslate"><div class="highlight"><pre><span></span>---
</pre></div>
</div>
<p>title: Ledger Replication
—</p>
<p>Note: this ledger replication solution was partially implemented, but not
completed. The partial implementation was removed by
<a class="reference external" href="https://github.com/solana-labs/solana/pull/9992">https://github.com/solana-labs/solana/pull/9992</a> in order to prevent the security
risk of unused code. The first part of this design document reflects the
once-implemented parts of ledger replication. The
[second part of this document](#ledger-replication-not-implemented) describes the
parts of the solution never implemented.</p>
<p>## Proof of Replication</p>
<p>At full capacity on a 1gbps network solana will generate 4 petabytes of data per year. To prevent the network from centralizing around validators that have to store the full data set this protocol proposes a way for mining nodes to provide storage capacity for pieces of the data.</p>
<p>The basic idea to Proof of Replication is encrypting a dataset with a public symmetric key using CBC encryption, then hash the encrypted dataset. The main problem with the naive approach is that a dishonest storage node can stream the encryption and delete the data as it’s hashed. The simple solution is to periodically regenerate the hash based on a signed PoH value. This ensures that all the data is present during the generation of the proof and it also requires validators to have the entirety of the encrypted data present for verification of every proof of every identity. So the space required to validate is <cite>number_of_proofs * data_size</cite></p>
<p>## Optimization with PoH</p>
<p>Our improvement on this approach is to randomly sample the encrypted segments faster than it takes to encrypt, and record the hash of those samples into the PoH ledger. Thus the segments stay in the exact same order for every PoRep and verification can stream the data and verify all the proofs in a single batch. This way we can verify multiple proofs concurrently, each one on its own CUDA core. The total space required for verification is <cite>1_ledger_segment + 2_cbc_blocks * number_of_identities</cite> with core count equal to <cite>number_of_identities</cite>. We use a 64-byte chacha CBC block size.</p>
<p>## Network</p>
<p>Validators for PoRep are the same validators that are verifying transactions. If an archiver can prove that a validator verified a fake PoRep, then the validator will not receive a reward for that storage epoch.</p>
<p>Archivers are specialized _light <a href="#id30"><span class="problematic" id="id31">clients_</span></a>. They download a part of the ledger (a.k.a Segment) and store it, and provide PoReps of storing the ledger. For each verified PoRep archivers earn a reward of sol from the mining pool.</p>
<p>## Constraints</p>
<p>We have the following constraints:</p>
<ul>
<li><p>Verification requires generating the CBC blocks. That requires space of 2</p>
<p>blocks per identity, and 1 CUDA core per identity for the same dataset. So as</p>
<p>many identities at once should be batched with as many proofs for those</p>
<p>identities verified concurrently for the same dataset.</p>
</li>
<li><p>Validators will randomly sample the set of storage proofs to the set that</p>
<p>they can handle, and only the creators of those chosen proofs will be</p>
<p>rewarded. The validator can run a benchmark whenever its hardware configuration</p>
<p>changes to determine what rate it can validate storage proofs.</p>
</li>
</ul>
<p>## Validation and Replication Protocol</p>
<p>### Constants</p>
<ol class="arabic">
<li><p>SLOTS_PER_SEGMENT: Number of slots in a segment of ledger data. The</p>
<p>unit of storage for an archiver.</p>
</li>
<li><p>NUM_KEY_ROTATION_SEGMENTS: Number of segments after which archivers</p>
<p>regenerate their encryption keys and select a new dataset to store.</p>
</li>
<li><p>NUM_STORAGE_PROOFS: Number of storage proofs required for a storage proof</p>
<p>claim to be successfully rewarded.</p>
</li>
<li><p>RATIO_OF_FAKE_PROOFS: Ratio of fake proofs to real proofs that a storage</p>
<p>mining proof claim has to contain to be valid for a reward.</p>
</li>
<li><p>NUM_STORAGE_SAMPLES: Number of samples required for a storage mining</p>
<p>proof.</p>
</li>
<li><p>NUM_CHACHA_ROUNDS: Number of encryption rounds performed to generate</p>
<p>encrypted state.</p>
</li>
<li><p>NUM_SLOTS_PER_TURN: Number of slots that define a single storage epoch or</p>
<p>a “turn” of the PoRep game.</p>
</li>
</ol>
<p>### Validator behavior</p>
<ol class="arabic">
<li><p>Validators join the network and begin looking for archiver accounts at each</p>
<p>storage epoch/turn boundary.</p>
</li>
<li><p>Every turn, Validators sign the PoH value at the boundary and use that signature</p>
<p>to randomly pick proofs to verify from each storage account found in the turn boundary.</p>
<p>This signed value is also submitted to the validator’s storage account and will be used by</p>
<p>archivers at a later stage to cross-verify.</p>
</li>
<li><p>Every <cite>NUM_SLOTS_PER_TURN</cite> slots the validator advertises the PoH value. This is value</p>
<p>is also served to Archivers via RPC interfaces.</p>
</li>
<li><p>For a given turn N, all validations get locked out until turn N+3 (a gap of 2 turn/epoch).</p>
<p>At which point all validations during that turn are available for reward collection.</p>
</li>
<li><p>Any incorrect validations will be marked during the turn in between.</p></li>
</ol>
<p>### Archiver behavior</p>
<ol class="arabic">
<li><p>Since an archiver is somewhat of a light client and not downloading all the</p>
<p>ledger data, they have to rely on other validators and archivers for information.</p>
<p>Any given validator may or may not be malicious and give incorrect information, although</p>
<p>there are not any obvious attack vectors that this could accomplish besides having the</p>
<p>archiver do extra wasted work. For many of the operations there are a number of options</p>
<p>depending on how paranoid an archiver is:</p>
<ul>
<li><p>(a) archiver can ask a validator</p></li>
<li><p>(b) archiver can ask multiple validators</p></li>
<li><p>(c) archiver can ask other archivers</p></li>
<li><p>(d) archiver can subscribe to the full transaction stream and generate</p>
<p>the information itself (assuming the slot is recent enough)</p>
</li>
<li><p>(e) archiver can subscribe to an abbreviated transaction stream to</p>
<p>generate the information itself (assuming the slot is recent enough)</p>
</li>
</ul>
</li>
<li><p>An archiver obtains the PoH hash corresponding to the last turn with its slot.</p></li>
<li><p>The archiver signs the PoH hash with its keypair. That signature is the</p>
<p>seed used to pick the segment to replicate and also the encryption key. The</p>
<p>archiver mods the signature with the slot to get which segment to</p>
<p>replicate.</p>
</li>
<li><p>The archiver retrieves the ledger by asking peer validators and</p>
<p>archivers. See 6.5.</p>
</li>
<li><p>The archiver then encrypts that segment with the key with chacha algorithm</p>
<p>in CBC mode with <cite>NUM_CHACHA_ROUNDS</cite> of encryption.</p>
</li>
<li><p>The archiver initializes a chacha rng with the a signed recent PoH value as</p>
<p>the seed.</p>
</li>
<li><p>The archiver generates <cite>NUM_STORAGE_SAMPLES</cite> samples in the range of the</p>
<p>entry size and samples the encrypted segment with sha256 for 32-bytes at each</p>
<p>offset value. Sampling the state should be faster than generating the encrypted</p>
<p>segment.</p>
</li>
<li><p>The archiver sends a PoRep proof transaction which contains its sha state</p>
<p>at the end of the sampling operation, its seed and the samples it used to the</p>
<p>current leader and it is put onto the ledger.</p>
</li>
<li><p>During a given turn the archiver should submit many proofs for the same segment</p>
<p>and based on the <cite>RATIO_OF_FAKE_PROOFS</cite> some of those proofs must be fake.</p>
</li>
<li><p>As the PoRep game enters the next turn, the archiver must submit a</p>
<p>transaction with the mask of which proofs were fake during the last turn. This</p>
<p>transaction will define the rewards for both archivers and validators.</p>
</li>
<li><p>Finally for a turn N, as the PoRep game enters turn N + 3, archiver’s proofs for</p>
<p>turn N will be counted towards their rewards.</p>
</li>
</ol>
<p>### The PoRep Game</p>
<p>The Proof of Replication game has 4 primary stages. For each “turn” multiple PoRep games can be in progress but each in a different stage.</p>
<p>The 4 stages of the PoRep Game are as follows:</p>
<ol class="arabic simple">
<li><p>Proof submission stage
- Archivers: submit as many proofs as possible during this stage
- Validators: No-op</p></li>
<li><p>Proof verification stage
- Archivers: No-op
- Validators: Select archivers and verify their proofs from the previous turn</p></li>
<li><p>Proof challenge stage
- Archivers: Submit the proof mask with justifications (for fake proofs submitted 2 turns ago)
- Validators: No-op</p></li>
<li><p>Reward collection stage
- Archivers: Collect rewards for 3 turns ago
- Validators: Collect rewards for 3 turns ago</p></li>
</ol>
<p>For each turn of the PoRep game, both Validators and Archivers evaluate each stage. The stages are run as separate transactions on the storage program.</p>
<p>### Finding who has a given block of ledger</p>
<ol class="arabic">
<li><p>Validators monitor the turns in the PoRep game and look at the rooted bank</p>
<p>at turn boundaries for any proofs.</p>
</li>
<li><p>Validators maintain a map of ledger segments and corresponding archiver public keys.</p>
<p>The map is updated when a Validator processes an archiver’s proofs for a segment.</p>
<p>The validator provides an RPC interface to access this map. Using this API, clients</p>
<p>can map a segment to an archiver’s network address (correlating it via cluster_info table).</p>
<p>The clients can then send repair requests to the archiver to retrieve segments.</p>
</li>
<li><p>Validators would need to invalidate this list every N turns.</p></li>
</ol>
<p>## Sybil attacks</p>
<p>For any random seed, we force everyone to use a signature that is derived from a PoH hash at the turn boundary. Everyone uses the same count, so the same PoH hash is signed by every participant. The signatures are then each cryptographically tied to the keypair, which prevents a leader from grinding on the resulting value for more than 1 identity.</p>
<p>Since there are many more client identities then encryption identities, we need to split the reward for multiple clients, and prevent Sybil attacks from generating many clients to acquire the same block of data. To remain BFT we want to avoid a single human entity from storing all the replications of a single chunk of the ledger.</p>
<p>Our solution to this is to force the clients to continue using the same identity. If the first round is used to acquire the same block for many client identities, the second round for the same client identities will force a redistribution of the signatures, and therefore PoRep identities and blocks. Thus to get a reward for archivers need to store the first block for free and the network can reward long lived client identities more than new ones.</p>
<p>## Validator attacks</p>
<ul>
<li><p>If a validator approves fake proofs, archiver can easily out them by</p>
<p>showing the initial state for the hash.</p>
</li>
<li><p>If a validator marks real proofs as fake, no on-chain computation can be done</p>
<p>to distinguish who is correct. Rewards would have to rely on the results from</p>
<p>multiple validators to catch bad actors and archivers from being denied rewards.</p>
</li>
<li><p>Validator stealing mining proof results for itself. The proofs are derived</p>
<p>from a signature from an archiver, since the validator does not know the</p>
<p>private key used to generate the encryption key, it cannot be the generator of</p>
<p>the proof.</p>
</li>
</ul>
<p>## Reward incentives</p>
<p>Fake proofs are easy to generate but difficult to verify. For this reason, PoRep proof transactions generated by archivers may require a higher fee than a normal transaction to represent the computational cost required by validators.</p>
<p>Some percentage of fake proofs are also necessary to receive a reward from storage mining.</p>
<p>## Notes</p>
<ul>
<li><p>We can reduce the costs of verification of PoRep by using PoH, and actually</p>
<p>make it feasible to verify a large number of proofs for a global dataset.</p>
</li>
<li><p>We can eliminate grinding by forcing everyone to sign the same PoH hash and</p>
<p>use the signatures as the seed</p>
</li>
<li><p>The game between validators and archivers is over random blocks and random</p>
<p>encryption identities and random data samples. The goal of randomization is</p>
<p>to prevent colluding groups from having overlap on data or validation.</p>
</li>
<li><p>Archiver clients fish for lazy validators by submitting fake proofs that</p>
<p>they can prove are fake.</p>
</li>
<li><p>To defend against Sybil client identities that try to store the same block we</p>
<p>force the clients to store for multiple rounds before receiving a reward.</p>
</li>
<li><p>Validators should also get rewarded for validating submitted storage proofs</p>
<p>as incentive for storing the ledger. They can only validate proofs if they</p>
<p>are storing that slice of the ledger.</p>
</li>
</ul>
<p># Ledger Replication Not Implemented</p>
<p>Replication behavior yet to be implemented.</p>
<p>## Storage epoch</p>
<p>The storage epoch should be the number of slots which results in around 100GB-1TB of ledger to be generated for archivers to store. Archivers will start storing ledger when a given fork has a high probability of not being rolled back.</p>
<p>## Validator behavior</p>
<ol class="arabic">
<li><p>Every NUM_KEY_ROTATION_TICKS it also validates samples received from</p>
<p>archivers. It signs the PoH hash at that point and uses the following</p>
<p>algorithm with the signature as the input:</p>
<ul>
<li><p>The low 5 bits of the first byte of the signature creates an index into</p>
<p>another starting byte of the signature.</p>
</li>
<li><p>The validator then looks at the set of storage proofs where the byte of</p>
<p>the proof’s sha state vector starting from the low byte matches exactly</p>
<p>with the chosen byte(s) of the signature.</p>
</li>
<li><p>If the set of proofs is larger than the validator can handle, then it</p>
<p>increases to matching 2 bytes in the signature.</p>
</li>
<li><p>Validator continues to increase the number of matching bytes until a</p>
<p>workable set is found.</p>
</li>
<li><p>It then creates a mask of valid proofs and fake proofs and sends it to</p>
<p>the leader. This is a storage proof confirmation transaction.</p>
</li>
</ul>
</li>
<li><p>After a lockout period of NUM_SECONDS_STORAGE_LOCKOUT seconds, the</p>
<p>validator then submits a storage proof claim transaction which then causes the</p>
<p>distribution of the storage reward if no challenges were seen for the proof to</p>
<p>the validators and archivers party to the proofs.</p>
</li>
</ol>
<p>## Archiver behavior</p>
<ol class="arabic">
<li><p>The archiver then generates another set of offsets which it submits a fake</p>
<p>proof with an incorrect sha state. It can be proven to be fake by providing the</p>
<p>seed for the hash result.</p>
<ul>
<li><p>A fake proof should consist of an archiver hash of a signature of a PoH</p>
<p>value. That way when the archiver reveals the fake proof, it can be</p>
<p>verified on chain.</p>
</li>
</ul>
</li>
<li><p>The archiver monitors the ledger, if it sees a fake proof integrated, it</p>
<p>creates a challenge transaction and submits it to the current leader. The</p>
<p>transaction proves the validator incorrectly validated a fake storage proof.</p>
<p>The archiver is rewarded and the validator’s staking balance is slashed or</p>
<p>frozen.</p>
</li>
</ol>
<p>## Storage proof contract logic</p>
<p>Each archiver and validator will have their own storage account. The validator’s account would be separate from their gossip id similar to their vote account. These should be implemented as two programs one which handles the validator as the keysigner and one for the archiver. In that way when the programs reference other accounts, they can check the program id to ensure it is a validator or archiver account they are referencing.</p>
<p>### SubmitMiningProof</p>
<p><a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a>text
SubmitMiningProof {</p>
<blockquote>
<div><p>slot: u64,
sha_state: Hash,
signature: Signature,</p>
</div></blockquote>
<p>};
keys = [archiver_keypair]
<a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a></p>
<p>Archivers create these after mining their stored ledger data for a certain hash value. The slot is the end slot of the segment of ledger they are storing, the sha_state the result of the archiver using the hash function to sample their encrypted ledger segment. The signature is the signature that was created when they signed a PoH value for the current storage epoch. The list of proofs from the current storage epoch should be saved in the account state, and then transferred to a list of proofs for the previous epoch when the epoch passes. In a given storage epoch a given archiver should only submit proofs for one segment.</p>
<p>The program should have a list of slots which are valid storage mining slots. This list should be maintained by keeping track of slots which are rooted slots in which a significant portion of the network has voted on with a high lockout value, maybe 32-votes old. Every SLOTS_PER_SEGMENT number of slots would be added to this set. The program should check that the slot is in this set. The set can be maintained by receiving a AdvertiseStorageRecentBlockHash and checking with its bank/Tower BFT state.</p>
<p>The program should do a signature verify check on the signature, public key from the transaction submitter and the message of the previous storage epoch PoH value.</p>
<p>### ProofValidation</p>
<p><a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a>text
ProofValidation {</p>
<blockquote>
<div><p>proof_mask: Vec&lt;ProofStatus&gt;,</p>
</div></blockquote>
<p>}
keys = [validator_keypair, archiver_keypair(s) (unsigned)]
<a href="#id13"><span class="problematic" id="id14">``</span></a><a href="#id15"><span class="problematic" id="id16">`</span></a></p>
<p>A validator will submit this transaction to indicate that a set of proofs for a given segment are valid/not-valid or skipped where the validator did not look at it. The keypairs for the archivers that it looked at should be referenced in the keys so the program logic can go to those accounts and see that the proofs are generated in the previous epoch. The sampling of the storage proofs should be verified ensuring that the correct proofs are skipped by the validator according to the logic outlined in the validator behavior of sampling.</p>
<p>The included archiver keys will indicate the storage samples which are being referenced; the length of the proof_mask should be verified against the set of storage proofs in the referenced archiver account(s), and should match with the number of proofs submitted in the previous storage epoch in the state of said archiver account.</p>
<p>### ClaimStorageReward</p>
<p><code class="docutils literal notranslate"><span class="pre">`text</span>
<span class="pre">ClaimStorageReward</span> <span class="pre">{</span>
<span class="pre">}</span>
<span class="pre">keys</span> <span class="pre">=</span> <span class="pre">[validator_keypair</span> <span class="pre">or</span> <span class="pre">archiver_keypair,</span> <span class="pre">validator/archiver_keypairs</span> <span class="pre">(unsigned)]</span>
<span class="pre">`</span></code></p>
<p>Archivers and validators will use this transaction to get paid tokens from a program state where SubmitStorageProof, ProofValidation and ChallengeProofValidations are in a state where proofs have been submitted and validated and there are no ChallengeProofValidations referencing those proofs. For a validator, it should reference the archiver keypairs to which it has validated proofs in the relevant epoch. And for an archiver it should reference validator keypairs for which it has validated and wants to be rewarded.</p>
<p>### ChallengeProofValidation</p>
<p><a href="#id17"><span class="problematic" id="id18">``</span></a><a href="#id19"><span class="problematic" id="id20">`</span></a>text
ChallengeProofValidation {</p>
<blockquote>
<div><p>proof_index: u64,
hash_seed_value: Vec&lt;u8&gt;,</p>
</div></blockquote>
<p>}
keys = [archiver_keypair, validator_keypair]
<a href="#id21"><span class="problematic" id="id22">``</span></a><a href="#id23"><span class="problematic" id="id24">`</span></a></p>
<p>This transaction is for catching lazy validators who are not doing the work to validate proofs. An archiver will submit this transaction when it sees a validator has approved a fake SubmitMiningProof transaction. Since the archiver is a light client not looking at the full chain, it will have to ask a validator or some set of validators for this information maybe via RPC call to obtain all ProofValidations for a certain segment in the previous storage epoch. The program will look in the validator account state see that a ProofValidation is submitted in the previous storage epoch and hash the hash_seed_value and see that the hash matches the SubmitMiningProof transaction and that the validator marked it as valid. If so, then it will save the challenge to the list of challenges that it has in its state.</p>
<p>### AdvertiseStorageRecentBlockhash</p>
<p><a href="#id25"><span class="problematic" id="id26">``</span></a><a href="#id27"><span class="problematic" id="id28">`</span></a>text
AdvertiseStorageRecentBlockhash {</p>
<blockquote>
<div><p>hash: Hash,
slot: u64,</p>
</div></blockquote>
<section id="id29">
<h2>}<a class="headerlink" href="#id29" title="Permalink to this heading">¶</a></h2>
<p>Validators and archivers will submit this to indicate that a new storage epoch has passed and that the storage proofs which are current proofs should now be for the previous epoch. Other transactions should check to see that the epoch that they are referencing is accurate according to current chain state.</p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../_sources/src/proposals/ledger-replication-to-implement.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>