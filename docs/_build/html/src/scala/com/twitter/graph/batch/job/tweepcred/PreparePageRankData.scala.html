<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; twit  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../../../../../../../../" id="documentation_options" src="../../../../../../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>package com.twitter.graph.batch.job.tweepcred</p>
<p>import com.twitter.data.proto.Flock
import com.twitter.scalding._
import com.twitter.pluck.source._
import com.twitter.pluck.source.combined_user_source.MostRecentCombinedUserSnapshotSource
import com.twitter.scalding_internal.dalv2.DAL
import com.twitter.service.interactions.InteractionGraph
import graphstore.common.FlockFollowsJavaDataset
import java.util.TimeZone</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>Prepare the graph data for page rank calculation. Also generate the initial</p></li>
<li><p>pagerank as the starting point. Afterwards, start WeightedPageRank job.</p></li>
<li></li>
<li><p>Either read a tsv file for testing or read the following to build the graph</p></li>
<li><p>flock edges Flock.Edge</p></li>
<li><p>real graph input for weights InteractionGraph.Edge</p></li>
<li></li>
<li><p>Options:</p></li>
<li><p>–pwd: working directory, will generate the following files there</p></li>
<li><p>numnodes: total number of nodes</p></li>
<li><p>nodes: nodes file &lt;’src_id, ‘dst_ids, ‘weights, ‘mass_prior&gt;</p></li>
<li><p>pagerank: the page rank file</p></li>
<li><p>–user_mass: user mass tsv file, generated by twadoop user_mass job</p></li>
<li><p>Optional arguments:</p></li>
<li><p>–input: use the given tsv file instead of flock and real graph</p></li>
<li><p>–weighted: do weighted pagerank, default false</p></li>
<li><p>–flock_edges_only: restrict graph to flock edges, default true</p></li>
<li><p>–input_pagerank: continue pagerank from this</p></li>
<li></li>
<li><p>Plus the following options for WeightedPageRank and ExtractTweepcred:</p></li>
<li><p>–output_pagerank: where to put pagerank file</p></li>
<li><p>–output_tweepcred: where to put tweepcred file</p></li>
<li><p>Optional:</p></li>
<li><p>–maxiterations: how many iterations to run.  Default is 20</p></li>
<li><p>–jumpprob: probability of a random jump, default is 0.1</p></li>
<li><p>–threshold: total difference before finishing early, default 0.001</p></li>
<li><p>–post_adjust: whether to do post adjust, default true</p></li>
</ul>
<p><a href="#id1"><span class="problematic" id="id2">*</span></a>/</p>
</dd>
<dt>class PreparePageRankData(args: Args) extends Job(args) {</dt><dd><p>implicit val timeZone: TimeZone = DateOps.UTC
val PWD = args(“pwd”)
val WEIGHTED = args.getOrElse(“weighted”, “false”).toBoolean
val FLOCK_EDGES_ONLY = args.getOrElse(“flock_edges_only”, “true”).toBoolean</p>
<p>val ROW_TYPE_1 = 1
val ROW_TYPE_2 = 2</p>
<p>// graph data and user mass
val userMass = getUserMass
val nodesWithPrior = getGraphData(userMass)
val numNodes = nodesWithPrior.groupAll { _.size }
numNodes.write(Tsv(PWD + “/numnodes”))
dumpNodes(nodesWithPrior, PWD + “/nodes”);</p>
<p>// initial pagerank to start computation
generateInitialPagerank(nodesWithPrior)</p>
<p>// continue with the calculation
override def next = {</p>
<blockquote>
<div><p>Some(new WeightedPageRank(args))</p>
</div></blockquote>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>read flock edges</p></li>
</ul>
<p><a href="#id3"><span class="problematic" id="id4">*</span></a>/</p>
</dd>
<dt>def getFlockEdges = {</dt><dd><dl>
<dt>DAL</dt><dd><p>.readMostRecentSnapshotNoOlderThan(FlockFollowsJavaDataset, Days(7))
.toTypedSource
.flatMapTo(‘src_id, ‘dst_id) { edge: Flock.Edge =&gt;</p>
<blockquote>
<div><dl class="simple">
<dt>if (edge.getStateId() == Flock.State.Positive.getNumber()) {</dt><dd><p>Some((edge.getSourceId(), edge.getDestinationId()))</p>
</dd>
<dt>} else {</dt><dd><p>None</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>read real graph edges with weights</p></li>
</ul>
<p><a href="#id5"><span class="problematic" id="id6">*</span></a>/</p>
</dd>
<dt>def getRealGraphEdges = {</dt><dd><dl>
<dt>RealGraphEdgeSource()</dt><dd><dl>
<dt>.flatMapTo(‘src_id, ‘dst_id, ‘weight) { edge: InteractionGraph.Edge =&gt;</dt><dd><dl class="simple">
<dt>if (edge.getSourceId() != edge.getDestinationId()) {</dt><dd><p>val srcId = edge.getSourceId()
val dstId = edge.getDestinationId()
val weight = edge.getWeight().toFloat
Some((srcId, dstId, weight))</p>
</dd>
<dt>} else {</dt><dd><p>None</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>combine real graph and flock. If flock_edges_only is true, only take the</p></li>
<li><p>flock edges; otherwise edges are either from flock or from real graph.</p></li>
<li><p>edges weights default to be 1, overwritten by weights from real graph</p></li>
</ul>
<p><a href="#id7"><span class="problematic" id="id8">*</span></a>/</p>
</dd>
<dt>def getFlockRealGraphEdges = {</dt><dd><p>val flock = getFlockEdges</p>
<dl>
<dt>if (WEIGHTED) {</dt><dd><dl>
<dt>val flockWithWeight = flock</dt><dd><dl class="simple">
<dt>.map(() -&gt; (‘weight, ‘rowtype)) { (u: Unit) =&gt;</dt><dd><p>(1.0f, ROW_TYPE_1)</p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>val realGraph = getRealGraphEdges</dt><dd><dl class="simple">
<dt>.map(() -&gt; ‘rowtype) { (u: Unit) =&gt;</dt><dd><p>(ROW_TYPE_2)</p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>val combined = (flockWithWeight ++ realGraph)</dt><dd><dl class="simple">
<dt>.groupBy(‘src_id, ‘dst_id) {</dt><dd><dl class="simple">
<dt>_.min(‘rowtype)</dt><dd><p>.max(‘weight) // take whichever is bigger</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</dd>
<dt>if (FLOCK_EDGES_ONLY) {</dt><dd><dl class="simple">
<dt>combined.filter(‘rowtype) { (rowtype: Int) =&gt;</dt><dd><p>rowtype == ROW_TYPE_1</p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>} else {</dt><dd><p>combined</p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>} else {</dt><dd><dl class="simple">
<dt>flock.map(() -&gt; (‘weight)) { (u: Unit) =&gt;</dt><dd><p>1.0f</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}.project(‘src_id, ‘dst_id, ‘weight)</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>def getCsvEdges(fileName: String) = {</dt><dd><dl>
<dt>Tsv(fileName).read</dt><dd><dl class="simple">
<dt>.mapTo((0, 1, 2) -&gt; (‘src_id, ‘dst_id, ‘weight)) { input: (Long, Long, Float) =&gt;</dt><dd><p>input</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>Compute user mass based on combined user</p></li>
</ul>
<p><a href="#id9"><span class="problematic" id="id10">*</span></a>/</p>
</dd>
<dt>def getUserMass =</dt><dd><dl>
<dt>TypedPipe</dt><dd><p>.from(MostRecentCombinedUserSnapshotSource)
.flatMap { user =&gt;</p>
<blockquote>
<div><p>UserMass.getUserMass(user)</p>
</div></blockquote>
<p>}
.map { userMassInfo =&gt;</p>
<blockquote>
<div><p>(userMassInfo.userId, userMassInfo.mass)</p>
</div></blockquote>
<p>}
.toPipe[(Long, Double)](‘src_id_input, ‘mass_prior)
.normalize(‘mass_prior)</p>
</dd>
</dl>
</dd>
<dt>/**</dt><dd><ul class="simple">
<li><p>Read either flock/real_graph or a given tsv file</p></li>
<li><p>group by the source id, and output node data structure</p></li>
<li><p>merge with the user_mass.</p></li>
<li><p>return &lt;’src_id, ‘dst_ids, ‘weights, ‘mass_prior&gt;</p></li>
<li></li>
<li><p>make sure src_id is the same set as in user_mass, and dst_ids</p></li>
<li><p>are subset of user_mass. eg flock has edges like 1-&gt;2,</p></li>
<li><p>where both users 1 and 2 do not exist anymore</p></li>
</ul>
<p><a href="#id11"><span class="problematic" id="id12">*</span></a>/</p>
</dd>
<dt>def getGraphData(userMass: RichPipe) = {</dt><dd><dl class="simple">
<dt>val edges: RichPipe = args.optional(“input”) match {</dt><dd><p>case None =&gt; getFlockRealGraphEdges
case Some(input) =&gt; getCsvEdges(input)</p>
</dd>
</dl>
<p>}</p>
<p>// remove edges where dst_id is not in userMass
val filterByDst = userMass</p>
<blockquote>
<div><p>.joinWithLarger(‘src_id_input -&gt; ‘dst_id, edges)
.discard(‘src_id_input, ‘mass_prior)</p>
</div></blockquote>
<p>// aggreate by the source id
val nodes = filterByDst</p>
<blockquote>
<div><dl>
<dt>.groupBy(‘src_id) {</dt><dd><dl>
<dt>_.mapReduceMap((‘dst_id, ‘weight) -&gt; (‘dst_ids, ‘weights)) /* map1 <a href="#id13"><span class="problematic" id="id14">*</span></a>/ { a: (Long, Float) =&gt;</dt><dd><p>(Vector(a._1), if (WEIGHTED) Vector(a._2) else Vector())</p>
</dd>
<dt>} /* reduce <a href="#id15"><span class="problematic" id="id16">*</span></a>/ { (a: (Vector[Long], Vector[Float]), b: (Vector[Long], Vector[Float])) =&gt;</dt><dd><dl class="simple">
<dt>{</dt><dd><p>(a._1 ++ b._1, a._2 ++ b._2)</p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>} /* map2 <a href="#id17"><span class="problematic" id="id18">*</span></a>/ { a: (Vector[Long], Vector[Float]) =&gt;</dt><dd><p>a</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}
.mapTo(</p>
<blockquote>
<div><p>(‘src_id, ‘dst_ids, ‘weights) -&gt; (‘src_id, ‘dst_ids, ‘weights, ‘mass_prior, ‘rowtype)) {
input: (Long, Vector[Long], Vector[Float]) =&gt;</p>
<blockquote>
<div><dl class="simple">
<dt>{</dt><dd><p>(input._1, input._2.toArray, input._3.toArray, 0.0, ROW_TYPE_1)</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>// get to the same schema
val userMassNodes = userMass</p>
<blockquote>
<div><dl>
<dt>.mapTo((‘src_id_input, ‘mass_prior) -&gt; (‘src_id, ‘dst_ids, ‘weights, ‘mass_prior, ‘rowtype)) {</dt><dd><dl>
<dt>input: (Long, Double) =&gt;</dt><dd><dl class="simple">
<dt>{</dt><dd><p>(input._1, Array[Long](), Array[Float](), input._2, ROW_TYPE_2)</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>// make src_id the same set as in userMass
(nodes ++ userMassNodes)</p>
<blockquote>
<div><dl class="simple">
<dt>.groupBy(‘src_id) {</dt><dd><dl class="simple">
<dt>_.sortBy(‘rowtype)</dt><dd><p>.head(‘dst_ids, ‘weights)
.last(‘mass_prior, ‘rowtype)</p>
</dd>
</dl>
</dd>
</dl>
<p>}
.filter(‘rowtype) { input: Int =&gt;</p>
<blockquote>
<div><p>input == ROW_TYPE_2</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/**</dt><dd><ul class="simple">
<li><p>generate the graph data output</p></li>
</ul>
<p><a href="#id19"><span class="problematic" id="id20">*</span></a>/</p>
</dd>
<dt>def dumpNodes(nodes: RichPipe, fileName: String) = {</dt><dd><dl>
<dt>mode match {</dt><dd><p>case Hdfs(_, conf) =&gt; nodes.write(SequenceFile(fileName))
case _ =&gt;</p>
<blockquote>
<div><dl>
<dt>nodes</dt><dd><dl class="simple">
<dt>.mapTo((0, 1, 2, 3) -&gt; (0, 1, 2, 3)) { input: (Long, Array[Long], Array[Float], Double) =&gt;</dt><dd><p>(input._1, input._2.mkString(“,”), input._3.mkString(“,”), input._4)</p>
</dd>
</dl>
<p>}
.write(Tsv(fileName))</p>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>
<dl>
<dt>/*</dt><dd><ul class="simple">
<li><p>output prior mass or copy the given mass file (merge, normalize)</p></li>
<li><p>to be used as the starting point</p></li>
</ul>
<p><a href="#id21"><span class="problematic" id="id22">*</span></a>/</p>
</dd>
<dt>def generateInitialPagerank(nodes: RichPipe) = {</dt><dd><dl>
<dt>val prior = nodes</dt><dd><p>.project(‘src_id, ‘mass_prior)</p>
</dd>
<dt>val combined = args.optional(“input_pagerank”) match {</dt><dd><p>case None =&gt; prior
case Some(fileName) =&gt; {</p>
<blockquote>
<div><dl>
<dt>val massInput = Tsv(fileName).read</dt><dd><dl class="simple">
<dt>.mapTo((0, 1) -&gt; (‘src_id, ‘mass_prior, ‘rowtype)) { input: (Long, Double) =&gt;</dt><dd><p>(input._1, input._2, ROW_TYPE_2)</p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>val priorRow = prior</dt><dd><dl class="simple">
<dt>.map(() -&gt; (‘rowtype)) { (u: Unit) =&gt;</dt><dd><p>ROW_TYPE_1</p>
</dd>
</dl>
<p>}</p>
</dd>
<dt>(priorRow ++ massInput)</dt><dd><dl class="simple">
<dt>.groupBy(‘src_id) {</dt><dd><dl class="simple">
<dt>_.sortBy(‘rowtype)</dt><dd><p>.last(‘mass_prior)
.head(‘rowtype)</p>
</dd>
</dl>
</dd>
</dl>
<p>}
// throw away extra nodes from input file
.filter(‘rowtype) { (rowtype: Int) =&gt;</p>
<blockquote>
<div><p>rowtype == ROW_TYPE_1</p>
</div></blockquote>
<p>}
.discard(‘rowtype)
.normalize(‘mass_prior)</p>
</dd>
</dl>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>}</p>
<p>combined.write(Tsv(PWD + “/pagerank_0”))</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
<p>}</p>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../../../../index.html">twit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../../../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, jare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../../../../../../../_sources/src/scala/com/twitter/graph/batch/job/tweepcred/PreparePageRankData.scala.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>